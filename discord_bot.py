import datetime
import multiprocessing
import os
import random
import struct
import subprocess
import configparser
import asyncio
import time

from pydub import AudioSegment

from discord import Option
from modifed_sinks import StreamSink
import speech_recognition as sr
from pathlib import Path
import sys
import discord
from discord.ext import commands
from use_free_cuda import check_cuda, use_cuda_async, stop_use_cuda_async

# Ð—Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ
voiceChannelErrorText = 'â— Ð’Ñ‹ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑŒÑÑ Ð² Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð¼ ÐºÐ°Ð½Ð°Ð»Ðµ â—'
config = configparser.ConfigParser()

connections = {}

stream_sink = StreamSink()

intents = discord.Intents.all()
bot = commands.Bot(command_prefix='\\', intents=intents)


async def set_get_config_all(section, key, value):
    config.read('config.ini')
    if value is None:
        return config.get(section, key)
    config.set(section, key, str(value))
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ
    with open('config.ini', 'w') as configfile:
        config.write(configfile)
    return ' '.join([section, key, str(value)])


async def set_get_config(key="record", value=None):
    config.read('config.ini')
    if value is None:
        return config.get("Sound", key)
    config.set('Sound', key, str(value))
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ
    with open('config.ini', 'w') as configfile:
        config.write(configfile)


async def set_get_config_default(key, value=None):
    config.read('config.ini')
    if value is None:
        return config.get("Default", key)
    config.set('Default', key, str(value))
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ
    with open('config.ini', 'w') as configfile:
        config.write(configfile)


@bot.event
async def on_ready():
    print('Status: online')
    await bot.change_presence(activity=discord.Activity(
        type=discord.ActivityType.listening, name='AI-covers'))


# @bot.event
# async def on_message(message):
#     if message.author.bot:
#         return
#     if len(message.attachments) > 0:
#         for attachment in message.attachments:
#             await attachment.save(attachment.filename)
#             print(f'ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½ Ñ„Ð°Ð¹Ð»: {attachment.filename}')


@bot.slash_command(name="change_video",
                   description='Ð¿ÐµÑ€ÐµÑ€Ð¸ÑÐ¾Ð²Ð°Ñ‚ÑŒ Ð¸ Ð¿ÐµÑ€ÐµÐ¾Ð·Ð²ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð²Ð¸Ð´ÐµÐ¾. Ð‘Ð¾Ñ‚ Ñ‚Ð°ÐºÐ¶Ðµ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸Ñ‚ Ð²Ð°Ð¼ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ')
async def __change_video(
        ctx,
        video_path: Option(discord.SlashCommandOptionType.attachment, description='Ð¤Ð°Ð¹Ð» Ñ Ð²Ð¸Ð´ÐµÐ¾',
                           required=True),
        fps: Option(int, description='Ð§Ð°ÑÑ‚Ð¾Ñ‚Ð° ÐºÐ°Ð´Ñ€Ð¾Ð² (ÐžÐ§Ð•ÐÐ¬ Ð²Ð»Ð¸ÑÐµÑ‚ Ð½Ð° Ð²Ñ€ÐµÐ¼Ñ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ))', required=True,
                    choices=[30, 15, 10, 6, 5, 3, 2, 1]),
        extension: Option(str, description='Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ðµ (ÑÐ¸Ð»ÑŒÐ½Ð¾ Ð²Ð»Ð¸ÑÐµÑ‚ Ð½Ð° Ð²Ñ€ÐµÐ¼Ñ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ)', required=True,
                          choices=["144p", "240p", "360p", "480p", "720p"]),
        prompt: Option(str, description='Ð·Ð°Ð¿Ñ€Ð¾Ñ', required=True),
        negative_prompt: Option(str, description='Ð½ÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ', default="NSFW", required=False),
        steps: Option(int, description='Ñ‡Ð¸ÑÐ»Ð¾ ÑˆÐ°Ð³Ð¾Ð²', required=False,
                      default=30,
                      min_value=1,
                      max_value=500),
        seed: Option(int, description='ÑÐ¸Ð´ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ', required=False,
                     default=random.randint(1, 1000000),
                     min_value=1,
                     max_value=1000000),
        strength: Option(float, description='Ð½Ð°ÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÐ¸Ð»ÑŒÐ½Ñ‹ Ð±ÑƒÐ´ÑƒÑ‚ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ', required=False,
                         default=0.15, min_value=0,
                         max_value=1),
        strength_prompt: Option(float,
                                description='Ð›Ð£Ð§Ð¨Ð• ÐÐ• Ð¢Ð ÐžÐ“ÐÐ¢Ð¬! ÐÐ°ÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÐ¸Ð»ÑŒÐ½Ð¾ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ÑÑ Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚',
                                required=False,
                                default=0.85, min_value=0,
                                max_value=1),
        strength_negative_prompt: Option(float,
                                         description='Ð›Ð£Ð§Ð¨Ð• ÐÐ• Ð¢Ð ÐžÐ“ÐÐ¢Ð¬! ÐÐ°ÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÐ¸Ð»ÑŒÐ½Ð¾ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ÑÑ Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚',
                                         required=False,
                                         default=1, min_value=0,
                                         max_value=1),
        voice: Option(str, description='Ð“Ð¾Ð»Ð¾Ñ Ð´Ð»Ñ Ð²Ð¸Ð´ÐµÐ¾', required=False, default="None"),
        pitch: Option(str, description='ÐšÑ‚Ð¾ Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚/Ð¿Ð¾Ñ‘Ñ‚ Ð² Ð²Ð¸Ð´ÐµÐ¾?', required=False,
                      choices=['Ð¼ÑƒÐ¶Ñ‡Ð¸Ð½Ð°', 'Ð¶ÐµÐ½Ñ‰Ð¸Ð½Ð°'], default=None),
        indexrate: Option(float, description='Ð˜Ð½Ð´ÐµÐºÑ Ð³Ð¾Ð»Ð¾ÑÐ° (Ð¾Ñ‚ 0 Ð´Ð¾ 1)', required=False, default=0.5, min_value=0,
                          max_value=1),
        loudness: Option(float, description='Ð“Ñ€Ð¾Ð¼ÐºÐ¾ÑÑ‚ÑŒ ÑˆÑƒÐ¼Ð° (Ð¾Ñ‚ 0 Ð´Ð¾ 1)', required=False, default=0.2, min_value=0,
                         max_value=1),
        main_vocal: Option(int, description='Ð“Ñ€Ð¾Ð¼ÐºÐ¾ÑÑ‚ÑŒ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð³Ð¾ Ð²Ð¾ÐºÐ°Ð»Ð° (Ð¾Ñ‚ -20 Ð´Ð¾ 0)', required=False, default=0,
                           min_value=-20, max_value=0),
        back_vocal: Option(int, description='Ð“Ñ€Ð¾Ð¼ÐºÐ¾ÑÑ‚ÑŒ Ð±ÑÐºÐ²Ð¾ÐºÐ°Ð»Ð° (Ð¾Ñ‚ -20 Ð´Ð¾ 0)', required=False, default=0,
                           min_value=-20, max_value=0),
        music: Option(int, description='Ð“Ñ€Ð¾Ð¼ÐºÐ¾ÑÑ‚ÑŒ Ð¼ÑƒÐ·Ñ‹ÐºÐ¸ (Ð¾Ñ‚ -20 Ð´Ð¾ 0)', required=False, default=0, min_value=-20,
                      max_value=0),
        roomsize: Option(float, description='Ð Ð°Ð·Ð¼ÐµÑ€ Ð¿Ð¾Ð¼ÐµÑ‰ÐµÐ½Ð¸Ñ (Ð¾Ñ‚ 0 Ð´Ð¾ 1)', required=False, default=0.2, min_value=0,
                         max_value=1),
        wetness: Option(float, description='Ð’Ð»Ð°Ð¶Ð½Ð¾ÑÑ‚ÑŒ (Ð¾Ñ‚ 0 Ð´Ð¾ 1)', required=False, default=0.1, min_value=0,
                        max_value=1),
        dryness: Option(float, description='Ð¡ÑƒÑ…Ð¾ÑÑ‚ÑŒ (Ð¾Ñ‚ 0 Ð´Ð¾ 1)', required=False, default=0.85, min_value=0,
                        max_value=1)
):
    # Ð²Ñ‹ÐºÐ¸Ð´Ñ‹Ð²Ð°ÐµÐ¼ Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ
    config.read('config.ini')
    voices = config.get("Sound", "voices").replace("\"", "").replace(",", "").split(";")
    if voice not in voices:
        return await ctx.respond("Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð³Ð¾Ð»Ð¾Ñ Ð¸Ð· ÑÐ¿Ð¸ÑÐºÐ°: " + ','.join(voices))
    if await set_get_config_all("Image", "model_loaded", None) == "False":
        return await ctx.respond("Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ ÐºÐ°Ñ€Ñ‚Ð¸Ð½Ð¾Ðº Ð½Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ð»Ð°ÑÑŒ, Ð¿Ð¾Ð´Ð¾Ð¶Ð´Ð¸Ñ‚Ðµ 10-20 Ð¼Ð¸Ð½ÑƒÑ‚")
    if not video_path:
        return

    # Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð²Ð¸Ð´ÐµÐ¾ÐºÐ°Ñ€Ñ‚Ñ‹
    await use_cuda_async(0)

    await ctx.defer()
    # run timer
    start_time = datetime.datetime.now()
    # save
    filename = str(random.randint(1, 1000000)) + ".mp4"
    print(filename)
    await video_path.save(filename)
    # loading params
    await set_get_config_all(f"Image", "strength_negative_prompt", strength_negative_prompt)
    await set_get_config_all(f"Image", "strength_prompt", strength_prompt)
    await set_get_config_all(f"Image", "strength", strength)
    await set_get_config_all(f"Image", "seed", seed)
    await set_get_config_all(f"Image", "steps", steps)
    await set_get_config_all(f"Image", "negative_prompt", negative_prompt)
    print("params suc")
    # wait for answer
    from video_change import video_pipeline
    video_path = await video_pipeline(filename, fps, extension, prompt, voice, pitch,
                                      indexrate, loudness, main_vocal, back_vocal, music,
                                      roomsize, wetness, dryness)
    # count time
    end_time = datetime.datetime.now()
    spent_time = str(end_time - start_time)
    # ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ Ð¼Ð¸Ð»Ð»Ð¸ÑÐµÐºÑƒÐ½Ð´Ñ‹
    spent_time = spent_time[:spent_time.find(".")]
    # Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼
    await ctx.respond("Ð’Ð¾Ñ‚ ÐºÐ°Ðº Ñ Ð¸Ð·Ð¼ÐµÐ½Ð¸Ð» Ð²Ð°ÑˆÐµ Ð²Ð¸Ð´ÐµÐ¾ðŸ–Œ. ÐŸÐ¾Ñ‚Ñ€Ð°Ñ‡ÐµÐ½Ð¾ " + spent_time)
    await send_file(ctx, video_path)
    # Ð¾ÑÐ²Ð¾Ð±Ð¾Ð¶Ð´Ð°ÐµÐ¼ Ð²Ð¸Ð´ÐµÐ¾ÐºÐ°Ñ€Ñ‚Ñƒ
    await stop_use_cuda_async(0)


@bot.slash_command(name="change_image", description='Ð¸Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð½ÐµÐ¹Ñ€Ð¾ÑÐµÑ‚ÑŒÑŽ')
async def __image(ctx,
                  image: Option(discord.SlashCommandOptionType.attachment, description='Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ',
                                required=True),
                  # prompt=prompt, negative_prompt=negative_prompt, x=512, y=512, steps=50,
                  #                      seed=random.randint(1, 10000), strenght=0.5
                  prompt: Option(str, description='Ð·Ð°Ð¿Ñ€Ð¾Ñ', required=True),
                  negative_prompt: Option(str, description='Ð½ÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ', default="NSFW", required=False),
                  steps: Option(int, description='Ñ‡Ð¸ÑÐ»Ð¾ ÑˆÐ°Ð³Ð¾Ð²', required=False,
                                default=30,
                                min_value=1,
                                max_value=500),
                  seed: Option(int, description='ÑÐ¸Ð´ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ', required=False,
                               default=random.randint(1, 1000000),
                               min_value=1,
                               max_value=1000000),
                  x: Option(int,
                            description='Ð¸Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ñ€Ð°Ð·Ð¼ÐµÑ€ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐ¸ Ð¿Ð¾ x (Ð´Ð¾ 768*768)',
                            required=False,
                            default=None, min_value=64,
                            max_value=768),
                  y: Option(int,
                            description='Ð¸Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ñ€Ð°Ð·Ð¼ÐµÑ€ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐ¸ Ð¿Ð¾ y (Ð´Ð¾ 768*768)',
                            required=False,
                            default=None, min_value=64,
                            max_value=768),
                  strength: Option(float, description='Ð½Ð°ÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÐ¸Ð»ÑŒÐ½Ñ‹ Ð±ÑƒÐ´ÑƒÑ‚ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ', required=False,
                                   default=0.5, min_value=0,
                                   max_value=1),
                  strength_prompt: Option(float,
                                          description='Ð›Ð£Ð§Ð¨Ð• ÐÐ• Ð¢Ð ÐžÐ“ÐÐ¢Ð¬! ÐÐ°ÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÐ¸Ð»ÑŒÐ½Ð¾ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ÑÑ Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚',
                                          required=False,
                                          default=0.85, min_value=0,
                                          max_value=1),
                  strength_negative_prompt: Option(float,
                                                   description='Ð›Ð£Ð§Ð¨Ð• ÐÐ• Ð¢Ð ÐžÐ“ÐÐ¢Ð¬! ÐÐ°ÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÐ¸Ð»ÑŒÐ½Ð¾ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ÑÑ Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚',
                                                   required=False,
                                                   default=1, min_value=0,
                                                   max_value=1)
                  ):
    await use_cuda_async(0)
    await set_get_config_all(f"Image", "result", "None")
    await ctx.defer()
    # throw extensions
    if await set_get_config_all(f"Image", "model_loaded", None) == "False":
        return await ctx.respond("Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ ÐºÐ°Ñ€Ñ‚Ð¸Ð½Ð¾Ðº Ð½Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ð»Ð°ÑÑŒ, Ð¿Ð¾Ð´Ð¾Ð¶Ð´Ð¸Ñ‚Ðµ 10-20 Ð¼Ð¸Ð½ÑƒÑ‚")
    # run timer
    start_time = datetime.datetime.now()
    input_image = "images/image" + str(random.randint(1, 1000000)) + ".png"
    await image.save(input_image)
    # get image size and round to 64
    if x is None and y is None:
        x, y = await get_image_dimensions(input_image)
    if not x % 64 == 0:
        x = ((x // 64) + 1) * 64
    if not y % 64 == 0:
        y = ((y // 64) + 1) * 64
    # Ð²Ð¾ Ð¸Ð·Ð±ÐµÐ¶Ð°Ð½Ð¸Ñ Ð¾ÑˆÐ¸Ð±Ð¾Ðº Ð¸Ð·-Ð·Ð° Ð½ÐµÑ…Ð²Ð°Ñ‚ÐºÐ¸ Ð¿Ð°Ð¼ÑÑ‚Ð¸, Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ 768x768
    while x * y > 589824:
        if not x == 64:
            x -= 64
        if not y == 64:
            y -= 64
    # loading params
    await set_get_config_all(f"Image", "strength_negative_prompt", strength_negative_prompt)
    await set_get_config_all(f"Image", "strength_prompt", strength_prompt)
    await set_get_config_all(f"Image", "strength", strength)
    await set_get_config_all(f"Image", "seed", seed)
    await set_get_config_all(f"Image", "steps", steps)
    await set_get_config_all(f"Image", "negative_prompt", negative_prompt)
    await set_get_config_all(f"Image", "prompt", prompt)
    await set_get_config_all(f"Image", "x", x)
    await set_get_config_all(f"Image", "y", y)
    await set_get_config_all(f"Image", "input", input_image)
    print("params suc")
    # wait for answer
    while True:
        output_image = await set_get_config_all(f"Image", "result", None)
        if output_image == "None":
            break
        await asyncio.sleep(0.25)

    # count time
    end_time = datetime.datetime.now()
    spent_time = str(end_time - start_time)
    # ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ Ñ‡Ð°ÑÑ‹ Ð¸ Ð¼Ð¸Ð»Ð»Ð¸ÑÐµÐºÑƒÐ½Ð´Ñ‹
    spent_time = spent_time[spent_time.find(":") + 1:]
    spent_time = spent_time[:spent_time.find(".")]
    # Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼
    await ctx.respond("Ð’Ð¾Ñ‚ ÐºÐ°Ðº Ñ Ð¸Ð·Ð¼ÐµÐ½Ð¸Ð» Ð²Ð°ÑˆÐµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÐµðŸ–Œ. ÐŸÐ¾Ñ‚Ñ€Ð°Ñ‡ÐµÐ½Ð¾ " + spent_time)
    await send_file(ctx, output_image)
    # ÑƒÐ´Ð°Ð»ÑÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹
    os.remove(output_image)
    # Ð¿ÐµÑ€ÐµÑÑ‚Ð°Ñ‘Ð¼ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð²Ð¸Ð´ÐµÐ¾ÐºÐ°Ñ€Ñ‚Ñƒ
    await stop_use_cuda_async(0)


@bot.slash_command(name="config", description='Ð¸Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ ÐºÐ¾Ð½Ñ„Ð¸Ð³ (Ð»ÑƒÑ‡ÑˆÐµ Ð½Ðµ Ñ‚Ñ€Ð¾Ð³Ð°Ñ‚ÑŒ, ÐµÑÐ»Ð¸ Ð½Ðµ Ð·Ð½Ð°ÐµÑˆÑŒ!)')
async def __config(
        ctx,
        section: Option(str, description='ÑÐµÐºÑ†Ð¸Ñ', required=True),
        key: Option(str, description='ÐºÐ»ÑŽÑ‡', required=True),
        value: Option(str, description='Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ', required=False, default=None)
):
    await ctx.defer()
    await ctx.respond(await set_get_config_all(section, key, value))


@bot.slash_command(name="join", description='Ð¿Ñ€Ð¸ÑÐ¾ÐµÐ´Ð¸Ð½Ð¸Ñ‚ÑŒÑÑ Ðº Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð¼Ñƒ ÐºÐ°Ð½Ð°Ð»Ñƒ')
async def join(ctx):
    await ctx.defer()
    voice = ctx.author.voice
    if not voice:
        await ctx.respond(voiceChannelErrorText)
        return

    voice_channel = voice.channel

    if ctx.voice_client is not None:
        return await ctx.voice_client.move_to(voice_channel)

    await voice_channel.connect()
    await ctx.respond("Ð¿Ñ€Ð¸ÑÐ¾ÐµÐ´Ð¸Ð½ÑÑŽÑÑŒ")


@bot.slash_command(name="record", description='Ð²Ð¾ÑÐ¿Ñ€Ð¸Ð½Ð¸Ð¼Ð°Ñ‚ÑŒ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ Ð¸Ð· Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°')
async def record(ctx):  # if you're using commands.Bot, this will also work.
    voice = ctx.author.voice
    voice_channel = voice.channel
    # Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ»ÑŽÑ‡ Ðº connetions
    if ctx.guild.id not in connections:
        connections[ctx.guild.id] = []

    if not voice:
        return await ctx.respond(voiceChannelErrorText)

    if ctx.voice_client is None:
        # ÐµÑÐ»Ð¸ Ð±Ð¾Ñ‚Ð° ÐÐ•Ð¢ Ð² Ð²Ð¾Ð¹Ñ-Ñ‡Ð°Ñ‚Ðµ
        vc = await voice_channel.connect()
    else:
        # ÐµÑÐ»Ð¸ Ð±Ð¾Ñ‚ Ð£Ð–Ð• Ð² Ð²Ð¾Ð¹Ñ-Ñ‡Ð°Ñ‚Ðµ
        vc = ctx.voice_client
    # ÐµÑÐ»Ð¸ ÑƒÐ¶Ðµ Ð·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÑ‚
    if vc in connections[ctx.guild.id]:
        return await ctx.respond("Ð£Ð¶Ðµ Ð·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÑŽ Ð²Ð°Ñˆ Ð³Ð¾Ð»Ð¾ÑðŸŽ¤")
    stream_sink.set_user(ctx.author.id)
    connections[ctx.guild.id].append(vc)

    # ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ð·Ð°Ð¿Ð¸ÑÑŒ
    vc.start_recording(
        stream_sink,  # the sink type to use.
        once_done,  # what to do once done.
        ctx.channel  # the channel to disconnect from.
    )
    await set_get_config(value=True)
    await ctx.respond("Started listening.")
    await recognize(ctx)


@bot.slash_command(name="stop_recording", description='Ð¿ÐµÑ€ÐµÑÑ‚Ð°Ñ‚ÑŒ Ð²Ð¾ÑÐ¿Ñ€Ð¸Ð½Ð¸Ð¼Ð°Ñ‚ÑŒ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ Ð¸Ð· Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°')
async def stop_recording(ctx):
    if ctx.guild.id in connections:
        vc = connections[ctx.guild.id][0]  # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚ ÑÐ¿Ð¸ÑÐºÐ°
        vc.stop_recording()
        del connections[ctx.guild.id]
    else:
        await ctx.respond("Ð¯ Ð¸ Ñ‚Ð°Ðº Ñ‚ÐµÐ±Ñ Ð½Ðµ ÑÐ»ÑƒÑˆÐ°Ð» ._.")


@bot.slash_command(name="disconnect", description='Ð²Ñ‹Ð¹Ñ‚Ð¸ Ð¸Ð· Ð²Ð¾Ð¹Ñ-Ñ‡Ð°Ñ‚Ð°')
async def disconnect(ctx):
    await ctx.defer()
    voice = ctx.voice_client
    if voice:
        await voice.disconnect(force=True)
        await ctx.respond("Ð²Ñ‹Ñ…Ð¾Ð¶Ñƒ")
    else:
        await ctx.respond("Ð¯ Ð½Ðµ Ð² Ð²Ð¾Ð¹ÑÐµ")
    if ctx.guild.id in connections:
        del connections[ctx.guild.id]  # remove the guild from the cache.


# @bot.command(help="ÑÐºÐ°Ð·Ð°Ñ‚ÑŒ Ñ€Ð¾Ð±Ð¾Ñ‚Ñƒ Ñ‚ÐµÐºÑÑ‚")
# async def say(ctx, *args):
#     message = " ".join(args)
#     from function import replace_mat_in_sentence
#     if not default_settings.get("robot_name_need"):
#         message = default_settings.get("currentAIname") + ", " + message
#         print(message)
#     else:
#         print(message)
#     message = await replace_mat_in_sentence(message)
#     # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð»Ð¸ Ð°Ð²Ñ‚Ð¾Ñ€ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ Ð² Ð²Ð¾Ð¹Ñ-Ñ‡Ð°Ñ‚Ðµ
#     # if ctx.author.voice:
#     if True:
#         # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð²Ð¾Ð¹Ñ-ÐºÐ°Ð½Ð°Ð» Ð°Ð²Ñ‚Ð¾Ñ€Ð° ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹
#         # voice_channel = ctx.author.voice.channel
#         # # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð»Ð¸ Ð±Ð¾Ñ‚ ÑƒÐ¶Ðµ Ð² ÐºÐ°ÐºÐ¾Ð¼-Ð»Ð¸Ð±Ð¾ Ð²Ð¾Ð¹Ñ-Ñ‡Ð°Ñ‚Ðµ
#         # if ctx.voice_client is None:
#         #     # Ð•ÑÐ»Ð¸ Ð±Ð¾Ñ‚ Ð½Ðµ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð² Ð²Ð¾Ð¹Ñ-Ñ‡Ð°Ñ‚Ðµ, Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ ÐµÐ³Ð¾
#         #     await voice_channel.connect()
#         # else:
#         #     # Ð•ÑÐ»Ð¸ Ð±Ð¾Ñ‚ ÑƒÐ¶Ðµ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð² Ð²Ð¾Ð¹Ñ-Ñ‡Ð°Ñ‚Ðµ, Ð¿ÐµÑ€ÐµÐ¼ÐµÑ‰Ð°ÐµÐ¼ ÐµÐ³Ð¾ Ð² Ð½Ð¾Ð²Ñ‹Ð¹ Ð²Ð¾Ð¹Ñ-ÐºÐ°Ð½Ð°Ð»
#         #     await ctx.voice_client.move_to(voice_channel)
#         await run_main_with_settings(ctx, message, True)
#     else:
#         await ctx.send("Ð’Ñ‹ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑŒÑÑ Ð² Ð²Ð¾Ð¹Ñ-Ñ‡Ð°Ñ‚Ðµ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ ÑÑ‚Ñƒ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ.")


@bot.slash_command(name="pause", description='Ð¿Ð°ÑƒÐ·Ð°/Ð²Ð¾ÑÐ¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ')
async def pause(ctx):
    await ctx.defer()
    await ctx.respond('Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ...')
    voice_client = ctx.voice_client
    if voice_client.is_playing():
        voice_client.pause()
        await ctx.respond("ÐŸÐ°ÑƒÐ·Ð° â¸")
    elif voice_client.is_paused():
        voice_client.resume()
        await ctx.respond("ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ Ð²Ð¾ÑÐ¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ â–¶ï¸")
    else:
        await ctx.respond("ÐÐµÑ‚ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ð°ÑƒÐ´Ð¸Ð¾ Ð´Ð»Ñ Ð¿Ñ€Ð¸Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ¸ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ñ.")


@bot.slash_command(name="skip", description='Ð¿Ñ€Ð¾Ð¿ÑƒÑÐº Ð°ÑƒÐ´Ð¸Ð¾')
async def skip(ctx):
    await ctx.defer()
    await ctx.respond('Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ...')
    voice_client = ctx.voice_client
    if voice_client.is_playing():
        voice_client.stop()
        await ctx.respond("Ð¢ÐµÐºÑƒÑ‰Ð¸Ð¹ Ñ‚Ñ€ÐµÐº Ð¿Ñ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½ â­ï¸")
        await set_get_config("stop_milliseconds", 0)
    else:
        await ctx.respond("ÐÐµÑ‚ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ð°ÑƒÐ´Ð¸Ð¾ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°.")


@bot.slash_command(name="lenght", description='Ð”Ð»Ð¸Ð½Ð° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°')
async def __lenght(
        ctx,
        number: Option(int, description='Ð”Ð»Ð¸Ð½Ð° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð´Ð»Ñ GPT (Ð§Ð¸ÑÐ»Ð¾ Ð¾Ñ‚ 1 Ð´Ð¾ 1000)', required=True, min_value=1,
                       max_value=1000)
):
    await ctx.defer()
    await ctx.respond('Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ...')
    # for argument in (number,"""boolean, member, text, choice"""):
    print(f'{number} ({type(number).__name__})\n')
    await run_main_with_settings(ctx, f"Ñ€Ð¾Ð±Ð¾Ñ‚ Ð´Ð»Ð¸Ð½Ð° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° {number}", True)
    await ctx.respond(f"Ð”Ð»Ð¸Ð½Ð° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°: {number}")


@bot.slash_command(name="say", description='Ð¡ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ñ€Ð¾Ð±Ð¾Ñ‚Ñƒ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾')
async def __say(
        ctx,
        text: Option(str, description='Ð¡Ð°Ð¼ Ñ‚ÐµÐºÑÑ‚/ÐºÐ¾Ð¼Ð°Ð½Ð´Ð°. Ð¡Ð¿Ð¸ÑÐ¾Ðº ÐºÐ¾Ð¼Ð°Ð½Ð´: \\help-say', required=True)
):
    await ctx.respond('Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ...')
    from function import replace_mat_in_sentence
    if await set_get_config_default("robot_name_need") == "False":
        text = await set_get_config_default("currentainame") + ", " + text
    text = await replace_mat_in_sentence(text)
    print(f'{text} ({type(text).__name__})\n')
    await run_main_with_settings(ctx, text, True)


@bot.slash_command(name="tts", description='_Ð—Ð°ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ_ Ð±Ð¾Ñ‚Ð° Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚ÑŒ Ð²ÑÑ‘, Ñ‡Ñ‚Ð¾ Ð·Ð°Ñ…Ð¾Ñ‡ÐµÑˆÑŒ')
async def __tts(
        ctx,
        text: Option(str, description='Ð¢ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð¾Ð·Ð²ÑƒÑ‡ÐºÐ¸', required=True),
        ai_voice: Option(str, description='Ð“Ð¾Ð»Ð¾Ñ Ð´Ð»Ñ Ð¾Ð·Ð²ÑƒÑ‡ÐºÐ¸', required=False, default="None")
):
    await ctx.defer()
    await ctx.respond('Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ...')
    await use_cuda_async(0)
    config.read('config.ini')
    voices = config.get("Sound", "voices").replace("\"", "").replace(",", "").split(";")
    if ai_voice not in voices:
        return await ctx.respond("Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð³Ð¾Ð»Ð¾Ñ Ð¸Ð· ÑÐ¿Ð¸ÑÐºÐ°: " + ','.join(voices))
    from function import replace_mat_in_sentence, mat_found
    text = await replace_mat_in_sentence(text)
    if mat_found:
        await ctx.respond("Ð¢Ð°ÐºÐ¾Ðµ Ð½ÐµÐ»ÑŒÐ·Ñ Ð¿Ñ€Ð¾Ð¸Ð·Ð½Ð¾ÑÐ¸Ñ‚ÑŒ!")
        return
    print(f'{text} ({type(text).__name__})\n')
    # Ð¼ÐµÐ½ÑÐµÐ¼ Ð³Ð¾Ð»Ð¾Ñ
    ai_voice_temp = await set_get_config_default("currentainame")
    if ai_voice == "None":
        ai_voice = await set_get_config_default("currentainame")
        print(await set_get_config_default("currentainame"))
    await set_get_config_default("currentainame", ai_voice)
    # Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ TTS
    await run_main_with_settings(ctx, f"Ñ€Ð¾Ð±Ð¾Ñ‚ Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð» 24 {text}",
                                 False)  # await text_to_speech(text, False, ctx, ai_dictionary=ai_voice)
    # Ð²Ð¾Ð·Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð³Ð¾Ð»Ð¾Ñ
    await set_get_config_default("currentainame", ai_voice_temp)
    # Ð¿ÐµÑ€ÐµÑÑ‚Ð°Ñ‘Ð¼ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð²Ð¸Ð´ÐµÐ¾ÐºÐ°Ñ€Ñ‚Ñƒ
    await stop_use_cuda_async(0)


@bot.slash_command(name="ai_cover", description='_Ð—Ð°ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ_ Ð±Ð¾Ñ‚Ð° Ð¾Ð·Ð²ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð²Ð¸Ð´ÐµÐ¾/ÑÐ¿ÐµÑ‚ÑŒ Ð¿ÐµÑÐ½ÑŽ')
async def __cover(
        ctx,
        url: Option(str, description='Ð¡ÑÑ‹Ð»ÐºÐ° Ð½Ð° Ð²Ð¸Ð´ÐµÐ¾', required=False, default=None),
        audio_path: Option(discord.SlashCommandOptionType.attachment, description='ÐÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð»',
                           required=False, default=None),
        voice: Option(str, description='Ð“Ð¾Ð»Ð¾Ñ Ð´Ð»Ñ Ð²Ð¸Ð´ÐµÐ¾', required=False, default=None),
        pitch: Option(str, description='ÐšÑ‚Ð¾ Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚/Ð¿Ð¾Ñ‘Ñ‚ Ð² Ð²Ð¸Ð´ÐµÐ¾?', required=False,
                      choices=['Ð¼ÑƒÐ¶Ñ‡Ð¸Ð½Ð°', 'Ð¶ÐµÐ½Ñ‰Ð¸Ð½Ð°'], default=None),
        time: Option(int, description='ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ñ‚ÑŒ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð²Ð¾ÑÐ¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ñ (Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ…)', required=False,
                     default=-1, min_value=0),
        indexrate: Option(float, description='Ð˜Ð½Ð´ÐµÐºÑ Ð³Ð¾Ð»Ð¾ÑÐ° (Ð¾Ñ‚ 0 Ð´Ð¾ 1)', required=False, default=0.5, min_value=0,
                          max_value=1),
        loudness: Option(float, description='Ð“Ñ€Ð¾Ð¼ÐºÐ¾ÑÑ‚ÑŒ ÑˆÑƒÐ¼Ð° (Ð¾Ñ‚ 0 Ð´Ð¾ 1)', required=False, default=0.2, min_value=0,
                         max_value=1),
        main_vocal: Option(int, description='Ð“Ñ€Ð¾Ð¼ÐºÐ¾ÑÑ‚ÑŒ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð³Ð¾ Ð²Ð¾ÐºÐ°Ð»Ð° (Ð¾Ñ‚ -20 Ð´Ð¾ 0)', required=False, default=0,
                           min_value=-20, max_value=0),
        back_vocal: Option(int, description='Ð“Ñ€Ð¾Ð¼ÐºÐ¾ÑÑ‚ÑŒ Ð±ÑÐºÐ²Ð¾ÐºÐ°Ð»Ð° (Ð¾Ñ‚ -20 Ð´Ð¾ 0)', required=False, default=0,
                           min_value=-20, max_value=0),
        music: Option(int, description='Ð“Ñ€Ð¾Ð¼ÐºÐ¾ÑÑ‚ÑŒ Ð¼ÑƒÐ·Ñ‹ÐºÐ¸ (Ð¾Ñ‚ -20 Ð´Ð¾ 0)', required=False, default=0, min_value=-20,
                      max_value=0),
        roomsize: Option(float, description='Ð Ð°Ð·Ð¼ÐµÑ€ Ð¿Ð¾Ð¼ÐµÑ‰ÐµÐ½Ð¸Ñ (Ð¾Ñ‚ 0 Ð´Ð¾ 1)', required=False, default=0.2, min_value=0,
                         max_value=1),
        wetness: Option(float, description='Ð’Ð»Ð°Ð¶Ð½Ð¾ÑÑ‚ÑŒ (Ð¾Ñ‚ 0 Ð´Ð¾ 1)', required=False, default=0.1, min_value=0,
                        max_value=1),
        dryness: Option(float, description='Ð¡ÑƒÑ…Ð¾ÑÑ‚ÑŒ (Ð¾Ñ‚ 0 Ð´Ð¾ 1)', required=False, default=0.85, min_value=0,
                        max_value=1),
        start: Option(int, description='ÐÐ°Ñ‡Ð°Ñ‚ÑŒ Ð²Ð¾ÑÐ¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÑŒ Ñ (Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ…)', required=False, default=0, min_value=0),
        output: Option(bool, description='ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð² Ð°Ñ€Ñ…Ð¸Ð²Ðµ', required=False, default=False)
):
    await ctx.defer()
    await ctx.respond('Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ...')
    params = []
    if audio_path:
        filename = str(random.randint(1, 1000000)) + ".mp3"
        await audio_path.save(filename)
        params.append(f"-url {filename}")
    elif url:
        params.append(f"-url {url}")
    else:
        return ctx.respond('ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ð° ÑÑÑ‹Ð»ÐºÐ° Ð¸Ð»Ð¸ Ð°ÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð»')
    if voice is None:
        voice = await set_get_config_default("currentAIname")
    if voice:
        params.append(f"-voice {voice}")
    # ÐµÑÐ»Ð¸ Ð¼ÑƒÐ¶Ñ‡Ð¸Ð½Ð°-Ð¼ÑƒÐ¶Ñ‡Ð¸Ð½Ð°, Ð¶ÐµÐ½Ñ‰Ð¸Ð½Ð°-Ð¶ÐµÐ½Ñ‰Ð¸Ð½Ð°, pitch Ð½Ðµ Ð¼ÐµÐ½ÑÐµÐ¼
    pitch_int = 0
    # ÐµÑÐ»Ð¸ Ð¶ÐµÐ½Ñ‰Ð¸Ð½Ð°, Ð½Ð¾ AI Ð¼ÑƒÐ¶Ñ‡Ð¸Ð½Ð° = 1,
    if pitch == 'Ð¶ÐµÐ½Ñ‰Ð¸Ð½Ð°':
        if not await set_get_config_default("currentaipitch") == 1:
            pitch_int = 1
    # ÐµÑÐ»Ð¸ Ð¼ÑƒÐ¶Ñ‡Ð¸Ð½Ð°, Ð½Ð¾ AI Ð¶ÐµÐ½Ñ‰Ð¸Ð½Ð° = -1,
    elif pitch == 'Ð¼ÑƒÐ¶Ñ‡Ð¸Ð½Ð°':
        if not await set_get_config_default("currentaipitch") == 0:
            pitch_int = -1
    params.append(f"-pitch {pitch_int}")
    if time != -1:
        params.append(f"-time {time}")
    if indexrate != 0.5:
        params.append(f"-indexrate {indexrate}")
    if loudness != 0.2:
        params.append(f"-loudness {loudness}")
    if main_vocal != 0:
        params.append(f"-vocal {main_vocal}")
    if back_vocal != 0:
        params.append(f"-bvocal {back_vocal}")
    if music != 0:
        params.append(f"-music {music}")
    if roomsize != 0.2:
        params.append(f"-roomsize {roomsize}")
    if wetness != 0.1:
        params.append(f"-wetness {wetness}")
    if dryness != 0.85:
        params.append(f"-dryness {dryness}")
    if start != 0:
        params.append(f"-start {start}")
    param_string = ' '.join(params)
    print("suc params")
    await run_main_with_settings(ctx, "Ñ€Ð¾Ð±Ð¾Ñ‚ Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð» 13 " + param_string, False)
    # output..


@bot.slash_command(name="add_voice", description='Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ RVC Ð³Ð¾Ð»Ð¾Ñ')
async def __add_voice(
        ctx,
        url: Option(str, description='Ð¡ÑÑ‹Ð»ÐºÐ° Ð½Ð° .zip Ñ„Ð°Ð¹Ð» Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒÑŽ RVC', required=True),
        name: Option(str, description=f'Ð˜Ð¼Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸', required=True),
        gender: Option(str, description=f'ÐŸÐ¾Ð» (Ð´Ð»Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ñ‚Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸)', required=True,
                       choices=['Ð¼ÑƒÐ¶Ñ‡Ð¸Ð½Ð°', 'Ð¶ÐµÐ½Ñ‰Ð¸Ð½Ð°']),
        info: Option(str, description=f'(Ð½ÐµÐ¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾) ÐšÐ°ÐºÐ¸Ðµ-Ñ‚Ð¾ ÑÐ²ÐµÐ´ÐµÐ½Ð¸Ñ Ð¾ Ð´Ð°Ð½Ð½Ð¾Ð¼ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐµ', required=False,
                     default="ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚"),
        change_voice: Option(bool, description=f'(Ð½ÐµÐ¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾) Ð˜Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð³Ð¾Ð»Ð¾Ñ Ð½Ð° ÑÑ‚Ð¾Ñ‚', required=False,
                             default=False)
):
    await ctx.defer()
    await ctx.defer()
    await ctx.respond('Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ...')
    if name == "None" or ";" in name or "/" in name or "\\" in name:
        await ctx.respond('Ð˜Ð¼Ñ Ð½Ðµ Ð´Ð¾Ð»Ð¶Ð½Ð¾ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ \";\" \"/\" \"\\\" Ð¸Ð»Ð¸ Ð±Ñ‹Ñ‚ÑŒ None')
    # !python download_model_with_link_AICoverGen.py {url} {dir_name} {gender} {info}
    command = None
    if gender == "Ð¶ÐµÐ½Ñ‰Ð¸Ð½Ð°":
        gender = "female"
    elif gender == "Ð¼ÑƒÐ¶Ñ‡Ð¸Ð½Ð°":
        gender = "male"
    else:
        gender = "male"
    try:
        command = [
            "python",
            "download_model_with_link_AICoverGen.py",
            url,
            name,
            gender,
            info
        ]
        subprocess.run(command, check=True)
        config.read('config.ini')
        voices = config.get("Sound", "voices").split(";")
        voices.append(name)
        config.set('Sound', "voices", ';'.join(voices))
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ
        with open('config.ini', 'w') as configfile:
            config.write(configfile)
        if change_voice:
            await run_main_with_settings(ctx, f"Ñ€Ð¾Ð±Ð¾Ñ‚ Ð¸Ð·Ð¼ÐµÐ½Ð¸ Ð³Ð¾Ð»Ð¾Ñ Ð½Ð° {name}", True)
    except subprocess.CalledProcessError as e:
        await ctx.respond(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ð¸ Ð³Ð¾Ð»Ð¾ÑÐ° {command}: {e}")


@bot.command(aliases=['cmd'], help="ÐºÐ¾Ð¼Ð°Ð½Ð´Ð½Ð°Ñ ÑÑ‚Ñ€Ð¾ÐºÐ°")
async def command_line(ctx, *args):
    text = " ".join(args)
    print("command line:", text)
    try:
        process = subprocess.Popen(text, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)
        stdout, stderr = process.communicate()
        for line in stdout.decode().split('\n'):
            if line.strip():
                await ctx.send(line)
        for line in stderr.decode().split('\n'):
            if line.strip():
                await ctx.send(line)
    except subprocess.CalledProcessError as e:
        await ctx.send(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹: {e}")
    except Exception as e:
        await ctx.send(f"ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°: {e}")


async def run_main_with_settings(ctx, spokenText, writeAnswer):
    from function import start_bot
    await start_bot(ctx, spokenText, writeAnswer)


async def write_in_discord(ctx, text):
    # await run_main_with_settings(ctx, text, True
    if text == "":
        text = "ÐžÑˆÐ¸Ð±ÐºÐ°. Ð•ÑÐ»Ð¸ Ð²Ñ‹ Ð¿Ñ‹Ñ‚Ð°ÐµÑ‚ÐµÑÑŒ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ ÑÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð±Ð¾Ñ‚Ñƒ, Ð¿Ð¾Ð²Ñ‹ÑÑŒÑ‚Ðµ Ð´Ð»Ð¸Ð½Ñƒ Ð¾Ñ‚Ð²ÐµÑ‚Ð° ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¾Ð¹ /lenght"
    await ctx.send(text)


async def send_file(ctx, file_path):
    try:
        await ctx.send(file=discord.File(file_path))
    except FileNotFoundError:
        await ctx.send('Ð¤Ð°Ð¹Ð» Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½.')
    except discord.HTTPException:
        await ctx.send('ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐµ Ñ„Ð°Ð¹Ð»Ð°.')


async def playSoundFileDiscord(ctx, audio_file_path, duration, start_seconds):
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð»Ð¸ Ð±Ð¾Ñ‚ Ð² Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð¼ ÐºÐ°Ð½Ð°Ð»Ðµ
    if not ctx.voice_client:
        await ctx.send("Ð‘Ð¾Ñ‚ Ð½Ðµ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð² Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð¼ ÐºÐ°Ð½Ð°Ð»Ðµ. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ `join`, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ñ€Ð¸ÑÐ¾ÐµÐ´Ð¸Ð½Ð¸Ñ‚ÑŒ ÐµÐ³Ð¾.")
        return

    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ð¸Ð³Ñ€Ð°ÐµÑ‚ Ð»Ð¸ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ ÑƒÐ¶Ðµ
    if ctx.voice_client.is_playing():
        await asyncio.sleep(0.1)

    # Ð¿Ñ€Ð¾Ð¸Ð³Ñ€Ñ‹Ð²Ð°ÐµÐ¼
    source = discord.FFmpegPCMAudio(audio_file_path, options=f"-ss {start_seconds} -t {duration}")
    ctx.voice_client.play(source)

    # ÐžÐ¶Ð¸Ð´Ð°ÐµÐ¼ Ð¾ÐºÐ¾Ð½Ñ‡Ð°Ð½Ð¸Ñ Ð¿Ñ€Ð¾Ð¸Ð³Ñ€Ñ‹Ð²Ð°Ð½Ð¸Ñ
    while ctx.voice_client.is_playing():
        await asyncio.sleep(1)
        # stop_milliseconds += 1000
        await set_get_config("stop_milliseconds", int(await set_get_config("stop_milliseconds")) + 1000)


async def once_done(sink: discord.sinks, channel: discord.TextChannel, *args):
    await set_get_config(value=False)
    # await sink.vc.disconnect()  # disconnect from the voice channel.
    print("Stopped listening.")


file_not_found_in_raw = 0


async def recognize(ctx):
    global file_not_found_in_raw
    wav_filename = "out_all.wav"
    recognizer = sr.Recognizer()
    while True:
        # Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ñ‘Ð¼, Ð¿Ð¾ÐºÐ° Ð½Ðµ Ð¿Ñ€Ð¾Ð¸Ð·Ð¾Ð¹Ð´Ñ‘Ñ‚ once_done
        if await set_get_config() == "False":
            print("Stopped listening2.")
            return
        file_found = None
        # Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²
        for filename in os.listdir(os.getcwd()):
            if filename.startswith("output") and filename.endswith(".wav"):
                file_found = filename
                break
        if file_found is None:
            await asyncio.sleep(0.1)
            file_not_found_in_raw += 1
            # ÐµÑÐ»Ð¸ Ð´Ð¾Ð»Ð³Ð¾ Ð½Ðµ Ð±Ñ‹Ð»Ð¾ Ñ„Ð°Ð¹Ð»Ð¾Ð² (Ñ‡ÐµÐ»Ð¾Ð²ÐµÐº Ð¿ÐµÑ€ÐµÑÑ‚Ð°Ð» Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚ÑŒ)
            if file_not_found_in_raw > float(await set_get_config("delay_record")) * 10:
                text = None
                # Ð¾Ñ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ð¿Ð¾Ñ‚Ð¾Ðº
                stream_sink.cleanup()
                file_not_found_in_raw = 0
                # Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð¸Ðµ Ñ€ÐµÑ‡Ð¸
                try:
                    with sr.AudioFile(wav_filename) as source:
                        audio_data = recognizer.record(source)
                        text = recognizer.recognize_google(audio_data, language="ru-RU")
                except sr.UnknownValueError:
                    pass
                except sr.RequestError as e:
                    print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ð¸: {e}")
                # ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ðµ out_all.wav
                try:
                    Path(wav_filename).unlink()
                except FileNotFoundError:
                    pass

                # ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿ÑƒÑÑ‚Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð°
                empty_audio = AudioSegment.silent(duration=0)
                try:
                    empty_audio.export(wav_filename, format="wav")
                except Exception as e:
                    print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ Ð¿ÑƒÑÑ‚Ð¾Ð³Ð¾ Ð°ÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð»Ð°: {e}")
                # Ð²Ñ‹Ð·Ð¾Ð² function
                if not text is None:
                    from function import replace_mat_in_sentence, replace_numbers_in_sentence
                    text = await replace_numbers_in_sentence(text)
                    text = await replace_mat_in_sentence(text)
                    print(text)
                    await run_main_with_settings(ctx, "Ñ€Ð¾Ð±Ð¾Ñ‚, " + text, True)

            continue
        result = AudioSegment.from_file(wav_filename, format="wav") + AudioSegment.from_file(file_found, format="wav")
        try:
            result.export(wav_filename, format="wav")
        except Exception as e:
            print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ðµ Ð°ÑƒÐ´Ð¸Ð¾: {e}")
        print("recognize_saved")
        # ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð°
        try:
            Path(file_found).unlink()
        except FileNotFoundError:
            pass
    print("Stop_Recording")


async def get_image_dimensions(file_path):
    with open(file_path, 'rb') as file:
        data = file.read(24)

    if data.startswith(b'\x89PNG\r\n\x1a\n'):
        return struct.unpack('>ii', data[16:24])
    elif data[:6] in (b'GIF87a', b'GIF89a') and data[10:12] == b'\x00\x00':
        return struct.unpack('<HH', data[6:10])
    elif data.startswith(b'\xff\xd8\xff\xe0') and data[6:10] == b'JFIF':
        return struct.unpack('>H', data[7:9])[0], struct.unpack('>H', data[9:11])[0]
    elif data.startswith(b'\xff\xd8\xff\xe1') and data[6:10] == b'Exif':
        return struct.unpack('<HH', data[10:14])[0], struct.unpack('<HH', data[14:18])[0]
    else:
        raise ValueError("Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ÑÑ")


if __name__ == "__main__":
    print("update 2")
    try:

        # === args ===

        arguments = sys.argv

        if len(arguments) > 1:
            discord_token = arguments[1]
            # load models? (img, gpt, all)
            load_gpt = False
            load_images = False
            if len(arguments) > 2:
                wait_for_load_moders = arguments[2]
                if wait_for_load_moders == "all":
                    load_gpt = True
                    load_images = True
                if wait_for_load_moders == "gpt":
                    load_gpt = True
                if wait_for_load_moders == "img":
                    load_images = True
        else:
            # raise error & exit
            print("Ð£ÐºÐ°Ð¶Ð¸Ñ‚Ðµ discord_TOKEN")
            exit(-1)
        # === load models ===
        # == load gpt ==
        if load_gpt:
            print("load gpt model")
            from GPT_runner import run

            pool = multiprocessing.Pool(processes=1)
            pool.apply_async(run)
            pool.close()

            while True:
                time.sleep(0.5)
                config.read('config.ini')
                if config.getboolean("gpt", "gpt"):
                    break

        # == load images ==
        if load_images:
            print("load image model")

            from image_create_cuda0 import generate_picture

            pool = multiprocessing.Pool(processes=1)
            pool.apply_async(generate_picture)
            pool.close()
            while True:
                time.sleep(0.5)
                config.read('config.ini')
                if config.getboolean("Image", "model_loaded"):
                    break
        # ==== load bot ====
        print("====load bot====")
        bot.run(discord_token)
    except Exception as e:
        print(f"ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ°: {e}")
