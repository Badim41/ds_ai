import datetime
import multiprocessing
import os
import random
import re
import subprocess
import asyncio
import time
import traceback

from pytube import Playlist

from PIL import Image
from pydub import AudioSegment
from moviepy.editor import VideoFileClip

from discord import Option
from modifed_sinks import StreamSink
import speech_recognition as sr
from pathlib import Path
import sys
import discord
from discord.ext import commands
from use_free_cuda import use_cuda_async, stop_use_cuda_async, use_cuda_images, check_cuda_images, \
    stop_use_cuda_images
from set_get_config import set_get_config_all, set_get_config_all_not_async

# –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
voiceChannelErrorText = '‚ùó –í—ã –¥–æ–ª–∂–Ω—ã –Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤ –≥–æ–ª–æ—Å–æ–≤–æ–º –∫–∞–Ω–∞–ª–µ ‚ùó'

connections = {}

stream_sink = StreamSink()

intents = discord.Intents.all()
bot = commands.Bot(command_prefix='\\', intents=intents)


@bot.event
async def on_ready():
    print('Status: online')
    await bot.change_presence(activity=discord.Activity(
        type=discord.ActivityType.listening, name='AI-covers'))


@bot.event
async def on_message(message):
    # minecraft chat bot
    if message.author.id == 1165023027847757836:
        text = message.content
        ctx = await bot.get_context(message)
        from function import replace_mat_in_sentence

        if await set_get_config_all("Default", "robot_name_need") == "False":
            text = await set_get_config_all("Default", "currentainame") + ", " + text
        text = await replace_mat_in_sentence(text)
        user = text[:text.find(":")]
        if "[" in text and "]" in text:
            text = re.sub(r'[.*?]', '', text)
        await set_get_config_all("Default", "user_name", value=user)
        # info
        info_was = await set_get_config_all("Default", "currentaiinfo")
        await set_get_config_all("Default", "currentaiinfo",
                                 "–¢—ã —Å–µ–π—á–∞—Å –∏–≥—Ä–∞–µ—à—å –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ –º–∞–π–Ω–∫—Ä–∞—Ñ—Ç GoldenFire –∏ –æ—Ç–≤–µ—á–∞–µ—à—å –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–≥—Ä–æ–∫–æ–≤ –∏–∑ —á–∞—Ç–∞")
        await run_main_with_settings(ctx, text, True)
        # info2
        await set_get_config_all("Default", "currentaiinfo", info_was)
        return

    # other users
    if message.author.bot:
        return
    if bot.user in message.mentions:
        text = message.content
        ctx = await bot.get_context(message)
        try:
            # –ø–æ–ª—É—á–µ–Ω–∏–µ, –Ω–∞ –∫–∞–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∏–ª–∏
            if message.reference:
                referenced_message = await message.channel.fetch_message(message.reference.message_id)
                reply_on_message = referenced_message.content
                if "||" in reply_on_message:
                    reply_on_message = re.sub(r'\|\|.*?\|\|', '', reply_on_message)
                text += f" (–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–∞—à–µ —Å–æ–æ–±—â–µ–Ω–∏–µ \"{reply_on_message}\")"
            from function import replace_mat_in_sentence
            if await set_get_config_all("Default", "robot_name_need") == "False":
                text = await set_get_config_all("Default", "currentainame") + ", " + text
            text = await replace_mat_in_sentence(text)
            await set_get_config_all("Default", "user_name", value=message.author)
            await run_main_with_settings(ctx, text, True)
        except Exception as e:
            traceback_str = traceback.format_exc()
            print(str(traceback_str))
            await ctx.send(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–º–∞–Ω–¥–µ say —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ {message}: {e}")
    await bot.process_commands(message)


@bot.slash_command(name="change_video",
                   description='–ø–µ—Ä–µ—Ä–∏—Å–æ–≤–∞—Ç—å –∏ –ø–µ—Ä–µ–æ–∑–≤—É—á–∏—Ç—å –≤–∏–¥–µ–æ. –ë–æ—Ç —Ç–∞–∫–∂–µ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç –≤–∞–º –Ω–∞–∑–≤–∞–Ω–∏–µ')
async def __change_video(
        ctx,
        video_path: Option(discord.SlashCommandOptionType.attachment, description='–§–∞–π–ª —Å –≤–∏–¥–µ–æ',
                           required=True),
        fps: Option(int, description='–ß–∞—Å—Ç–æ—Ç–∞ –∫–∞–¥—Ä–æ–≤ (–û–ß–ï–ù–¨ –≤–ª–∏—è–µ—Ç –Ω–∞ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è))', required=True,
                    choices=[30, 15, 10, 6, 5, 3, 2, 1]),
        extension: Option(str, description='–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ (—Å–∏–ª—å–Ω–æ –≤–ª–∏—è–µ—Ç –Ω–∞ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è)', required=True,
                          choices=["144p", "240p", "360p", "480p", "720p"]),
        prompt: Option(str, description='–∑–∞–ø—Ä–æ—Å', required=True),
        negative_prompt: Option(str, description='–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å', default="NSFW", required=False),
        steps: Option(int, description='—á–∏—Å–ª–æ —à–∞–≥–æ–≤', required=False,
                      default=30,
                      min_value=1,
                      max_value=500),
        seed: Option(int, description='—Å–∏–¥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è', required=False,
                     default=random.randint(1, 1000000),
                     min_value=1,
                     max_value=1000000),
        strength: Option(float, description='–Ω–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω—ã –±—É–¥—É—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è', required=False,
                         default=0.15, min_value=0,
                         max_value=1),
        strength_prompt: Option(float,
                                description='–õ–£–ß–®–ï –ù–ï –¢–†–û–ì–ê–¢–¨! –ù–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç',
                                required=False,
                                default=0.85, min_value=0,
                                max_value=1),
        strength_negative_prompt: Option(float,
                                         description='–õ–£–ß–®–ï –ù–ï –¢–†–û–ì–ê–¢–¨! –ù–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç',
                                         required=False,
                                         default=1, min_value=0,
                                         max_value=1),
        voice: Option(str, description='–ì–æ–ª–æ—Å –¥–ª—è –≤–∏–¥–µ–æ', required=False, default="None"),
        pitch: Option(str, description='–ö—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç/–ø–æ—ë—Ç –≤ –≤–∏–¥–µ–æ?', required=False,
                      choices=['–º—É–∂—á–∏–Ω–∞', '–∂–µ–Ω—â–∏–Ω–∞'], default=None),
        indexrate: Option(float, description='–ò–Ω–¥–µ–∫—Å –≥–æ–ª–æ—Å–∞ (–æ—Ç 0 –¥–æ 1)', required=False, default=0.5, min_value=0,
                          max_value=1),
        loudness: Option(float, description='–ì—Ä–æ–º–∫–æ—Å—Ç—å —à—É–º–∞ (–æ—Ç 0 –¥–æ 1)', required=False, default=0.2, min_value=0,
                         max_value=1),
        main_vocal: Option(int, description='–ì—Ä–æ–º–∫–æ—Å—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –≤–æ–∫–∞–ª–∞ (–æ—Ç -20 –¥–æ 0)', required=False, default=0,
                           min_value=-20, max_value=0),
        back_vocal: Option(int, description='–ì—Ä–æ–º–∫–æ—Å—Ç—å –±—ç–∫–≤–æ–∫–∞–ª–∞ (–æ—Ç -20 –¥–æ 0)', required=False, default=0,
                           min_value=-20, max_value=0),
        music: Option(int, description='–ì—Ä–æ–º–∫–æ—Å—Ç—å –º—É–∑—ã–∫–∏ (–æ—Ç -20 –¥–æ 0)', required=False, default=0, min_value=-20,
                      max_value=0),
        roomsize: Option(float, description='–†–∞–∑–º–µ—Ä –ø–æ–º–µ—â–µ–Ω–∏—è (–æ—Ç 0 –¥–æ 1)', required=False, default=0.2, min_value=0,
                         max_value=1),
        wetness: Option(float, description='–í–ª–∞–∂–Ω–æ—Å—Ç—å (–æ—Ç 0 –¥–æ 1)', required=False, default=0.1, min_value=0,
                        max_value=1),
        dryness: Option(float, description='–°—É—Ö–æ—Å—Ç—å (–æ—Ç 0 –¥–æ 1)', required=False, default=0.85, min_value=0,
                        max_value=1)
):
    cuda_numbers = None
    try:
        # –æ—à–∏–±–∫–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        await ctx.defer()

        voices = (await set_get_config_all("Sound", "voices")).replace("\"", "").replace(",", "").split(";")
        if voice not in voices:
            await ctx.respond("–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å –∏–∑ —Å–ø–∏—Å–∫–∞: " + ','.join(voices))
            return
        if await set_get_config_all(f"Image0", "model_loaded", None) == "False":
            await ctx.respond("–º–æ–¥–µ–ª—å –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–æ–∫ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return
        if not video_path:
            return
        # –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—ã
        cuda_avaible = await check_cuda_images()
        if cuda_avaible == 0:
            await ctx.respond("–ù–µ—Ç —Å–≤–æ–±–æ–¥–Ω—ã—Ö –≤–∏–¥–µ–æ–∫–∞—Ä—Ç")
            return
        else:
            await ctx.respond(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {cuda_avaible} –≤–∏–¥–µ–æ–∫–∞—Ä—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ")

        cuda_numbers = []
        for i in range(cuda_avaible):
            cuda_numbers.append(await use_cuda_images())

        # run timer
        start_time = datetime.datetime.now()
        # save
        filename = str(random.randint(1, 1000000)) + ".mp4"
        print(filename)
        await video_path.save(filename)
        # —Å–∫–æ–ª—å–∫–æ –∫–∞–¥—Ä–æ–≤ –±—É–¥–µ—Ç –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
        video_clip = VideoFileClip(filename)
        total_frames = int((video_clip.fps * video_clip.duration) / (30 / fps))
        max_frames = int(await set_get_config_all("Video", "max_frames", None))
        if max_frames <= total_frames:
            await ctx.send(
                f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∫–∞–¥—Ä–æ–≤, —Å–Ω–∏–∑—å—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä FPS! –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –≤ –≤–∏–¥–µ–æ: {max_frames}. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ —É –≤–∞—Å - {total_frames}")
            for i in cuda_numbers:
                await stop_use_cuda_async(i)
            return
        else:
            # –Ω–∞ kaggle —Ç—Ä–∞—Ç–∏—Ç—Å—è –æ–∫–æ–ª–æ 13 —Å–µ–∫—É–Ω–¥, –Ω–∞ –∫–æ–ª–∞–± - 16
            if len(cuda_numbers) > 1:
                seconds = total_frames * 13 / len(cuda_numbers)
            else:
                seconds = total_frames * 16
            if seconds >= 3600:
                hours = seconds // 3600
                minutes = (seconds % 3600) // 60
                remaining_seconds = seconds % 60
                if minutes == 0 and remaining_seconds == 0:
                    time_spend = f"{hours} —á–∞—Å–æ–≤"
                elif remaining_seconds == 0:
                    time_spend = f"{hours} —á–∞—Å–æ–≤, {minutes} –º–∏–Ω—É—Ç"
                elif minutes == 0:
                    time_spend = f"{hours} —á–∞—Å–æ–≤, {remaining_seconds} —Å–µ–∫—É–Ω–¥"
                else:
                    time_spend = f"{hours} —á–∞—Å–æ–≤, {minutes} –º–∏–Ω—É—Ç, {remaining_seconds} —Å–µ–∫—É–Ω–¥"
            elif seconds >= 60:
                minutes = seconds // 60
                remaining_seconds = seconds % 60
                if remaining_seconds == 0:
                    time_spend = f"{minutes} –º–∏–Ω—É—Ç"
                else:
                    time_spend = f"{minutes} –º–∏–Ω—É—Ç, {remaining_seconds} —Å–µ–∫—É–Ω–¥"
            else:
                time_spend = f"{seconds} —Å–µ–∫—É–Ω–¥"
            await ctx.send(f"–í–∏–¥–µ–æ –±—É–¥–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è ~{time_spend}")
        # loading params
        for i in cuda_numbers:
            await set_get_config_all(f"Image{i}", "strength_negative_prompt", strength_negative_prompt)
            await set_get_config_all(f"Image{i}", "strength_prompt", strength_prompt)
            await set_get_config_all(f"Image{i}", "strength", strength)
            await set_get_config_all(f"Image{i}", "seed", seed)
            await set_get_config_all(f"Image{i}", "steps", steps)
            await set_get_config_all(f"Image{i}", "negative_prompt", negative_prompt)
        print("params suc")
        # wait for answer
        from video_change import video_pipeline
        video_path = await video_pipeline(filename, fps, extension, prompt, voice, pitch,
                                          indexrate, loudness, main_vocal, back_vocal, music,
                                          roomsize, wetness, dryness, cuda_numbers)
        # count time
        end_time = datetime.datetime.now()
        spent_time = str(end_time - start_time)
        # —É–±–∏—Ä–∞–µ–º –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
        spent_time = spent_time[:spent_time.find(".")]
        # –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º
        await ctx.send("–í–æ—Ç –∫–∞–∫ —è –∏–∑–º–µ–Ω–∏–ª –≤–∞—à–µ –≤–∏–¥–µ–æüñå. –ü–æ—Ç—Ä–∞—á–µ–Ω–æ " + spent_time)
        await send_file(ctx, video_path)
        # –æ—Å–≤–æ–±–æ–∂–¥–∞–µ–º –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—ã
        for i in cuda_numbers:
            await stop_use_cuda_images(i)
    except Exception as e:
        await ctx.send(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏ (—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\
                          {fps, extension, prompt, negative_prompt, steps, seed, strength, strength_prompt, voice, pitch, indexrate, loudness, main_vocal, back_vocal, music, roomsize, wetness, dryness}\
                          ): {e}")
        if cuda_numbers:
            for i in range(cuda_avaible):
                await stop_use_cuda_images(i)
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        raise e


@bot.slash_command(name="change_image", description='–∏–∑–º–µ–Ω–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é')
async def __image(ctx,
                  image: Option(discord.SlashCommandOptionType.attachment, description='–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ',
                                required=True),
                  # prompt=prompt, negative_prompt=negative_prompt, x=512, y=512, steps=50,
                  #                      seed=random.randint(1, 10000), strenght=0.5
                  prompt: Option(str, description='–∑–∞–ø—Ä–æ—Å', required=True),
                  negative_prompt: Option(str, description='–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å', default="NSFW", required=False),
                  steps: Option(int, description='—á–∏—Å–ª–æ —à–∞–≥–æ–≤', required=False,
                                default=60,
                                min_value=1,
                                max_value=500),
                  seed: Option(int, description='—Å–∏–¥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è', required=False,
                               default=None,
                               min_value=1,
                               max_value=9007199254740991),
                  x: Option(int,
                            description='–∏–∑–º–µ–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∫–∞—Ä—Ç–∏–Ω–∫–∏ –ø–æ x',
                            required=False,
                            default=None, min_value=64,
                            max_value=768),
                  y: Option(int,
                            description='–∏–∑–º–µ–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∫–∞—Ä—Ç–∏–Ω–∫–∏ –ø–æ y',
                            required=False,
                            default=None, min_value=64,
                            max_value=768),
                  strength: Option(float, description='–Ω–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω—ã –±—É–¥—É—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è', required=False,
                                   default=0.5, min_value=0,
                                   max_value=1),
                  strength_prompt: Option(float,
                                          description='–õ–£–ß–®–ï –ù–ï –¢–†–û–ì–ê–¢–¨! –ù–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç',
                                          required=False,
                                          default=0.85, min_value=0,
                                          max_value=1),
                  strength_negative_prompt: Option(float,
                                                   description='–õ–£–ß–®–ï –ù–ï –¢–†–û–ì–ê–¢–¨! –ù–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç',
                                                   required=False,
                                                   default=1, min_value=0,
                                                   max_value=1),
                  repeats: Option(int,
                                  description='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤',
                                  required=False,
                                  default=1, min_value=1,
                                  max_value=16)
                  ):
    await ctx.defer()
    for i in range(repeats):
        cuda_number = None
        try:
            try:
                cuda_number = await use_cuda_images()
            except Exception:
                await ctx.respond("–ù–µ—Ç —Å–≤–æ–±–æ–¥–Ω—ã—Ö –≤–∏–¥–µ–æ–∫–∞—Ä—Ç")
                return

            await set_get_config_all(f"Image{cuda_number}", "result", "None")
            # throw extensions
            if await set_get_config_all(f"Image{cuda_number}", "model_loaded", None) == "False":
                return await ctx.respond("–º–æ–¥–µ–ª—å –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–æ–∫ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            # run timer
            start_time = datetime.datetime.now()
            input_image = "images/image" + str(random.randint(1, 1000000)) + ".png"
            await image.save(input_image)
            # get image size and round to 64
            if x is None or y is None:
                x, y = await get_image_dimensions(input_image)
                x = int(x)
                y = int(y)
            # —Å–∫—ç–π–ª–∏–Ω–≥ –≤–æ –∏–∑–±–µ–∂–∞–Ω–∏—è –æ—à–∏–±–æ–∫ –∏–∑-–∑–∞ –Ω–µ—Ö–≤–∞—Ç–∫–∏ –ø–∞–º—è—Ç–∏
            scale_factor = (1000000 / (x * y)) ** 0.5
            x = int(x * scale_factor)
            y = int(y * scale_factor)
            if not x % 64 == 0:
                x = ((x // 64) + 1) * 64
            if not y % 64 == 0:
                y = ((y // 64) + 1) * 64
            print("X:", x, "Y:", y)
            # loading params
            if seed is None:
                seed = random.randint(1, 9007199254740991)
            await set_get_config_all(f"Image{cuda_number}", "strength_negative_prompt", strength_negative_prompt)
            await set_get_config_all(f"Image{cuda_number}", "strength_prompt", strength_prompt)
            await set_get_config_all(f"Image{cuda_number}", "strength", strength)
            await set_get_config_all(f"Image{cuda_number}", "seed", seed)
            await set_get_config_all(f"Image{cuda_number}", "steps", steps)
            await set_get_config_all(f"Image{cuda_number}", "negative_prompt", negative_prompt)
            await set_get_config_all(f"Image{cuda_number}", "prompt", prompt)
            await set_get_config_all(f"Image{cuda_number}", "x", x)
            await set_get_config_all(f"Image{cuda_number}", "y", y)
            await set_get_config_all(f"Image{cuda_number}", "input", input_image)
            print("params suc")
            # wait for answer
            while True:
                output_image = await set_get_config_all(f"Image{cuda_number}", "result", None)
                if not output_image == "None":
                    break
                await asyncio.sleep(0.25)

            # count time
            end_time = datetime.datetime.now()
            spent_time = str(end_time - start_time)
            # —É–±–∏—Ä–∞–µ–º —á–∞—Å—ã –∏ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
            spent_time = spent_time[spent_time.find(":") + 1:]
            spent_time = spent_time[:spent_time.find(".")]
            # –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º
            if repeats == 1:
                await ctx.respond("–í–æ—Ç –∫–∞–∫ —è –∏–∑–º–µ–Ω–∏–ª –≤–∞—à–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µüñå. –ü–æ—Ç—Ä–∞—á–µ–Ω–æ " + spent_time)
            else:
                await ctx.send("–í–æ—Ç –∫–∞–∫ —è –∏–∑–º–µ–Ω–∏–ª –≤–∞—à–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µüñå. –ü–æ—Ç—Ä–∞—á–µ–Ω–æ " + spent_time)
            await send_file(ctx, output_image, delete_file=True)
            # –ø–µ—Ä–µ—Å—Ç–∞—ë–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—É
            await stop_use_cuda_images(cuda_number)
        except Exception as e:
            traceback_str = traceback.format_exc()
            print(str(traceback_str))
            await ctx.send(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏ (—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\
                              {prompt, negative_prompt, steps, x, y, strength, strength_prompt, strength_negative_prompt}): {e}")
            # –ø–µ—Ä–µ—Å—Ç–∞—ë–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—É
            if not cuda_number is None:
                await stop_use_cuda_images(cuda_number)


@bot.slash_command(name="config", description='–∏–∑–º–µ–Ω–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥ (–ª—É—á—à–µ –Ω–µ —Ç—Ä–æ–≥–∞—Ç—å, –µ—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å!)')
async def __config(
        ctx,
        section: Option(str, description='—Å–µ–∫—Ü–∏—è', required=True),
        key: Option(str, description='–∫–ª—é—á', required=True),
        value: Option(str, description='–∑–Ω–∞—á–µ–Ω–∏–µ', required=False, default=None)
):
    try:
        await ctx.defer()
        result = await set_get_config_all(section, key, value)
        if value is None:
            await ctx.respond(result)
        else:
            await ctx.respond(section + " " + key + " " + value)
    except Exception as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∫–æ–Ω—Ñ–∏–≥–∞ (—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏{section},{key},{value}): {e}")


@bot.slash_command(name="read_messages", description='–ß–∏—Ç–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ x —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ —á–∞—Ç–∞ –∏ –¥–µ–ª–∞–µ—Ç –ø–æ –Ω–∏–º –≤—ã–≤–æ–¥')
async def __read_messages(
        ctx,
        number: Option(int, description='–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π (–æ—Ç 1 –¥–æ 100', required=True, min_value=1,
                       max_value=100),
        prompt: Option(str, description='–ü—Ä–æ–º–ø—Ç –¥–ª—è GPT. –ö–∞–∫–æ–π –≤—ã–≤–æ–¥ —Å–¥–µ–ª–∞—Ç—å –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—è–º (–ø–µ—Ä–µ–≤–µ—Å—Ç–∏, –ø–µ—Ä–µ—Å–∫–∞–∑–∞—Ç—å)',
                       required=True)
):
    await ctx.defer()
    from function import chatgpt_get_result, text_to_speech
    try:
        messages = []
        async for message in ctx.channel.history(limit=number):
            messages.append(f"–°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {message.author.name}: {message.content}")
        # –û—Ç –Ω–∞—á–∞–ª–∞ –¥–æ –∫–æ–Ω—Ü–∞
        messages = messages[::-1]
        # —É–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ / –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        messages = messages[:number - 1]
        print(messages)
        result = await chatgpt_get_result(f"{prompt}. –í–æ—Ç –∏—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π:{messages}", ctx)
        print(result)
        await ctx.respond(result)
        await text_to_speech(result, False, ctx)
    except Exception as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        await ctx.respond(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")


@bot.slash_command(name="join", description='–ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å—Å—è –∫ –≥–æ–ª–æ—Å–æ–≤–æ–º—É –∫–∞–Ω–∞–ª—É')
async def join(ctx):
    try:
        await ctx.defer()
        voice = ctx.author.voice
        if not voice:
            await ctx.respond(voiceChannelErrorText)
            return

        voice_channel = voice.channel

        if ctx.voice_client is not None:
            return await ctx.voice_client.move_to(voice_channel)

        await voice_channel.connect()
        await ctx.respond("–ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è—é—Å—å")
    except Exception as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–∏: {e}")


@bot.slash_command(name="record", description='–≤–æ—Å–ø—Ä–∏–Ω–∏–º–∞—Ç—å –∫–æ–º–∞–Ω–¥—ã –∏–∑ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞')
async def record(ctx):  # if you're using commands.Bot, this will also work.
    try:
        voice = ctx.author.voice
        voice_channel = voice.channel
        # –¥–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á –∫ connetions
        if ctx.guild.id not in connections:
            connections[ctx.guild.id] = []

        if not voice:
            return await ctx.respond(voiceChannelErrorText)

        if ctx.voice_client is None:
            # –µ—Å–ª–∏ –±–æ—Ç–∞ –ù–ï–¢ –≤ –≤–æ–π—Å-—á–∞—Ç–µ
            vc = await voice_channel.connect()
        else:
            # –µ—Å–ª–∏ –±–æ—Ç –£–ñ–ï –≤ –≤–æ–π—Å-—á–∞—Ç–µ
            vc = ctx.voice_client
        # –µ—Å–ª–∏ —É–∂–µ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç
        if vc in connections[ctx.guild.id]:
            return await ctx.respond("–£–∂–µ –∑–∞–ø–∏—Å—ã–≤–∞—é –≤–∞—à –≥–æ–ª–æ—Åüé§")
        stream_sink.set_user(ctx.author.id)
        connections[ctx.guild.id].append(vc)

        # –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å
        vc.start_recording(
            stream_sink,  # the sink type to use.
            once_done,  # what to do once done.
            ctx.channel  # the channel to disconnect from.
        )
        await set_get_config_all("Sound", "record", "True")
        await ctx.respond("–í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –≤–∞—Å —Å–ª—É—à–∞—é")
        await recognize(ctx)
    except Exception as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –∑–≤—É–∫–∞ –∏–∑ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: {e}")


@bot.slash_command(name="stop_recording", description='–ø–µ—Ä–µ—Å—Ç–∞—Ç—å –≤–æ—Å–ø—Ä–∏–Ω–∏–º–∞—Ç—å –∫–æ–º–∞–Ω–¥—ã –∏–∑ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞')
async def stop_recording(ctx):
    try:
        if ctx.guild.id in connections:
            vc = connections[ctx.guild.id][0]  # –ü–æ–ª—É—á–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç —Å–ø–∏—Å–∫–∞
            vc.stop_recording()
            del connections[ctx.guild.id]
            await ctx.respond("–Ø –ø–µ—Ä–µ—Å—Ç–∞–ª –≤–∞—Å —Å–ª—ã—à–∞—Ç—å")
        else:
            await ctx.respond("–Ø –∏ —Ç–∞–∫ —Ç–µ–±—è –Ω–µ —Å–ª—É—à–∞–ª ._.")
    except Exception as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–ø–∏—Å–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: {e}")


@bot.slash_command(name="disconnect", description='–≤—ã–π—Ç–∏ –∏–∑ –≤–æ–π—Å-—á–∞—Ç–∞')
async def disconnect(ctx):
    try:
        await ctx.defer()
        voice = ctx.voice_client
        if voice:
            await voice.disconnect(force=True)
            await ctx.respond("–≤—ã—Ö–æ–∂—É")
        else:
            await ctx.respond("–Ø –Ω–µ –≤ –≤–æ–π—Å–µ")
        if ctx.guild.id in connections:
            del connections[ctx.guild.id]  # remove the guild from the cache.
    except Exception as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—Ö–æ–¥–µ –∏–∑ –≤–æ–π—Å-—á–∞—Ç–∞: {e}")


# @bot.command(help="—Å–∫–∞–∑–∞—Ç—å —Ä–æ–±–æ—Ç—É —Ç–µ–∫—Å—Ç")
# async def say(ctx, *args):
#     message = " ".join(args)
#     from function import replace_mat_in_sentence
#     if not default_settings.get("robot_name_need"):
#         message = default_settings.get("currentAIname") + ", " + message
#         print(message)
#     else:
#         print(message)
#     message = await replace_mat_in_sentence(message)
#     # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ –∞–≤—Ç–æ—Ä –∫–æ–º–∞–Ω–¥—ã –≤ –≤–æ–π—Å-—á–∞—Ç–µ
#     # if ctx.author.voice:
#     if True:
#         # –ü–æ–ª—É—á–∞–µ–º –≤–æ–π—Å-–∫–∞–Ω–∞–ª –∞–≤—Ç–æ—Ä–∞ –∫–æ–º–∞–Ω–¥—ã
#         # voice_channel = ctx.author.voice.channel
#         # # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ –±–æ—Ç —É–∂–µ –≤ –∫–∞–∫–æ–º-–ª–∏–±–æ –≤–æ–π—Å-—á–∞—Ç–µ
#         # if ctx.voice_client is None:
#         #     # –ï—Å–ª–∏ –±–æ—Ç –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –≤–æ–π—Å-—á–∞—Ç–µ, –ø–æ–¥–∫–ª—é—á–∞–µ–º –µ–≥–æ
#         #     await voice_channel.connect()
#         # else:
#         #     # –ï—Å–ª–∏ –±–æ—Ç —É–∂–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –≤–æ–π—Å-—á–∞—Ç–µ, –ø–µ—Ä–µ–º–µ—â–∞–µ–º –µ–≥–æ –≤ –Ω–æ–≤—ã–π –≤–æ–π—Å-–∫–∞–Ω–∞–ª
#         #     await ctx.voice_client.move_to(voice_channel)
#         await run_main_with_settings(ctx, message, True)
#     else:
#         await ctx.send("–í—ã –¥–æ–ª–∂–Ω—ã –Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤ –≤–æ–π—Å-—á–∞—Ç–µ, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç—É –∫–æ–º–∞–Ω–¥—É.")


@bot.slash_command(name="pause", description='–ø–∞—É–∑–∞/–≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ (–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–∏–∞–ª–æ–≥–∞)')
async def pause(ctx):
    try:
        await ctx.defer()
        if await set_get_config_all("dialog", "dialog", None) == "True":
            await set_get_config_all("dialog", "dialog", "False")
            await ctx.respond("–î–∏–∞–ª–æ–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

            # —Å–∫–∏–ø–∞–µ–º –∞—É–¥–∏–æ
            voice_client = ctx.voice_client
            if voice_client.is_playing():
                voice_client.stop()
                await set_get_config_all("Sound", "stop_milliseconds", 0)
                await set_get_config_all("Sound", "playing", "False")
            return
        voice_client = ctx.voice_client
        if voice_client.is_playing():
            # voice_client.pause()
            await set_get_config_all("Sound", "pause", "True")
            await ctx.respond("–ü–∞—É–∑–∞ ‚è∏")
        elif voice_client.is_paused():
            # voice_client.resume()
            await set_get_config_all("Sound", "pause", "False")
            await ctx.respond("–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ ‚ñ∂Ô∏è")
        else:
            await ctx.respond("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∏–ª–∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è.")
    except Exception as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—É–∑–µ: {e}")


@bot.slash_command(name="skip", description='–ø—Ä–æ–ø—É—Å–∫ –∞—É–¥–∏–æ')
async def skip(ctx):
    try:
        await ctx.defer()
        await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')
        voice_client = ctx.voice_client
        if voice_client.is_playing():
            voice_client.stop()
            await ctx.respond("–ê—É–¥–∏–æ –ø—Ä–æ–ø—É—â–µ–Ω–æ ‚è≠Ô∏è")
            await set_get_config_all("Sound", "stop_milliseconds", 0)
            await set_get_config_all("Sound", "playing", "False")
        else:
            await ctx.respond("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞.")
    except Exception as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–ø—É—Å–∫–µ: {e}")


@bot.slash_command(name="lenght", description='–î–ª–∏–Ω–∞ –∑–∞–ø—Ä–æ—Å–∞')
async def __lenght(
        ctx,
        number: Option(int, description='–î–ª–∏–Ω–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è GPT (–ß–∏—Å–ª–æ –æ—Ç 1 –¥–æ 1000)', required=True, min_value=1,
                       max_value=1000)
):
    try:
        await ctx.defer()
        await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')
        # for argument in (number,"""boolean, member, text, choice"""):
        print(f'{number} ({type(number).__name__})\n')
        await run_main_with_settings(ctx, f"—Ä–æ–±–æ—Ç –¥–ª–∏–Ω–∞ –∑–∞–ø—Ä–æ—Å–∞ {number}", True)
        await ctx.respond(f"–î–ª–∏–Ω–∞ –∑–∞–ø—Ä–æ—Å–∞: {number}")
    except Exception as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –¥–ª–∏–Ω—ã –∑–∞–ø—Ä–æ—Å–∞ (—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏{number}): {e}")


@bot.slash_command(name="say", description='–°–∫–∞–∑–∞—Ç—å —Ä–æ–±–æ—Ç—É —á—Ç–æ-—Ç–æ')
async def __say(
        ctx,
        text: Option(str, description='–°–∞–º —Ç–µ–∫—Å—Ç/–∫–æ–º–∞–Ω–¥–∞. –°–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥: \\help-say', required=True),
        gpt_mode: Option(str, description="–º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è GPT. 'all' - –≤—Å–µ –æ—Ç–≤–µ—Ç—ã, 'fast' - –±—ã—Å—Ç—Ä—ã–π, 'None' - —Ç–æ—á–Ω—ã–π",
                         choices=["fast", "all", "None"], required=False, default=None)
):
    try:
        await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')

        if gpt_mode:
            await set_get_config_all("gpt", "gpt_mode", gpt_mode)

        from function import replace_mat_in_sentence
        if await set_get_config_all("Default", "robot_name_need") == "False":
            text = await set_get_config_all("Default", "currentainame") + ", " + text
        text = await replace_mat_in_sentence(text)
        print(f'{text} ({type(text).__name__})\n')
        await set_get_config_all("Default", "user_name", value=ctx.author.name)

        await run_main_with_settings(ctx, text, True)
    except Exception as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–º–∞–Ω–¥–µ say (—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏{text}): {e}")


@bot.slash_command(name="tts", description='_–ó–∞—Å—Ç–∞–≤–∏—Ç—å_ –±–æ—Ç–∞ –≥–æ–≤–æ—Ä–∏—Ç—å –≤—Å—ë, —á—Ç–æ –∑–∞—Ö–æ—á–µ—à—å')
async def __tts(
        ctx,
        text: Option(str, description='–¢–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏', required=True),
        ai_voice: Option(str, description='–ì–æ–ª–æ—Å –¥–ª—è –æ–∑–≤—É—á–∫–∏', required=False, default=None),
        output: Option(bool, description='–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç', required=False, default=False)
):
    ai_voice_temp = None
    try:
        await ctx.defer()
        await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')
        # count time
        start_time = datetime.datetime.now()
        await use_cuda_async(0)
        voices = (await set_get_config_all("Sound", "voices")).replace("\"", "").replace(",", "").split(";")
        if str(ai_voice) not in voices:
            return await ctx.respond("–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å –∏–∑ —Å–ø–∏—Å–∫–∞: " + ','.join(voices))
        from function import replace_mat_in_sentence, mat_found
        text = await replace_mat_in_sentence(text)
        if mat_found:
            await ctx.respond("–¢–∞–∫–æ–µ –Ω–µ–ª—å–∑—è –ø—Ä–æ–∏–∑–Ω–æ—Å–∏—Ç—å!")
            return
        print(f'{text} ({type(text).__name__})\n')
        # –º–µ–Ω—è–µ–º –≥–æ–ª–æ—Å
        voices = (await set_get_config_all("Sound", "voices")).replace("\"", "").replace(",", "").split(";")
        ai_voice_temp = await set_get_config_all("Default", "currentainame")
        if ai_voice is None:
            ai_voice = await set_get_config_all("Default", "currentainame")
            print(await set_get_config_all("Default", "currentainame"))
        elif ai_voice not in voices:
            return await ctx.respond("–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å –∏–∑ —Å–ø–∏—Å–∫–∞: " + ','.join(voices))
        await set_get_config_all("Default", "currentainame", ai_voice)
        # –∑–∞–ø—É—Å–∫–∞–µ–º TTS
        from function import text_to_speech
        await text_to_speech(text, False, ctx, ai_dictionary=ai_voice)
        # await run_main_with_settings(ctx, f"—Ä–æ–±–æ—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª 24 {text}",
        #                              False)  # await text_to_speech(text, False, ctx, ai_dictionary=ai_voice)
        # –ø–µ—Ä–µ—Å—Ç–∞—ë–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—É
        await stop_use_cuda_async(0)

        # count time
        end_time = datetime.datetime.now()
        spent_time = str(end_time - start_time)
        # —É–±–∏—Ä–∞–µ–º –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
        spent_time = spent_time[:spent_time.find(".")]
        if "0:00:00" not in str(spent_time):
            await ctx.respond("–ü–æ—Ç—Ä–∞—á–µ–Ω–æ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É:" + spent_time)
        if output:
            await send_file(ctx, "2.mp3")
    except Exception as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ (—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ {text}): {e}")
        # –≤–æ–∑—Ä–∞—â–∞–µ–º –≥–æ–ª–æ—Å
        if not ai_voice_temp is None:
            await set_get_config_all("Default", "currentainame", ai_voice_temp)
        # –ø–µ—Ä–µ—Å—Ç–∞—ë–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—É
        await stop_use_cuda_async(0)


async def get_links_from_playlist(playlist_url):
    try:
        playlist = Playlist(playlist_url)
        playlist._video_regex = re.compile(r"\"url\":\"(/watch\?v=[\w-]*)")
        video_links = playlist.video_urls
        video_links = str(video_links).replace("'", "").replace("[", "").replace("]", "").replace(" ", "").replace(",",
                                                                                                                   ";")
        return video_links
    except Exception as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –ø–ª–µ–π–ª–∏—Å—Ç–∞: {e}")
        return []


@bot.slash_command(name="ai_cover", description='_–ó–∞—Å—Ç–∞–≤–∏—Ç—å_ –±–æ—Ç–∞ –æ–∑–≤—É—á–∏—Ç—å –≤–∏–¥–µ–æ/—Å–ø–µ—Ç—å –ø–µ—Å–Ω—é')
async def __cover(
        ctx,
        url: Option(str, description='–°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∏–¥–µ–æ', required=False, default=None),
        audio_path: Option(discord.SlashCommandOptionType.attachment, description='–ê—É–¥–∏–æ—Ñ–∞–π–ª',
                           required=False, default=None),
        voice: Option(str, description='–ì–æ–ª–æ—Å –¥–ª—è –≤–∏–¥–µ–æ', required=False, default=None),
        gender: Option(str, description='–ö—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç/–ø–æ—ë—Ç –≤ –≤–∏–¥–µ–æ? (–∏–ª–∏ —É–∫–∞–∑–∞—Ç—å pitch)', required=False,
                       choices=['–º—É–∂—á–∏–Ω–∞', '–∂–µ–Ω—â–∏–Ω–∞'], default=None),
        pitch: Option(int, description='–ö–∞–∫—É—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å (–æ—Ç -24 –¥–æ 24) (–∏–ª–∏ —É–∫–∞–∑–∞—Ç—å gender)',
                      required=False,
                      default=0, min_value=-24, max_value=24),
        time: Option(int, description='–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)', required=False,
                     default=-1, min_value=-1),
        indexrate: Option(float, description='–ò–Ω–¥–µ–∫—Å –≥–æ–ª–æ—Å–∞ (–æ—Ç 0 –¥–æ 1)', required=False, default=0.5, min_value=0,
                          max_value=1),
        loudness: Option(float, description='–ì—Ä–æ–º–∫–æ—Å—Ç—å —à—É–º–∞ (–æ—Ç 0 –¥–æ 1)', required=False, default=0.4, min_value=0,
                         max_value=1),
        filter_radius: Option(int,
                              description='–ù–∞—Å–∫–æ–ª—å–∫–æ –¥–∞–ª–µ–∫–æ –æ—Ç –∫–∞–∂–¥–æ–π —Ç–æ—á–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö –±—É–¥—É—Ç —É—á–∏—Ç—ã–≤–∞—Ç—å—Å—è –∑–Ω–∞—á–µ–Ω–∏—è... (–æ—Ç 1 –¥–æ 7)',
                              required=False, default=3, min_value=0,
                              max_value=7),
        main_vocal: Option(int, description='–ì—Ä–æ–º–∫–æ—Å—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –≤–æ–∫–∞–ª–∞ (–æ—Ç -20 –¥–æ 0)', required=False, default=0,
                           min_value=-20, max_value=0),
        back_vocal: Option(int, description='–ì—Ä–æ–º–∫–æ—Å—Ç—å –±—ç–∫–≤–æ–∫–∞–ª–∞ (–æ—Ç -20 –¥–æ 0)', required=False, default=0,
                           min_value=-20, max_value=0),
        music: Option(int, description='–ì—Ä–æ–º–∫–æ—Å—Ç—å –º—É–∑—ã–∫–∏ (–æ—Ç -20 –¥–æ 0)', required=False, default=0, min_value=-20,
                      max_value=0),
        roomsize: Option(float, description='–†–∞–∑–º–µ—Ä –ø–æ–º–µ—â–µ–Ω–∏—è (–æ—Ç 0 –¥–æ 1)', required=False, default=0.2, min_value=0,
                         max_value=1),
        wetness: Option(float, description='–í–ª–∞–∂–Ω–æ—Å—Ç—å (–æ—Ç 0 –¥–æ 1)', required=False, default=0.2, min_value=0,
                        max_value=1),
        dryness: Option(float, description='–°—É—Ö–æ—Å—Ç—å (–æ—Ç 0 –¥–æ 1)', required=False, default=0.8, min_value=0,
                        max_value=1),
        palgo: Option(str, description='–ê–ª–≥–æ—Ä–∏—Ç–º. Rmvpe - –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç, mangio-crepe - –±–æ–ª–µ–µ –º—è–≥–∫–∏–π –≤–æ–∫–∞–ª',
                      required=False,
                      choices=['rmvpe', 'mangio-crepe'], default="rmvpe"),
        hop: Option(int, description='–ö–∞–∫ —á–∞—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–æ–Ω–∞ –≤ mango-crepe', required=False, default=128,
                    min_value=64,
                    max_value=1280),
        start: Option(int, description='–ù–∞—á–∞—Ç—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å —Å (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö). -1 –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è', required=False,
                      default=0, min_value=-2),
        output: Option(str, description='–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç', choices=["link", "file", "all_files", "None"],
                       required=False, default="file"),
        only_voice_change: Option(bool,
                                  description='–ù–µ –∏–∑–≤–ª–µ–∫–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–ª –∏ –±—ç–∫–≤–æ–∫–∞–ª, –∏–∑–º–µ–Ω–∏—Ç—å –≥–æ–ª–æ—Å. –ù–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Å—Å—ã–ª–∫–∏',
                                  required=False, default=False)
):
    param_string = None
    try:
        await ctx.defer()
        await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')
        params = []
        if voice is None:
            voice = await set_get_config_all("Default", "currentAIname")
        if voice:
            params.append(f"-voice {voice}")
        # –µ—Å–ª–∏ –º—É–∂—á–∏–Ω–∞-–º—É–∂—á–∏–Ω–∞, –∂–µ–Ω—â–∏–Ω–∞-–∂–µ–Ω—â–∏–Ω–∞, pitch –Ω–µ –º–µ–Ω—è–µ–º
        pitch_int = pitch
        # –µ—Å–ª–∏ –∂–µ–Ω—â–∏–Ω–∞, –∞ AI –º—É–∂—á–∏–Ω–∞ = -12,
        if gender == '–∂–µ–Ω—â–∏–Ω–∞':
            if await set_get_config_all("Default", "currentaipitch") == "0":
                pitch_int = -12
        # –µ—Å–ª–∏ –º—É–∂—á–∏–Ω–∞, –∞ AI –∂–µ–Ω—â–∏–Ω–∞ = 12,
        elif gender == '–º—É–∂—á–∏–Ω–∞':
            if not await set_get_config_all("Default", "currentaipitch") == "0":
                pitch_int = 12
        params.append(f"-pitch {pitch_int}")
        if time is None:
            params.append(f"-time -1")
        else:
            params.append(f"-time {time}")
        if palgo != "rmvpe":
            params.append(f"-palgo {palgo}")
        if hop != 128:
            params.append(f"-hop {hop}")
        if indexrate != 0.5:
            params.append(f"-indexrate {indexrate}")
        if loudness != 0.2:
            params.append(f"-loudness {loudness}")
        if filter_radius != 3:
            params.append(f"-filter_radius {filter_radius}")
        if main_vocal != 0:
            params.append(f"-vocal {main_vocal}")
        if back_vocal != 0:
            params.append(f"-bvocal {back_vocal}")
        if music != 0:
            params.append(f"-music {music}")
        if roomsize != 0.2:
            params.append(f"-roomsize {roomsize}")
        if wetness != 0.1:
            params.append(f"-wetness {wetness}")
        if dryness != 0.85:
            params.append(f"-dryness {dryness}")
        if start == -2:
            stop_seconds = int(await set_get_config_all("Sound", "stop_milliseconds", None)) // 1000
            params.append(f"-start {stop_seconds}")
        elif start == -1 or start != 0:
            params.append(f"-start {start}")
        if output != "None":
            params.append(f"-output {output}")

        param_string = ' '.join(params)
        print("suc params")
        # time start
        start_time = datetime.datetime.now()
        if audio_path:
            filename = str(random.randint(1, 1000000)) + ".mp3"
            await audio_path.save(filename)
            # –ò–∑–º–µ–Ω–∏—Ç—å –¢–û–õ–¨–ö–û –ì–û–õ–û–°
            if only_voice_change:
                try:
                    command = [
                        "python",
                        "only_voice_change_cuda0.py",
                        "-i", f"{filename}",
                        "-o", f"{filename}",
                        "-dir", str(voice),
                        "-p", f"{pitch_int}",
                        "-ir", f"{indexrate}",
                        "-fr", f"{filter_radius}",
                        "-rms", f"{roomsize}",
                        "-pro", "0.05"
                    ]
                    print("run RVC, AIName:", voice)
                    subprocess.run(command, check=True)
                    await send_file(ctx, filename, delete_file=True)
                except subprocess.CalledProcessError as e:
                    traceback_str = traceback.format_exc()
                    print(str(traceback_str))
                    await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –≥–æ–ª–æ—Å–∞(ID:d1): {e}")
            else:
                # –∏–∑–º–µ–Ω–∏—Ç—å –≥–æ–ª–æ—Å –±–µ–∑ –º—É–∑—ã–∫–∏
                param_string += f" -url {filename} "
                await run_main_with_settings(ctx, "—Ä–æ–±–æ—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª 13 " + param_string, False)
        elif url:
            if ";" in url:
                urls = url.split(";")
            elif "playlist" in url:
                urls = await get_links_from_playlist(url)
                urls = urls.split(";")
                if urls == "" or urls is None:
                    ctx.respond("–û—à–∏–±–∫–∞ –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –≤–∏–¥–µ–æ –≤ –ø–ª–µ–π–ª–∏—Å—Ç–µ")
            else:
                urls = [url]
            args = ""
            i = 0
            for one_url in urls:
                i += 1
                args += f"—Ä–æ–±–æ—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª 13 -url {one_url} {param_string}\n"
            await run_main_with_settings(ctx, args, True)
        else:
            await ctx.respond('–ù–µ —É–∫–∞–∑–∞–Ω–∞ —Å—Å—ã–ª–∫–∞ –∏–ª–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª')
            return
        end_time = datetime.datetime.now()
        spent_time = str(end_time - start_time)
        # —É–±–∏—Ä–∞–µ–º –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
        spent_time = spent_time[:spent_time.find(".")]
        if not "0:00:00" in str(spent_time):
            await ctx.respond("–ü–æ—Ç—Ä–∞—á–µ–Ω–æ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É:" + spent_time)
    except Exception as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –≥–æ–ª–æ—Å–∞(ID:d5) (—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ {param_string}): {e}")


@bot.slash_command(name="create_dialog", description='–ò–º–∏—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∏–∞–ª–æ–≥ –ª—é–¥–µ–π')
async def __dialog(
        ctx,
        names: Option(str, description="–£—á–∞—Å—Ç–Ω–∏–∫–∏ –¥–∏–∞–ª–æ–≥–∞ —á–µ—Ä–µ–∑ ';' (—É –∫–∞–∂–¥–æ–≥–æ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω –≥–æ–ª–æ—Å!)",
                      required=True),
        theme: Option(str, description="–ù–∞—á–∞–ª—å–Ω–∞—è —Ç–µ–º–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞", required=False, default="—Å–ª—É—á–∞–π–Ω–∞—è —Ç–µ–º–∞"),
        prompt: Option(str, description="–û–±—â–∏–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –≤—Å–µ—Ö –¥–∏–∞–ª–æ–≥–æ–≤", required=False, default="")
):
    try:
        await ctx.defer()
        await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')
        if await set_get_config_all("dialog", "dialog", None) == "True":
            await ctx.respond("–£–∂–µ –∏–¥—ë—Ç –¥–∏–∞–ª–æ–≥!")
            return
        # –æ—Ç—á–∏—â–∞–µ–º –ø—Ä–æ—à–ª—ã–µ –¥–∏–∞–ª–æ–≥–∏
        with open("caversAI/dialog_create.txt", "w"):
            pass
        with open("caversAI/dialog_play.txt", "w"):
            pass
        voices = (await set_get_config_all("Sound", "voices")).replace("\"", "").replace(",", "").split(";")
        voices.remove("None")  # —É–±–∏—Ä–∞–µ–º, —á—Ç–æ–±—ã –Ω–µ –ø—É—Ç–∞—Ç—å—Å—è
        names = names.split(";")
        if len(names) < 2:
            await ctx.respond("–î–æ–ª–∂–Ω–æ –±—ã—Ç—å –∫–∞–∫ –º–∏–Ω–∏–º—É–º 2 –ø–µ—Ä—Å–æ–Ω–∞–∂–∞")
            return
        infos = []
        for name in names:
            if name not in voices:
                await ctx.respond("–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å–∞ –∏–∑ —Å–ø–∏—Å–∫–∞: " + ','.join(voices))
                return
            with open(f"rvc_models/{name}/info.txt") as reader:
                file_content = reader.read().replace("–í–æ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–µ–±–µ:", "")
                infos.append(f"–í–æ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ {name}: {file_content}")
        await set_get_config_all("dialog", "dialog", "True")
        await set_get_config_all("gpt", "gpt_mode", "None")
        # names, theme, infos, prompt, ctx
        # –∑–∞–ø—É—Å—Ç–∏–º —Å—Ä–∞–∑—É 8 –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ–ª–æ—Å–∞
        await asyncio.gather(gpt_dialog(names, theme, infos, prompt, ctx), play_dialog(ctx),
                             create_audio_dialog(ctx, 0, "dialog"), create_audio_dialog(ctx, 1, "dialog"),
                             create_audio_dialog(ctx, 2, "dialog"), create_audio_dialog(ctx, 3, "dialog"),
                             create_audio_dialog(ctx, 4, "dialog"), create_audio_dialog(ctx, 5, "dialog"),
                             create_audio_dialog(ctx, 6, "dialog"), create_audio_dialog(ctx, 7, "dialog"))
    except Exception as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–∏–∞–ª–æ–≥–µ: {e}")


@bot.slash_command(name="add_voice", description='–î–æ–±–∞–≤–∏—Ç—å RVC –≥–æ–ª–æ—Å')
async def __add_voice(
        ctx,
        url: Option(str, description='–°—Å—ã–ª–∫–∞ –Ω–∞ .zip —Ñ–∞–π–ª —Å –º–æ–¥–µ–ª—å—é RVC', required=True),
        name: Option(str, description=f'–ò–º—è –º–æ–¥–µ–ª–∏', required=True),
        gender: Option(str, description=f'–ü–æ–ª (–¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏)', required=True,
                       choices=['–º—É–∂—á–∏–Ω–∞', '–∂–µ–Ω—â–∏–Ω–∞']),
        info: Option(str, description=f'–ö–∞–∫–∏–µ-—Ç–æ —Å–≤–µ–¥–µ–Ω–∏—è –æ –¥–∞–Ω–Ω–æ–º —á–µ–ª–æ–≤–µ–∫–µ', required=False,
                     default="–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"),
        speed: Option(float, description=f'–£—Å–∫–æ—Ä–µ–Ω–∏–µ/–∑–∞–º–µ–¥–ª–µ–Ω–∏–µ –≥–æ–ª–æ—Å–∞', required=False,
                      default=1, min_value=0.5, max_value=2),
        change_voice: Option(bool, description=f'(–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ) –ò–∑–º–µ–Ω–∏—Ç—å –≥–æ–ª–æ—Å –Ω–∞ —ç—Ç–æ—Ç', required=False,
                             default=False)
):
    await ctx.defer()
    await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')
    if name == "None" or ";" in name or "/" in name or "\\" in name:
        await ctx.respond('–ò–º—è –Ω–µ –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å \";\" \"/\" \"\\\" –∏–ª–∏ –±—ã—Ç—å None')
    # !python download_voice_model.py {url} {dir_name} {gender} {info}
    name = name.replace(" ", "_")
    if gender == "–∂–µ–Ω—â–∏–Ω–∞":
        gender = "female"
    elif gender == "–º—É–∂—á–∏–Ω–∞":
        gender = "male"
    else:
        gender = "male"
    try:
        command = [
            "python",
            "download_voice_model.py",
            url,
            name,
            gender,
            f"{info}",
            str(speed)
        ]
        subprocess.run(command, check=True)
        voices = (await set_get_config_all("Sound", "voices")).split(";")
        voices.append(name)
        await set_get_config_all("Sound", "voices", ';'.join(voices))
        if change_voice:
            await run_main_with_settings(ctx, f"—Ä–æ–±–æ—Ç –∏–∑–º–µ–Ω–∏ –≥–æ–ª–æ—Å –Ω–∞ {name}", True)
        await ctx.send(f"–ú–æ–¥–µ–ª—å {name} —É—Å–ø–µ—à–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞!")
    except subprocess.CalledProcessError as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        await ctx.respond(f"–ì–æ–ª–æ—Å —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –Ω–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –±—ã–ª–∏ –∏–∑–º–µ–Ω–µ–Ω—ã")


@bot.command(aliases=['cmd'], help="–∫–æ–º–∞–Ω–¥–Ω–∞—è —Å—Ç—Ä–æ–∫–∞")
async def command_line(ctx, *args):
    text = " ".join(args)
    print("command line:", text)
    try:
        process = subprocess.Popen(text, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)
        stdout, stderr = process.communicate()
        for line in stdout.decode().split('\n'):
            if line.strip():
                await ctx.send(line)
        for line in stderr.decode().split('\n'):
            if line.strip():
                await ctx.send(line)
    except subprocess.CalledProcessError as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        await ctx.send(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã: {e}")
    except Exception as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        await ctx.send(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")


async def play_dialog(ctx):
    number = int(await set_get_config_all("dialog", "play_number", None))
    while await set_get_config_all("dialog", "dialog", None) == "True":
        try:
            files = os.listdir("song_output")
            files = sorted(files)
            for file in files:
                if file.startswith(str(number)):
                    with open("caversAI/dialog_play.txt", "r") as reader:
                        lines = reader.read()
                        if file not in lines:
                            await asyncio.sleep(0.1)
                            continue
                    from function import playSoundFile
                    number += 1
                    await set_get_config_all("dialog", "play_number", number)
                    speaker = file[:file.find(".")]
                    speaker = re.sub(r'\d', '', speaker)
                    await ctx.send("–≥–æ–≤–æ—Ä–∏—Ç " + speaker)
                    await playSoundFile("song_output/" + file, -1, 0, ctx)
                    os.remove("song_output/" + file)
                    await ctx.send("end")
                else:
                    await asyncio.sleep(0.2)
        except Exception as e:
            traceback_str = traceback.format_exc()
            print(str(traceback_str))
            await ctx.send(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –≥–æ–ª–æ—Å–∞(ID:d2): {e}")


async def text_to_speech_file(tts, currentpitch, file_name):
    from elevenlabs import generate, save, set_api_key
    language = await set_get_config_all("Default", "language", None)
    max_simbols = await set_get_config_all("voice", "max_simbols", None)

    pitch = 0
    if len(tts) > int(max_simbols) or await set_get_config_all("voice", "avaible_tokens", None) == "None":
        print("gtts1")
        from function import gtts
        await gtts(tts, language[:2], file_name)
        if currentpitch == 0:
            pitch = -12
    else:
        # –ø–æ–ª—É—á–∞–µ–º –∫–ª—é—á –¥–ª—è elevenlab
        keys = (await set_get_config_all("voice", "avaible_tokens", None)).split(";")
        key = keys[0]
        if not key == "Free":
            set_api_key(key)
        try:
            # –≥–æ–ª–æ—Å TTS –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–æ–ª–∞
            if currentpitch == 0:
                voice = "Arnold"
            else:
                voice = "Bella"
            audio = generate(
                text=tts,
                model='eleven_multilingual_v2',
                voice=voice
            )

            save(audio, file_name)
        except Exception as e:
            from function import remove_unavaible_voice_token
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∫–æ–º–∞–Ω–¥—ã (ID:f16): {e}")
            traceback_str = traceback.format_exc()
            print(str(traceback_str))
            await remove_unavaible_voice_token()
            pitch = await text_to_speech_file(tts, currentpitch, file_name)
            return pitch
            # gtts(tts, language[:2], file_name)
    return pitch


async def create_audio_dialog(ctx, cuda, wait_untill):
    await asyncio.sleep(cuda * 0.11 + 0.05)
    cuda = cuda % 2

    while True:
        text_path = "caversAI/dialog_create.txt"
        play_path = "caversAI/dialog_play.txt"
        with open(text_path, "r") as reader:
            line = reader.readline()
            if not line is None and not line.replace(" ", "") == "":
                await remove_line_from_txt(text_path, 1)
                name = line[line.find("-voice") + 7:].replace("\n", "")
                with open(os.path.join(f"rvc_models/{name}/gender.txt"), "r") as file:
                    pitch = 0
                    if file.read().lower() == "female":
                        pitch = 12
                filename = int(await set_get_config_all("dialog", "files_number", None))
                await set_get_config_all("dialog", "files_number", filename + 1)
                filename = "song_output/" + str(filename) + name + ".mp3"
                pitch = await text_to_speech_file(line[:line.find("-voice")], pitch, filename)
                try:
                    command = [
                        "python",
                        f"only_voice_change_cuda{cuda}.py",
                        "-i", f"{filename}",
                        "-o", f"{filename}",
                        "-dir", name,
                        "-p", f"{pitch}",
                        "-ir", "0.5",
                        "-fr", "3",
                        "-rms", "0.3",
                        "-pro", "0.15",
                        "-slow"  # –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –¥–∏–∞–ª–æ–≥–∞
                    ]
                    print("run RVC, AIName:", name)
                    from function import execute_command
                    await execute_command(' '.join(command), ctx)

                    # –¥–∏–∞–ª–æ–≥ –∑–∞–≤–µ—Ä—à—ë–Ω.
                    print("DIALOG_TEMP:", await set_get_config_all("dialog", wait_untill, None))
                    if await set_get_config_all("dialog", wait_untill, None) == "False":
                        return

                    # –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —É—Å–∫–æ—Ä–µ–Ω–∏—è
                    if await set_get_config_all("Sound", "change_speed", None) == "True":
                        with open(os.path.join(f"rvc_models/{name}/speed.txt"), "r") as reader:
                            speed = float(reader.read())
                            # print("SPEED:", speed)
                        from function import speed_up_audio
                        await speed_up_audio(filename, speed)
                    with open(play_path, "a") as writer:
                        writer.write(filename + "\n")
                except Exception as e:
                    traceback_str = traceback.format_exc()
                    print(str(traceback_str))
                    await ctx.send(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –≥–æ–ª–æ—Å–∞(ID:d3): {e}")
            else:
                await asyncio.sleep(0.5)


async def remove_line_from_txt(file_path, delete_line):
    try:
        if not os.path.exists(file_path):
            return
        lines = []
        with open(file_path, "r") as reader:
            i = 1
            for line in reader:
                if not i == delete_line:
                    lines.append(line)
                i += 1
        with open(file_path, "w") as writer:
            for line in lines:
                writer.write(line)
    except Exception as e:
        raise f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Å—Ç—Ä–æ–∫–∏: {e}"


async def gpt_dialog(names, theme, infos, prompt_global, ctx):
    from function import chatgpt_get_result
    # –î–µ–ª–∞–µ–º –¥–∏–∞–ª–æ–≥ –º–µ–∂–¥—É —Å–æ–±–æ–π
    if await set_get_config_all("dialog", "dialog", None) == "True":
        prompt = (f"–ü—Ä–∏–≤–µ—Ç, chatGPT. –í—ã —Å–æ–±–∏—Ä–∞–µ—Ç–µ—Å—å —Å–¥–µ–ª–∞—Ç—å –¥–∏–∞–ª–æ–≥ –º–µ–∂–¥—É {', '.join(names)}. –ù–∞ —Ç–µ–º—É \"{theme}\". "
                  f"–ø–µ—Ä—Å–æ–Ω–∞–∂–∏ –¥–æ–ª–∂–Ω—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —Å–≤–æ–µ–º—É –æ–±—Ä–∞–∑—É –Ω–∞—Å–∫–æ–ª—å–∫–æ —ç—Ç–æ –≤–æ–∑–º–æ–∂–Ω–æ. "
                  f"{'.'.join(infos)}. {prompt_global}. "
                  f"–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤ –∫–æ–Ω—Ü–µ –¥–∏–∞–ª–æ–≥–∞ –Ω–∞–ø–∏—à–∏ –æ—á–µ–Ω—å –∫—Ä–∞—Ç–∫–æ —á—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ –≤ —ç—Ç–æ–º –¥–∏–∞–ª–æ–≥–∏ –∏ —á—Ç–æ –¥–æ–ª–∂–Ω–æ –ø—Ä–æ–∏–∑–æ–π—Ç–∏ –¥–∞–ª—å—à–µ. "
                  f"–í—ã–≤–µ–¥–∏ –¥–∏–∞–ª–æ–≥ –≤ —Ç–∞–∫–æ–º —Ñ–æ—Ä–º–∞—Ç–µ:[–ì–æ–≤–æ—Ä—è—â–∏–π]: [—Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ–Ω –ø—Ä–æ–∏–∑–Ω–æ—Å–∏—Ç]")
        result = (await chatgpt_get_result(prompt, ctx)).replace("[", "").replace("]", "")
        # await write_in_discord(ctx, result)
        with open("caversAI/dialog_create.txt", "a") as writer:
            for line in result.split("\n"):
                for name in names:
                    # –ß–µ–ª–æ–≤–µ–∫: –ø—Ä–∏–≤–µ—Ç
                    # –ß–µ–ª–æ–≤–µ–∫ (man): –ø—Ä–∏–≤–µ—Ç
                    if line.startswith(name):
                        line = line[line.find(":") + 1:]
                        writer.write(line + f"-voice {name}\n")

        while await set_get_config_all("dialog", "dialog", None) == "True":
            try:
                if "\n" in result:
                    result = result[result.rfind("\n"):]
                spoken_text = ""
                spoken_text_config = await set_get_config_all("dialog", "user_spoken_text", None)
                if not spoken_text_config == "None":
                    spoken_text = "–û—Ç–≤–µ—á–∞–π—Ç –∑—Ä–∏—Ç–µ–ª—è–º! –ó—Ä–∏—Ç–µ–ª–∏ –∑–∞ –ø—Ä–æ—à–ª—ã–π –¥–∏–∞–ª–æ–≥ –Ω–∞–ø–∏—Å–∞–ª–∏:\"" + spoken_text_config + "\""
                    await set_get_config_all("dialog", "user_spoken_text", "None")
                random_int = random.randint(1, 33)
                if not random_int == 0:
                    prompt = (f"–ü—Ä–∏–≤–µ—Ç chatGPT, –ø—Ä–æ–¥–æ–ª–∂–∏ –¥–∏–∞–ª–æ–≥ –º–µ–∂–¥—É {', '.join(names)}. "
                              f"{'.'.join(infos)}. {prompt_global} "
                              f"–ø–µ—Ä—Å–æ–Ω–∞–∂–∏ –¥–æ–ª–∂–Ω—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —Å–≤–æ–µ–º—É –æ–±—Ä–∞–∑—É –Ω–∞—Å–∫–æ–ª—å–∫–æ —ç—Ç–æ –≤–æ–∑–º–æ–∂–Ω–æ. "
                              f"–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–∏—à–∏ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –≤ –Ω–∞—á–∞–ª–µ —ç—Ç–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞. "
                              f"–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–π —Ç–æ, —á—Ç–æ –±—ã–ª–æ –≤ –ø—Ä–æ—à–ª–æ–º –¥–∏–∞–ª–æ–≥–µ! –í–æ—Ç —á—Ç–æ –±—ã–ª–æ –≤ –ø—Ä–æ—à–ª–æ–º –¥–∏–∞–ª–æ–≥–µ:\"{result}\". {spoken_text}"
                              f"\n–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤ –∫–æ–Ω—Ü–µ –Ω–∞–ø–∏—à–∏ –æ—á–µ–Ω—å –∫—Ä–∞—Ç–∫–æ —á—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ –≤ —ç—Ç–æ–º –¥–∏–∞–ª–æ–≥–∏ –∏ —á—Ç–æ –¥–æ–ª–∂–Ω–æ –ø—Ä–æ–∏–∑–æ–π—Ç–∏ –¥–∞–ª—å—à–µ. "
                              f"–í—ã–≤–µ–¥–∏ –¥–∏–∞–ª–æ–≥ –≤ —Ç–∞–∫–æ–º —Ñ–æ—Ä–º–∞—Ç–µ:[–ì–æ–≤–æ—Ä—è—â–∏–π]: [—Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ–Ω –ø—Ä–æ–∏–∑–Ω–æ—Å–∏—Ç]")
                else:
                    prompt = (
                        f"–ü—Ä–∏–≤–µ—Ç, chatGPT. –í—ã —Å–æ–±–∏—Ä–∞–µ—Ç–µ—Å—å —Å–¥–µ–ª–∞—Ç—å –¥–∏–∞–ª–æ–≥ –º–µ–∂–¥—É {', '.join(names)} –Ω–∞ —Å–ª—É—á–∞–π–Ω—É—é —Ç–µ–º—É,"
                        f" –∫–æ—Ç–æ—Ä–∞—è –¥–æ–ª–∂–Ω–∞ –æ—Ç–Ω–æ—Å–∏—Ç—å—Å—è –∫ —Å–æ–±—ã—Ç–∏—è–º —Å–µ—Ä–≤–µ—Ä–∞. "
                        f"–ü–µ—Ä—Å–æ–Ω–∞–∂–∏ –¥–æ–ª–∂–Ω—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —Å–≤–æ–µ–º—É –æ–±—Ä–∞–∑—É –Ω–∞—Å–∫–æ–ª—å–∫–æ —ç—Ç–æ –≤–æ–∑–º–æ–∂–Ω–æ. "
                        f"–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–∏—à–∏ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –≤ –Ω–∞—á–∞–ª–µ —ç—Ç–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞. "
                        f"{'.'.join(infos)}. {prompt_global}. {spoken_text}"
                        f"–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤ –∫–æ–Ω—Ü–µ –Ω–∞–ø–∏—à–∏ –æ—á–µ–Ω—å –∫—Ä–∞—Ç–∫–æ —á—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ –≤ —ç—Ç–æ–º –¥–∏–∞–ª–æ–≥–∏ –∏ —á—Ç–æ –¥–æ–ª–∂–Ω–æ –ø—Ä–æ–∏–∑–æ–π—Ç–∏ –¥–∞–ª—å—à–µ. "
                        f"–í—ã–≤–µ–¥–∏ –¥–∏–∞–ª–æ–≥ –≤ —Ç–∞–∫–æ–º —Ñ–æ—Ä–º–∞—Ç–µ:[–ì–æ–≤–æ—Ä—è—â–∏–π]: [—Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ–Ω –ø—Ä–æ–∏–∑–Ω–æ—Å–∏—Ç]")
                print("PROMPT:", prompt)
                result = (await chatgpt_get_result(prompt, ctx)).replace("[", "").replace("]", "")
                # await write_in_discord(ctx, result)
                with open("caversAI/dialog_create.txt", "a") as writer:
                    for line in result.split("\n"):
                        for name in names:
                            # –ß–µ–ª–æ–≤–µ–∫: –ø—Ä–∏–≤–µ—Ç
                            # –ß–µ–ª–æ–≤–µ–∫ (man): –ø—Ä–∏–≤–µ—Ç
                            if line.startswith(name):
                                line = line[line.find(":") + 1:]
                                writer.write(line + f"-voice {name}\n")
                                break
            except Exception as e:
                traceback_str = traceback.format_exc()
                print(str(traceback_str))
                await ctx.send(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –≥–æ–ª–æ—Å–∞(ID:d4): {e}")


async def run_main_with_settings(ctx, spokenText, writeAnswer):
    from function import start_bot
    await start_bot(ctx, spokenText, writeAnswer)


async def write_in_discord(ctx, text):
    from function import result_command_change, Color
    if text == "" or text is None:
        await result_command_change("–û–¢–ü–†–ê–í–õ–ï–ù–û –ü–£–°–¢–û–ï –°–û–û–ë–©–ï–ù–ò–ï", Color.RED)
        return
    if len(text) < 1990:
        await ctx.send(text)
    else:
        # –Ω–∞—á–∏–Ω–∞–µ—Ç —Å—Ç—Ä–æ–∫—É —Å "```" –µ—Å–ª–∏ –æ–Ω–æ –≤—Å—Ç—Ä–µ—Ç–∏–ª–æ—Å—å –∏ —É–±–∏—Ä–∞–µ—Ç, –∫–æ–≥–¥–∞ "```" –æ–ø—è—Ç—å –ø–æ—è–≤–∏—Ç—Å—è
        add_format = False
        lines = text.split("\n")
        for line in lines:
            if "```" in line:
                add_format = not add_format
            if line.strip():
                if add_format:
                    line = line.replace("```", "")
                    line = "```" + line + "```"
                await ctx.send(line)


async def send_file(ctx, file_path, delete_file=False):
    try:
        await ctx.send(file=discord.File(file_path))
        if delete_file:
            await asyncio.sleep(3)
            os.remove(file_path)
    except FileNotFoundError:
        await ctx.send('–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.')
    except discord.HTTPException as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        await ctx.send(f'–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–∞–π–ª–∞: {e}.')


async def playSoundFileDiscord(ctx, audio_file_path, duration, start_seconds):
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ –±–æ—Ç –≤ –≥–æ–ª–æ—Å–æ–≤–æ–º –∫–∞–Ω–∞–ª–µ
    if start_seconds == -1:
        start_seconds = int(await set_get_config_all("Sound", "stop_milliseconds", None)) // 1000
    try:
        if not ctx.voice_client:
            await ctx.send("–ë–æ—Ç –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –≥–æ–ª–æ—Å–æ–≤–æ–º –∫–∞–Ω–∞–ª–µ. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É `join`, —á—Ç–æ–±—ã –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å –µ–≥–æ.")
            return
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–≥—Ä–∞–µ—Ç –ª–∏ —á—Ç–æ-—Ç–æ —É–∂–µ
        while await set_get_config_all("Sound", "playing", None) == "True":
            await asyncio.sleep(0.1)
        await set_get_config_all("Sound", "playing", "True")
        # –ø—Ä–æ–∏–≥—Ä—ã–≤–∞–µ–º
        source = discord.FFmpegPCMAudio(audio_file_path, options=f"-ss {start_seconds} -t {duration}")
        ctx.voice_client.play(source)

        # –û–∂–∏–¥–∞–µ–º –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø—Ä–æ–∏–≥—Ä—ã–≤–∞–Ω–∏—è
        resume = False
        while ctx.voice_client.is_playing():

            await asyncio.sleep(1)
            voice_client = ctx.voice_client
            pause = await set_get_config_all("Sound", "pause", None) == "True"
            if pause:
                resume = True
                voice_client.pause()
                while await set_get_config_all("Sound", "pause", None) == "True":
                    await asyncio.sleep(0.25)
            if resume:
                voice_client.resume()

            # stop_milliseconds += 1000
            await set_get_config_all("Sound", "stop_milliseconds",
                                     int(await set_get_config_all("Sound", "stop_milliseconds")) + 1000)
        await set_get_config_all("Sound", "playing", "False")
    except Exception as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        print(f"–û—à–∏–±–∫–∞, {e}")
        await set_get_config_all("Sound", "playing", "False")


async def once_done(sink: discord.sinks, channel: discord.TextChannel, *args):
    await set_get_config_all("Sound", "record", "False")
    # await sink.vc.disconnect()  # disconnect from the voice channel.
    print("Stopped listening.")


async def max_volume(audio_file_path):
    audio = AudioSegment.from_file(audio_file_path)
    max_dBFS = audio.max_dBFS
    print(max_dBFS, type(max_dBFS))
    return max_dBFS


last_speaking = 0


async def recognize(ctx):
    global last_speaking
    wav_filename = "out_all.wav"
    recognizer = sr.Recognizer()
    while True:
        # —Ä–∞—Å–ø–æ–∑–Ω–∞—ë–º, –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–∏–∑–æ–π–¥—ë—Ç once_done
        if await set_get_config_all("Sound", "record") == "False":
            print("Stopped listening2.")
            return
        file_found = []
        # –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        for filename in os.listdir(os.getcwd()):
            if filename.startswith("output") and filename.endswith(".wav"):
                file_found.append(filename)
                break
        if len(file_found) == 0:
            await asyncio.sleep(0.1)
            last_speaking += 1
            # –µ—Å–ª–∏ –¥–æ–ª–≥–æ –Ω–µ –±—ã–ª–æ —Ñ–∞–π–ª–æ–≤ (—á–µ–ª–æ–≤–µ–∫ –ø–µ—Ä–µ—Å—Ç–∞–ª –≥–æ–≤–æ—Ä–∏—Ç—å)
            if last_speaking > float(await set_get_config_all("Sound", "delay_record")) * 10:
                text = None
                # –æ—á–∏—â–∞–µ–º –ø–æ—Ç–æ–∫
                stream_sink.cleanup()
                last_speaking = 0
                # —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∏–µ —Ä–µ—á–∏
                try:
                    with sr.AudioFile(wav_filename) as source:
                        audio_data = recognizer.record(source)
                        text = recognizer.recognize_google(audio_data, language="ru-RU")
                except sr.UnknownValueError:
                    pass
                except sr.RequestError as e:
                    traceback_str = traceback.format_exc()
                    print(str(traceback_str))
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏: {e}")
                # —É–¥–∞–ª–µ–Ω–∏–µ out_all.wav
                try:
                    Path(wav_filename).unlink()
                except FileNotFoundError:
                    pass

                # —Å–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
                empty_audio = AudioSegment.silent(duration=0)
                try:
                    empty_audio.export(wav_filename, format="wav")
                except Exception as e:
                    traceback_str = traceback.format_exc()
                    print(str(traceback_str))
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø—É—Å—Ç–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞: {e}")
                # –≤—ã–∑–æ–≤ function
                if not text is None:
                    from function import replace_mat_in_sentence, replace_numbers_in_sentence
                    text = await replace_numbers_in_sentence(
                        text)
                    text = await replace_mat_in_sentence(text)
                    print(text)

                    if await set_get_config_all("dialog", "dialog", None) == "True":
                        spoken_text_config = await set_get_config_all("dialog", "user_spoken_text", None)
                        if spoken_text_config == "None":
                            spoken_text_config = ""
                        await set_get_config_all("dialog", "user_spoken_text", spoken_text_config + text)
                    else:
                        await set_get_config_all("Default", "user_name", value=ctx.author.name)
                        await run_main_with_settings(ctx,
                                                     await set_get_config_all("Default", "currentainame") + ", " + text,
                                                     True)

            continue

        # –∑–∞–ø–∏—Å—å –Ω–µ–ø—É—Å—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤
        max_loudness_all = float('-inf')
        for file in file_found:
            volume = await max_volume(file)
            if volume == float('-inf'):
                Path(file).unlink()
                file_found.remove(file)
                continue
            if volume > max_loudness_all:
                max_loudness_all = volume

        if max_loudness_all > int(await set_get_config_all("Sound", "min_volume", None)):
            last_speaking = 0

            result = AudioSegment.from_file(wav_filename, format="wav")

            for file in file_found:
                result += AudioSegment.from_file(file, format="wav")

            try:
                result.export(wav_filename, format="wav")
            except Exception as e:
                traceback_str = traceback.format_exc()
                print(str(traceback_str))
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ –∞—É–¥–∏–æ: {e}")

        # —É–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        try:
            for file in file_found:
                Path(file).unlink()
        except FileNotFoundError:
            pass
    print("Stop_Recording")


async def get_file_type(ctx, attachment):
    if not attachment:
        await ctx.send("–§–∞–π–ª –Ω–µ –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω.")
        return
    import magic
    mime = magic.Magic()
    file_type = mime.from_buffer(attachment.fp.read(2048))

    # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ MIME-—Ç–∏–ø–∞
    if file_type.startswith('image'):
        return "image"
    elif file_type.startswith('video'):
        return "video"
    elif file_type.startswith('audio'):
        return "audio"
    else:
        await ctx.send("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞.")


async def get_image_dimensions(file_path):
    with Image.open(file_path) as img:
        sizes = img.size
    return str(sizes).replace("(", "").replace(")", "").replace(" ", "").split(",")


if __name__ == "__main__":
    print("update 2")
    try:

        # === args ===

        arguments = sys.argv

        if len(arguments) > 1:
            discord_token = arguments[1]
            # load models? (img, gpt, all)
            load_gpt = False
            load_images1 = False
            load_images2 = False
            if len(arguments) > 2:
                args = arguments[2]
                if "gpt_local" in args:
                    load_gpt = True
                if "gpt_provider" in args:
                    set_get_config_all_not_async("gpt", "use_gpt_provider", "True")
                if "img1" in args:
                    load_images1 = True
                    set_get_config_all_not_async("Values", "cuda0_is_busy", "True")
                if "img2" in args:
                    load_images1 = True
                    set_get_config_all_not_async("Values", "cuda0_is_busy", "True")
                    load_images2 = True
                    set_get_config_all_not_async("Values", "cuda1_is_busy", "True")
        else:
            # raise error & exit
            print("–£–∫–∞–∂–∏—Ç–µ discord_TOKEN")
            exit(-1)
        # === load models ===
        # == load gpt ==
        if load_gpt:
            print("load gpt model")
            from GPT_runner import run

            pool = multiprocessing.Pool(processes=1)
            pool.apply_async(run)
            pool.close()

            while True:
                time.sleep(0.5)
                if set_get_config_all_not_async("gpt", "gpt") == "True":
                    break

        # == load images ==
        if load_images1:
            print("load image model on GPU-0")

            from image_create_cuda0 import generate_picture0

            pool = multiprocessing.Pool(processes=1)
            pool.apply_async(generate_picture0)
            pool.close()
            while True:
                time.sleep(0.5)
                if set_get_config_all_not_async("Image0", "model_loaded") == "True":
                    break
        if load_images2:
            print("load image model on GPU-1")

            from image_create_cuda1 import generate_picture1

            pool = multiprocessing.Pool(processes=1)
            pool.apply_async(generate_picture1)
            pool.close()
            while True:
                time.sleep(0.5)
                if set_get_config_all_not_async("Image1", "model_loaded") == "True":
                    break
        # === load voice models ===
        from only_voice_change_cuda0 import voice_change0
        from only_voice_change_cuda1 import voice_change1

        pool = multiprocessing.Pool(processes=2)
        pool.apply_async(voice_change0)
        # pool.apply_async(voice_change1)
        pool.close()

        # ==== load bot ====
        print("====load bot====")
        loop = asyncio.get_event_loop()
        loop.run_until_complete(bot.start(discord_token))
    except Exception as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
