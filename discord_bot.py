import asyncio
import os
import random
import re
import subprocess
import sys
import traceback
import zipfile
from contextlib import asynccontextmanager
from moviepy.video.io.VideoFileClip import VideoFileClip
from pathlib import Path
from pydub import AudioSegment
from pytube import Playlist

import speech_recognition as sr
from PIL import Image

import discord
from bark_tts import BarkTTS
from cover_gen import run_ai_cover_gen
from discord import Option
from discord.ext import commands
from discord_tools.chat_gpt import ChatGPT
from discord_tools.detect_mat import moderate_mat_in_sentence
from discord_tools.logs import Logs, Color
from discord_tools.sql_db import set_get_database_async as set_get_config_all
from discord_tools.timer import Time_Count
from download_voice_model import download_online_model
from function import Image_Generator, Character, Voice_Changer, get_link_to_file
from modifed_sinks import StreamSink
from use_free_cuda import Use_Cuda

try:
    import nest_asyncio

    nest_asyncio.apply()
except:
    pass

recognizers = {}
audio_players = {}
dialogs = {}
characters_all = {}

intents = discord.Intents.all()
bot = commands.Bot(command_prefix='\\', intents=intents)
cuda_manager = Use_Cuda()
image_generators = []
bark_model = None

logger = Logs(warnings=True)

voiceChannelErrorText = '‚ùó –í—ã –¥–æ–ª–∂–Ω—ã –Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤ –≥–æ–ª–æ—Å–æ–≤–æ–º –∫–∞–Ω–∞–ª–µ ‚ùó'
ALL_VOICES = {'Rachel': "–ñ", 'Clyde': '–ú', 'Domi': '–ñ', 'Dave': '–ú', 'Fin': '–ú', 'Bella': '–ñ', 'Antoni': '–ú',
              'Thomas': '–ú',
              'Charlie': '–ú', 'Emily': '–ñ', 'Elli': '–ñ', 'Callum': '–ú', 'Patrick': '–ú', 'Harry': '–ú', 'Liam': '–ú',
              'Dorothy': '–ñ', 'Josh': '–ú', 'Arnold': '–ú', 'Charlotte': '–ñ', 'Matilda': '–ñ', 'Matthew': '–ú',
              'James': '–ú',
              'Joseph': '–ú', 'Jeremy': '–ú', 'Michael': '–ú', 'Ethan': '–ú', 'Gigi': '–ñ', 'Freya': '–ñ', 'Grace': '–ñ',
              'Daniel': '–ú', 'Serena': '–ñ', 'Adam': '–ú', 'Nicole': '–ñ', 'Jessie': '–ú', 'Ryan': '–ú', 'Sam': '–ú',
              'Glinda': '–ñ',
              'Giovanni': '–ú', 'Mimi': '–ñ'}


class SQL_Keys:
    AIname = "AIname"
    reload = "reload"
    owner_id = "owner_id"
    delay_record = "delay_record"
    gpt_mode = "gpt_mode"
    voice_keys = "voice_keys"

    # [Default]
    # reload
    # owner_id
    # AIname
    # delay_record
    # gpt_role
    # [User]
    # gpt_mode


class DiscordUser:
    def __init__(self, ctx):
        self.ctx = ctx
        self.id = ctx.author.id
        self.name = ctx.author.name
        character_name = asyncio.run(set_get_config_all(self.id, SQL_Keys.AIname))
        self.character = Character(character_name)
        self.gpt_mode = asyncio.run(set_get_config_all(self.id, SQL_Keys.gpt_mode))
        self.owner = str(self.id) in asyncio.run(set_get_config_all("Default", SQL_Keys.owner_id)).split(";")

    async def set_user_config(self, key, value=None):
        await set_get_config_all(self.id, key, value)
        await self.update_values()

    async def update_values(self):
        self.gpt_mode = await set_get_config_all(self.id, SQL_Keys.gpt_mode)
        character_name = await set_get_config_all(self.id, SQL_Keys.AIname)
        self.character = Character(character_name)


@bot.event
async def on_ready():
    import torch
    logger.logging('Status: online', "\ncuda:", torch.cuda.device_count(), color=Color.GREEN)
    await bot.change_presence(activity=discord.Activity(
        type=discord.ActivityType.listening, name='AI-covers'))
    id = (await set_get_config_all("Default", SQL_Keys.owner_id)).split(";")[0]
    logger.logging("ID:", id, color=Color.GRAY)
    if not id == "True":
        user = await bot.fetch_user(int(id))
        await user.send("–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω!")


@bot.event
async def on_message(message):
    ctx = await bot.get_context(message)
    if message.author.id == 1165023027847757836:  # minecraft chat bot
        text = message.content
        if text.startswith("\\themer "):
            text = text.replace("\\themer ", "")

            guild_id = ctx.guild.id
            if guild_id in dialogs:
                dialog = dialogs[guild_id]
                if dialog:
                    dialog.theme = text
                    await ctx.send("–ò–∑–º–µ–Ω–µ–Ω–∞ —Ç–µ–º–∞:" + text)
            return

        _, text = await moderate_mat_in_sentence(text)

        user = text[:text.find(":")]
        if "[" in text and "]" in text:
            text = re.sub(r'[.*?]', '', text)
        chatGPT = ChatGPT()
        answer = await chatGPT.run_all_gpt(f"{user}:{text}", user_id=user)
        await ctx.send(answer)
        return

    # other users
    if message.author.bot:
        return
    if bot.user in message.mentions:
        text = message.content
        try:
            # –ø–æ–ª—É—á–µ–Ω–∏–µ, –Ω–∞ –∫–∞–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∏–ª–∏
            if message.reference:
                referenced_message = await message.channel.fetch_message(message.reference.message_id)
                reply_on_message = referenced_message.content
                if "||" in reply_on_message:
                    reply_on_message = re.sub(r'\|\|.*?\|\|', '', reply_on_message)
                text += f" (–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–∞—à–µ —Å–æ–æ–±—â–µ–Ω–∏–µ \"{reply_on_message}\")"

            _, text_out = await moderate_mat_in_sentence(text)

            user = DiscordUser(ctx)
            gpt_role = user.character.gpt_info

            chatGPT = ChatGPT()
            answer = await chatGPT.run_all_gpt(f"{user.name}:{text}", user_id=user.id, gpt_role=gpt_role)
            await ctx.send(answer)
            audio_player = AudioPlayerDiscord(ctx)
            if audio_player.voice_client and user.character:
                audio_path_1 = f"{user.id}-{user.character.name}-message-row.mp3"
                audio_path_2 = f"{user.id}-{user.character.name}-message.mp3"
                await user.character.text_to_speech(answer, audio_path=audio_path_1, output_name=audio_path_2)
                await audio_player.play(audio_path_2)

                os.remove(audio_path_1)
                os.remove(audio_path_2)
        except Exception as e:
            traceback_str = traceback.format_exc()
            logger.logging(str(traceback_str), color=Color.RED)
            await ctx.send(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–º–∞–Ω–¥–µ say —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ {message}: {e}")
    await bot.process_commands(message)


@bot.slash_command(name="help", description='–ø–æ–º–æ—â—å –ø–æ –∫–æ–º–∞–Ω–¥–∞–º')
async def help_command(
        ctx,
        command: Option(str, description='–ù—É–∂–Ω–∞—è –≤–∞–º –∫–æ–º–∞–Ω–¥–∞', required=True,
                        choices=['say', 'read_messages', 'ai_cover', 'tts', 'add_voice', 'create_dialog',
                                 'change_image', 'change_video', 'join', 'disconnect', 'record', 'stop_recording',
                                 'pause', 'skip', 'bark']
                        ),
):
    if command == "say":
        await ctx.respond(
            "# /say\n(–°–¥–µ–ª–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∫ GPT)\n**text - –∑–∞–ø—Ä–æ—Å –¥–ª—è GPT**\ngpt_mode\*:\n- –º–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤ / –±—ã—Å—Ç—Ä—ã–π –æ—Ç–≤–µ—Ç\n")
        await ctx.send("\* - –ø–∞—Ä–∞–º–µ—Ç—Ä —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è")
    elif command == "read_messages":
        await ctx.respond("# /read_messages\n(–ü—Ä–æ—á–∏—Ç–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ —á—Ç–æ-—Ç–æ —Å –Ω–∏–º–∏ —Å–¥–µ–ª–∞—Ç—å)\n**number - "
                          "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∏—Ç–∞–µ–º—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π**\n**prompt - –∑–∞–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–µ—Ä–µ—Å–∫–∞–∂–∏ —ç—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏—è)**\n")
    elif command == "ai_cover":
        await ctx.respond(
            "# /ai_cover:\n(–ü–µ—Ä–µ–ø–µ—Ç—å/–æ–∑–≤—É—á–∏—Ç—å –≤–∏–¥–µ–æ –∏–ª–∏ –∞—É–¥–∏–æ)\n**url - —Å—Å—ã–ª–∫–∞ –Ω–∞ –≤–∏–¥–µ–æ**\n**audio_path - "
            "–∞—É–¥–∏–æ —Ñ–∞–π–ª**\nvoice - –≥–æ–ª–æ—Å–æ–≤–∞—è –º–æ–¥–µ–ª—å\ngender - –ø–æ–ª (–¥–ª—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏)\npitch - —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å (12 "
            "–∏–∑ –º—É–∂—Å–∫–æ–≥–æ –≤ –∂–µ–Ω—Å–∫–∏–π, -12 –∏–∑ –∂–µ–Ω—Å–∫–æ–≥–æ –≤ –º—É–∂—Å–∫–æ–π)\nindexrate - –∏–Ω–¥–µ–∫—Å –≥–æ–ª–æ—Å–∞ (—á–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –±–æ–ª—å—à–µ "
            "—á–µ—Ä—Ç —á–µ—Ä—Ç –≥–æ–ª–æ—Å–∞ –≥–æ–≤–æ—Ä—è—â–µ–≥–æ)\nrms_mix_rate - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à—É–º–∞ (—á–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –±–æ–ª—å—à–µ —à—É–º–∞)\nfilter_radius - "
            "—Ä–∞–∑–º–µ—Ä —Ñ–∏–ª—å—Ç—Ä–∞ (—á–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –±–æ–ª—å—à–µ —à—É–º–∞)\nmain_vocal, back_vocal, music - –≥—Ä–æ–º–∫–æ—Å—Ç—å –∫–∞–∂–¥–æ–π "
            "–∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫–∏\nroomsize, wetness, dryness - –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–µ–≤–µ—Ä–±–µ—Ä–∞—Ü–∏–∏\npalgo - rmvpe - –ª—É—á—à–∏–π, mangio-crepe "
            "- –±–æ–ª–µ–µ –ø–ª–∞–≤–Ω—ã–π\nhop - –¥–ª–∏–Ω–∞ –¥–ª—è —É—á–∏—Ç—ã–≤–∞–Ω–∏—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ (mangio-crepe)\ntime - –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–¥–ª—è "
            "–≤–æ–π—Å-—á–∞—Ç–∞)\noutput - link - —Å—Å–ª—ã–∫–∞ –Ω–∞ –∞—Ä—Ö–∏–≤, all_files - –≤—Å–µ "
            "—Ñ–∞–π–ª—ã, file - —Ç–æ–ª—å–∫–æ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª\nonly_voice_change - –ø—Ä–æ—Å—Ç–æ –∑–∞–º–µ–Ω–∏—Ç—å –≥–æ–ª–æ—Å, –±–µ–∑ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –≤–æ–∫–∞–ª–∞ "
            "–∏ –º—É–∑—ã–∫–∏\n")
    elif command == "tts":
        await ctx.respond(
            "# /tts\n(–û–∑–≤—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç)\n**text - –ø—Ä–æ–∏–∑–Ω–æ—Å–∏–º—ã–π —Ç–µ–∫—Å—Ç**\nvoice_name - –≥–æ–ª–æ—Å–æ–≤–∞—è –º–æ–¥–µ–ª—å\nspeed - "
            "–£—Å–∫–æ—Ä–µ–Ω–∏–µ/–∑–∞–º–µ–¥–ª–µ–Ω–∏–µ\nvoice_model - –ú–æ–¥–µ–ª—å –≥–æ–ª–æ—Å–∞ elevenlab\noutput - –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª –≤ —á–∞—Ç\n"
            "stability - –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –≥–æ–ª–æ—Å–∞ (0 - –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–π, 1 - —Å—Ç–∞–±–∏–ª—å–Ω—ã–π)\n"
            "similarity_boost - –ü–æ–≤—ã—à–µ–Ω–∏–µ —Å—Ö–æ–¥—Å—Ç–≤–∞ (0 - –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)\n"
            "style - –í—ã—Ä–∞–∂–µ–Ω–∏–µ (0 - –º–∞–ª–æ –ø–∞—É–∑ –∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è, 1 - –±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—É–∑ –∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è)\n")
    elif command == "add_voice":
        await ctx.respond("# /add_voice\n(–î–æ–±–∞–≤–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤—É—é –º–æ–¥–µ–ª—å)\n**url - —Å—Å—ã–ª–∫–∞ –Ω–∞ –º–æ–¥–µ–ª—å **\n**name - –∏–º—è –º–æ–¥–µ–ª–∏ "
                          "**\n**gender - –ø–æ–ª –º–æ–¥–µ–ª–∏ (–¥–ª—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏)**\ninfo - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —á–µ–ª–æ–≤–µ–∫–µ (–¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ GPT)\n"
                          "speed - —É—Å–∫–æ—Ä–µ–Ω–∏–µ/–∑–∞–º–µ–¥–ª–µ–Ω–∏–µ –ø—Ä–∏ /tts\nvoice_model - –º–æ–¥–µ–ª—å elevenlab\nchange_voice - True = "
                          "–∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Ç–µ–∫—É—â–∏–π –≥–æ–ª–æ—Å\ntxt_file - –±—ã—Å—Ç—Ä–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π *(–æ—Å—Ç–∞–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–∞–∫ 'url', 'gender', 'name'  –±—É–¥—É—Ç –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è)*, –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:\n"
                          "- –Ω–∞–ø–∏—à–∏—Ç–µ –≤ txt —Ñ–∞–π–ª–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è add_voice (1 –º–æ–¥–µ–ª—å - 1 —Å—Ç—Ä–æ–∫–∞), –ø—Ä–∏–º–µ—Ä:")
        await send_file(ctx, "add_voice_args.txt")
    elif command == "create_dialog":
        await ctx.respond(
            "# /create_dialog\n(–°–æ–∑–¥–∞—Ç—å –¥–∏–∞–ª–æ–≥ –≤ –≤–æ–π—Å-—á–∞—Ç–µ)\n**names - —É—á–∞—Å—Ç–Ω–∏–∫–∏ –¥–∏–∞–ª–æ–≥–∞ "
            "—á–µ—Ä–µ–∑ ';' - —Å–ø–∏—Å–æ–∫ –≥–æ–ª–æ—Å–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –ù–∞–ø—Ä–∏–º–µ—Ä, –£—á–∞—Å—Ç–Ω–∏–∫1;–£—á–∞—Å—Ç–Ω–∏–∫2**\ntheme - –¢–µ–º–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ "
            "(–º–æ–∂–µ—Ç –∏–∑–º–µ–Ω–∏—Ç—å—Å—è)\nprompt - –ü–æ—Å—Ç–æ—è–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á—Ç–æ –æ–Ω–∏ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–º –º–µ—Å—Ç–µ)\n")
    elif command == "change_image":
        await ctx.respond("# /change_image \n(–ò–∑–º–µ–Ω–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)\n**image - –∫–∞—Ä—Ç–∏–Ω–∫–∞, –∫–æ—Ç–æ—Ä—É—é –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å**\n"
                          "**prompt - –ó–∞–ø—Ä–æ—Å **\nnegative_prompt - –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å\nsteps - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ (–±–æ–ª—å—à–µ - "
                          "–ª—É—á—à–µ, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ)\nseed - —Å–∏–¥ (–µ—Å–ª–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Å–∏–¥ –∏ —Ñ–∞–π–ª, —Ç–æ –ø–æ–ª—É—á–∏—Ç—Å—è —Ç–æ –∂–µ —Å–∞–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)"
                          "\nx - —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –ø–æ X\ny - —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –ø–æ Y\nstrength - —Å–∏–ª–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è\nstrength_prompt - —Å–∏–ª–∞ –¥–ª—è "
                          "–∑–∞–ø—Ä–æ—Å–∞\nstrength_negative_prompt - —Å–∏–ª–∞ –¥–ª—è –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞\nrepeats - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        import torch
        cuda_avaible = torch.cuda.device_count()
        if len(image_generators) == 0:
            await ctx.send(f"–ó–∞–≥—Ä—É–∑–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –Ω–∞ {cuda_avaible}-–æ–π –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–µ")
            image_generators.append(Image_Generator(cuda_avaible - 1))

    elif command == "change_video":
        await ctx.respond(
            "# /change_video \n(–ò–∑–º–µ–Ω–∏—Ç—å –≤–∏–¥–µ–æ **–ü–û–ö–ê–î–†–û–í–û**)\n**video_path - –≤–∏–¥–µ–æ—Ñ–∞–π–ª**\n**fps - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ "
            "–∫–∞–¥—Ä–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É**\n**extension - –ö–∞—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ **\n**prompt - –ó–∞–ø—Ä–æ—Å**\nnegative_prompt - "
            "–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å\nsteps - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ (–±–æ–ª—å—à–µ - –ª—É—á—à–µ, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ)\nseed - —Å–∏–¥ (–µ—Å–ª–∏ "
            "–æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Å–∏–¥ –∏ —Ñ–∞–π–ª, —Ç–æ –ø–æ–ª—É—á–∏—Ç—Å—è —Ç–æ –∂–µ —Å–∞–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)\nstrength - —Å–∏–ª–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è\n"
            "strength_prompt - —Å–∏–ª–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞\nstrength_negative_prompt - —Å–∏–ª–∞ –¥–ª—è –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞\n"
            "voice - –≥–æ–ª–æ—Å–æ–≤–∞—è –º–æ–¥–µ–ª—å\n")
        import torch
        cuda_avaible = torch.cuda.device_count()
        if len(image_generators) == 0:
            for i in range(cuda_avaible):
                await ctx.send(f"–ó–∞–≥—Ä—É–∑–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –Ω–∞ {i+1}-–æ–π –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–µ")
                image_generators.append(Image_Generator(i))
    elif command == "join":
        await ctx.respond("# /join\n - –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å—Å—è –∫ –≤–∞–º –≤ –≤–æ–π—Å-—á–∞—Ç–µ")
    elif command == "disconnect":
        await ctx.respond("# /disconnect\n - –≤—ã–π—Ç–∏ –∏–∑ –≤–æ–π—Å-—á–∞—Ç–∞")
    elif command == "record":
        await ctx.respond("# /record\n - –≤–∫–ª—é—á–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ –º–∏–∫—Ä–æ—Ñ–æ–Ω")
    elif command == "stop_recording":
        await ctx.respond("# /stop_recording\n  - –≤—ã–∫–ª—é—á–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ –º–∏–∫—Ä–æ—Ñ–æ–Ω")
    elif command == "pause":
        await ctx.respond("# /pause\n - –ø–∞—É–∑–∞ / –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞")
    elif command == "skip":
        await ctx.respond("# /skip\n - –ø—Ä–æ–ø—É—Å–∫ –∞—É–¥–∏–æ")
    elif command == "bark":
        await ctx.respond("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞—É–¥–∏–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ—á–∏.\n"
                          "**text** - –¢–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω –≤ —Ä–µ—á—å.\n"
                          "speaker - –ú–æ–¥–µ–ª—å –≥–æ–ª–æ—Å–∞\n"
                          "gen_temp - –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")


@bot.slash_command(name="change_video",
                   description='–ü–µ—Ä–µ—Ä–∏—Å–æ–≤–∞—Ç—å –∏ –ø–µ—Ä–µ–æ–∑–≤—É—á–∏—Ç—å –≤–∏–¥–µ–æ')
async def __change_video(
        ctx,
        video_path: Option(discord.SlashCommandOptionType.attachment, description='–§–∞–π–ª —Å –≤–∏–¥–µ–æ',
                           required=True),
        fps: Option(int, description='–ß–∞—Å—Ç–æ—Ç–∞ –∫–∞–¥—Ä–æ–≤ (–û–ß–ï–ù–¨ –≤–ª–∏—è–µ—Ç –Ω–∞ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è))', required=True,
                    choices=[30, 15, 10, 6, 5, 3, 2, 1]),
        extension: Option(str, description='–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ (—Å–∏–ª—å–Ω–æ –≤–ª–∏—è–µ—Ç –Ω–∞ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è)', required=True,
                          choices=["144p", "240p", "360p", "480p", "720p"]),
        prompt: Option(str, description='–∑–∞–ø—Ä–æ—Å', required=True),
        negative_prompt: Option(str, description='–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å', default="NSFW", required=False),
        steps: Option(int, description='—á–∏—Å–ª–æ —à–∞–≥–æ–≤', required=False,
                      default=30,
                      min_value=1,
                      max_value=500),
        seed: Option(int, description='—Å–∏–¥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è', required=False,
                     default=random.randint(1, 1000000),
                     min_value=1,
                     max_value=1000000),
        strength: Option(float, description='–Ω–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω—ã –±—É–¥—É—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è', required=False,
                         default=0.15, min_value=0,
                         max_value=1),
        strength_prompt: Option(float,
                                description='–õ–£–ß–®–ï –ù–ï –¢–†–û–ì–ê–¢–¨! –ù–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç',
                                required=False,
                                default=0.85, min_value=0.1,
                                max_value=1),
        strength_negative_prompt: Option(float,
                                         description='–õ–£–ß–®–ï –ù–ï –¢–†–û–ì–ê–¢–¨! –ù–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç',
                                         required=False,
                                         default=1, min_value=0.1,
                                         max_value=1),
        voice_name: Option(str, description='–ì–æ–ª–æ—Å –¥–ª—è –≤–∏–¥–µ–æ', required=False, default="None")
):
    cuda_all = None
    try:
        await ctx.defer()

        # –æ—à–∏–±–∫–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        voices = (await set_get_config_all("Sound", "voices")).replace("\"", "").replace(",", "").split(";")
        if voice_name not in voices:
            await ctx.respond("–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å –∏–∑ —Å–ø–∏—Å–∫–∞: " + ';'.join(voices))
            return

        if not image_generators:
            await ctx.respond("–º–æ–¥–µ–ª—å –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–æ–∫ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return

        filename = f"{ctx.author.id}.mp4"
        await video_path.save(filename)
        # —Å–∫–æ–ª—å–∫–æ –∫–∞–¥—Ä–æ–≤ –±—É–¥–µ—Ç –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
        video_clip = VideoFileClip(filename)
        total_frames = int((video_clip.fps * video_clip.duration) / (30 / fps))
        max_frames = int(await set_get_config_all("Video", "max_frames", None))
        if max_frames <= total_frames:
            await ctx.send(
                f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∫–∞–¥—Ä–æ–≤, —Å–Ω–∏–∑—å—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä FPS! –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –≤ –≤–∏–¥–µ–æ: {max_frames}. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ —É –≤–∞—Å - {total_frames}")
            return

        # –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—ã
        cuda_avaible = await cuda_manager.check_cuda_images()
        if cuda_avaible == 0:
            await ctx.respond("–ù–µ—Ç —Å–≤–æ–±–æ–¥–Ω—ã—Ö –≤–∏–¥–µ–æ–∫–∞—Ä—Ç")
            return
        else:
            await ctx.respond(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {cuda_avaible} –≤–∏–¥–µ–æ–∫–∞—Ä—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ")

        cuda_all = []
        for i in range(cuda_avaible):
            cuda_all.append(await cuda_manager.use_cuda_images())

        # run timer
        timer = Time_Count()

        if len(cuda_all) > 1:
            seconds = total_frames * 13 / len(cuda_all)
        else:
            seconds = total_frames * 16
        if seconds >= 3600:
            hours = seconds // 3600
            minutes = (seconds % 3600) // 60
            remaining_seconds = seconds % 60
            if minutes == 0 and remaining_seconds == 0:
                time_spend = f"{hours} —á–∞—Å–æ–≤"
            elif remaining_seconds == 0:
                time_spend = f"{hours} —á–∞—Å–æ–≤, {minutes} –º–∏–Ω—É—Ç"
            elif minutes == 0:
                time_spend = f"{hours} —á–∞—Å–æ–≤, {remaining_seconds} —Å–µ–∫—É–Ω–¥"
            else:
                time_spend = f"{hours} —á–∞—Å–æ–≤, {minutes} –º–∏–Ω—É—Ç, {remaining_seconds} —Å–µ–∫—É–Ω–¥"
        elif seconds >= 60:
            minutes = seconds // 60
            remaining_seconds = seconds % 60
            if remaining_seconds == 0:
                time_spend = f"{minutes} –º–∏–Ω—É—Ç"
            else:
                time_spend = f"{minutes} –º–∏–Ω—É—Ç, {remaining_seconds} —Å–µ–∫—É–Ω–¥"
        else:
            time_spend = f"{seconds} —Å–µ–∫—É–Ω–¥"
        await ctx.send(f"–í–∏–¥–µ–æ –±—É–¥–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è ~{time_spend}")
        print("params suc")
        # wait for answer
        from video_change import video_pipeline
        video_path = await video_pipeline(video_path=filename, fps_output=fps, video_extension=extension, prompt=prompt,
                                          voice_name=voice_name, video_id=ctx.author.id, cuda_all=cuda_all,
                                          strength_negative_prompt=strength_negative_prompt,
                                          strength_prompt=strength_prompt,
                                          strength=strength, seed=seed, steps=steps, negative_prompt=negative_prompt)

        await ctx.send("–í–æ—Ç –∫–∞–∫ —è –∏–∑–º–µ–Ω–∏–ª –≤–∞—à–µ –≤–∏–¥–µ–æüñå. –ü–æ—Ç—Ä–∞—á–µ–Ω–æ " + timer.count_time())
        await send_file(ctx, video_path)
        # –æ—Å–≤–æ–±–æ–∂–¥–∞–µ–º –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—ã
        for i in cuda_all:
            await cuda_manager.stop_use_cuda_images(i)
    except Exception as e:
        await ctx.send(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏ (—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\
                          {fps, extension, prompt, negative_prompt, steps, seed, strength, strength_prompt, voice_name}\
                          ): {e}")
        if cuda_all:
            for i in range(cuda_avaible):
                await cuda_manager.stop_use_cuda_images(i)

        traceback_str = traceback.format_exc()
        await logger.logging(str(traceback_str), Color.RED)
        raise e


@bot.slash_command(name="change_image", description='–∏–∑–º–µ–Ω–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é')
async def __image(ctx,
                  image: Option(discord.SlashCommandOptionType.attachment, description='–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ',
                                required=True),
                  prompt: Option(str, description='–∑–∞–ø—Ä–æ—Å', required=True),
                  negative_prompt: Option(str, description='–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å', default="NSFW", required=False),
                  steps: Option(int, description='—á–∏—Å–ª–æ —à–∞–≥–æ–≤', required=False,
                                default=60,
                                min_value=1,
                                max_value=500),
                  seed: Option(int, description='—Å–∏–¥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è', required=False,
                               default=None,
                               min_value=1,
                               max_value=9007199254740991),
                  x: Option(int,
                            description='–∏–∑–º–µ–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∫–∞—Ä—Ç–∏–Ω–∫–∏ –ø–æ x',
                            required=False,
                            default=None, min_value=64,
                            max_value=768),
                  y: Option(int,
                            description='–∏–∑–º–µ–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∫–∞—Ä—Ç–∏–Ω–∫–∏ –ø–æ y',
                            required=False,
                            default=None, min_value=64,
                            max_value=768),
                  strength: Option(float, description='–Ω–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω—ã –±—É–¥—É—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è', required=False,
                                   default=0.5, min_value=0,
                                   max_value=1),
                  strength_prompt: Option(float,
                                          description='–õ–£–ß–®–ï –ù–ï –¢–†–û–ì–ê–¢–¨! –ù–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç',
                                          required=False,
                                          default=0.85, min_value=0.1,
                                          max_value=1),
                  strength_negative_prompt: Option(float,
                                                   description='–õ–£–ß–®–ï –ù–ï –¢–†–û–ì–ê–¢–¨! –ù–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç',
                                                   required=False,
                                                   default=1, min_value=0.1,
                                                   max_value=1),
                  repeats: Option(int,
                                  description='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤',
                                  required=False,
                                  default=1, min_value=1,
                                  max_value=16)
                  ):
    async def get_image_dimensions(file_path):
        with Image.open(file_path) as img:
            sizes = img.size
        return str(sizes).replace("(", "").replace(")", "").replace(" ", "").split(",")

    await ctx.defer()
    if not image_generators:
        await ctx.respond("–º–æ–¥–µ–ª—å –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–æ–∫ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        return

    for i in range(repeats):
        cuda_number = None
        try:
            try:
                cuda_number = await cuda_manager.use_cuda_images()
            except Exception:
                await ctx.respond("–ù–µ—Ç —Å–≤–æ–±–æ–¥–Ω—ã—Ö –≤–∏–¥–µ–æ–∫–∞—Ä—Ç")
                return

            timer = Time_Count()
            input_image = "images/image" + str(ctx.author.id) + ".png"
            await image.save(input_image)
            # get image size and round to 64
            if x is None or y is None:
                x, y = await get_image_dimensions(input_image)
                x = int(x)
                y = int(y)
                # —Å–∫—ç–π–ª–∏–Ω–≥ –≤–æ –∏–∑–±–µ–∂–∞–Ω–∏—è –æ—à–∏–±–æ–∫ –∏–∑-–∑–∞ –Ω–µ—Ö–≤–∞—Ç–∫–∏ –ø–∞–º—è—Ç–∏
                scale_factor = (1000000 / (x * y)) ** 0.5
                x = int(x * scale_factor)
                y = int(y * scale_factor)
            if not x % 64 == 0:
                x = ((x // 64) + 1) * 64
            if not y % 64 == 0:
                y = ((y // 64) + 1) * 64
            print("X:", x, "Y:", y)
            # loading params
            if seed is None or repeats > 1:
                seed_current = random.randint(1, 9007199254740991)
            else:
                seed_current = seed
            image_path = image_generators[cuda_number].generate_image(prompt, negative_prompt, x, y, steps, seed,
                                                                      strength,
                                                                      strength_prompt,
                                                                      strength_negative_prompt, input_image)

            # –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º
            text = "–í–æ—Ç –∫–∞–∫ —è –∏–∑–º–µ–Ω–∏–ª –≤–∞—à–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µüñå. –ü–æ—Ç—Ä–∞—á–µ–Ω–æ " + timer.count_time() + f"—Å–∏–¥:{seed_current}"
            if repeats == 1:
                await ctx.respond(text)
            else:
                await ctx.send(text)

            await send_file(ctx, image_path, delete_file=True)
            # –ø–µ—Ä–µ—Å—Ç–∞—ë–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—É
            await cuda_manager.stop_use_cuda_images(cuda_number)
        except Exception as e:
            traceback_str = traceback.format_exc()
            await logger.logging(str(traceback_str), Color.RED)
            await ctx.send(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏ (—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\
                              {prompt, negative_prompt, steps, x, y, strength, strength_prompt, strength_negative_prompt}): {e}")
            # –ø–µ—Ä–µ—Å—Ç–∞—ë–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—É
            if not cuda_number is None:
                await cuda_manager.stop_use_cuda_images(cuda_number)

@bot.slash_command(name="config", description='–∏–∑–º–µ–Ω–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥')
async def __config(
        ctx,
        section: Option(str, description='—Å–µ–∫—Ü–∏—è', required=True),
        key: Option(str, description='–∫–ª—é—á', required=True),
        value: Option(str, description='–∑–Ω–∞—á–µ–Ω–∏–µ', required=False, default=None)
):
    try:
        await ctx.defer()
        owner_ids = (await set_get_config_all("Default", SQL_Keys.owner_id)).split(";")
        if str(ctx.author.id) not in owner_ids:
            await ctx.author.send("–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â—ë–Ω")
            return
        result = await set_get_config_all(section, key, value)
        if value is None:
            await ctx.respond(result)
        else:
            await ctx.respond(section + " " + key + " " + value)
    except Exception as e:
        traceback_str = traceback.format_exc()
        logger.logging(str(traceback_str), color=Color.RED)
        await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∫–æ–Ω—Ñ–∏–≥–∞ (—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏{section},{key},{value}): {e}")


@bot.slash_command(name="read_messages", description='–ß–∏—Ç–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ x —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ —á–∞—Ç–∞ –∏ –¥–µ–ª–∞–µ—Ç –ø–æ –Ω–∏–º –≤—ã–≤–æ–¥')
async def __read_messages(
        ctx,
        number: Option(int, description='–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π (–æ—Ç 1 –¥–æ 100', required=True, min_value=1,
                       max_value=100),
        prompt: Option(str, description='–ü—Ä–æ–º–ø—Ç –¥–ª—è GPT. –ö–∞–∫–æ–π –≤—ã–≤–æ–¥ —Å–¥–µ–ª–∞—Ç—å –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—è–º (–ø–µ—Ä–µ–≤–µ—Å—Ç–∏, –ø–µ—Ä–µ—Å–∫–∞–∑–∞—Ç—å)',
                       required=True)
):
    await ctx.defer()
    try:
        messages = []
        async for message in ctx.channel.history(limit=number):
            messages.append(f"–°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {message.author.name}: {message.content}")
        # –û—Ç –Ω–∞—á–∞–ª–∞ –¥–æ –∫–æ–Ω—Ü–∞
        messages = messages[::-1]
        # —É–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ / –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        messages = messages[:number - 1]
        chatGPT = ChatGPT()
        answer = await chatGPT.run_all_gpt(f"{prompt}. –í–æ—Ç –∏—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π:{messages}", user_id=0)
        await ctx.respond(answer)
    except Exception as e:
        traceback_str = traceback.format_exc()
        logger.logging(str(traceback_str), color=Color.RED)
        await ctx.respond(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")


@bot.slash_command(name="join", description='–ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å—Å—è –∫ –≥–æ–ª–æ—Å–æ–≤–æ–º—É –∫–∞–Ω–∞–ª—É')
async def join(ctx):
    await ctx.defer()
    await AudioPlayerDiscord(ctx).join_channel()
    await ctx.respond("–ü—Ä–∏—Å–æ–µ–¥–∏–Ω—è—é—Å—å")


@bot.slash_command(name="disconnect", description='–≤—ã–π—Ç–∏ –∏–∑ –≤–æ–π—Å-—á–∞—Ç–∞')
async def disconnect(ctx):
    await ctx.defer()

    # –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏
    author_id = ctx.author.id
    if author_id in recognizers:
        recognizer = recognizers[author_id]
        if recognizer:
            await recognizer.stop_recording()

    await AudioPlayerDiscord(ctx).disconnect()
    await ctx.respond("–ü–æ–∫–∏–¥–∞—é –≤–æ–π—Å-—á–∞—Ç")


@bot.slash_command(name="pause", description='–ø–∞—É–∑–∞/–≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ (–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–∏–∞–ª–æ–≥–∞)')
async def pause(ctx):
    await ctx.defer()
    guild_id = ctx.guild.id
    if guild_id in dialogs:
        dialog = dialogs[guild_id]
        if dialog:
            await dialog.stop_dialog()
            await ctx.respond("–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –¥–∏–∞–ª–æ–≥")
            return
    result = await AudioPlayerDiscord(ctx).stop()
    await ctx.respond(result)


@bot.slash_command(name="skip", description='–ø—Ä–æ–ø—É—Å–∫ –∞—É–¥–∏–æ')
async def skip(ctx):
    await ctx.defer()
    result = await AudioPlayerDiscord(ctx).skip()
    await ctx.respond(result)


@bot.slash_command(name="say", description='–°–∫–∞–∑–∞—Ç—å —Ä–æ–±–æ—Ç—É —á—Ç–æ-—Ç–æ')
async def __say(
        ctx,
        text: Option(str, description='–°–∞–º —Ç–µ–∫—Å—Ç/–∫–æ–º–∞–Ω–¥–∞. –°–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥: \\help-say', required=True),
        gpt_mode: Option(str, description="–º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è GPT. –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–∏—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö!",
                         choices=["–±—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º", "–º–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤ (–º–µ–¥–ª–µ–Ω–Ω—ã–π)", "—ç–∫–æ–Ω–æ–º–Ω—ã–π —Ä–µ–∂–∏–º"], required=False,
                         default=None)
):
    # ["fast", "all", "None"], ["–±—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º", "–º–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤ (–º–µ–¥–ª–µ–Ω–Ω—ã–π)", "–≠–∫–æ–Ω–æ–º–Ω—ã–π —Ä–µ–∂–∏–º"]
    user = DiscordUser(ctx)
    if gpt_mode:
        gpt_mode = gpt_mode.replace("–±—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º", "Fast").replace("–º–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤ (–º–µ–¥–ª–µ–Ω–Ω—ã–π)", "All").replace(
            "—ç–∫–æ–Ω–æ–º–Ω—ã–π —Ä–µ–∂–∏–º", "None")
        await user.set_user_config(SQL_Keys.gpt_mode, gpt_mode)
    else:
        gpt_mode = user.gpt_mode

    try:
        await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')
        if not gpt_mode:
            gpt_mode = "Fast"
        _, text = await moderate_mat_in_sentence(text)

        gpt_role = user.character.gpt_info

        chatGPT = ChatGPT()
        answer = await chatGPT.run_all_gpt(f"{user.name}:{text}", user_id=user.id, gpt_role=gpt_role, mode=gpt_mode)
        await ctx.send(answer)
        audio_player = AudioPlayerDiscord(ctx)
        if user.character:
            audio_path_1 = f"{user.id}-{user.character.name}-say-row.mp3"
            audio_path_2 = f"{user.id}-{user.character.name}-say.mp3"
            await user.character.text_to_speech(answer, audio_path=audio_path_1, output_name=audio_path_2)
            await audio_player.play(audio_path_2)

            os.remove(audio_path_1)
            os.remove(audio_path_2)
    except Exception as e:
        traceback_str = traceback.format_exc()
        logger.logging(str(traceback_str), color=Color.RED)
        await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–º–∞–Ω–¥–µ say (—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏{text}): {e}")


async def get_voice_list():
    from cover_gen import rvc_models_dir
    directory_path = rvc_models_dir

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–º–µ–Ω –ø–∞–ø–æ–∫
    return [folder for folder in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, folder))]


@bot.slash_command(name="tts", description='–ó–∞—Å—Ç–∞–≤–∏—Ç—å –±–æ—Ç–∞ –≥–æ–≤–æ—Ä–∏—Ç—å –≤—Å—ë, —á—Ç–æ –∑–∞—Ö–æ—á–µ—à—å')
async def __tts(
        ctx,
        text: Option(str, description='–¢–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏', required=True),
        voice_name: Option(str, description='–ì–æ–ª–æ—Å –¥–ª—è –æ–∑–≤—É—á–∫–∏', required=False, default=None),
        speed: Option(float, description='–£—Å–∫–æ—Ä–µ–Ω–∏–µ –≥–æ–ª–æ—Å–∞', required=False, default=None, min_value=1, max_value=3),
        voice_model_eleven: Option(str, description=f'–ö–∞–∫–∞—è –º–æ–¥–µ–ª—å elevenlabs –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞', required=False,
                                   default=None),
        stability: Option(float, description='–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –≥–æ–ª–æ—Å–∞', required=False, default=None, min_value=0,
                          max_value=1),
        similarity_boost: Option(float, description='–ü–æ–≤—ã—à–µ–Ω–∏–µ —Å—Ö–æ–¥—Å—Ç–≤–∞', required=False, default=None, min_value=0,
                                 max_value=1),
        style: Option(float, description='–í—ã—Ä–∞–∂–µ–Ω–∏–µ', required=False, default=None, min_value=0, max_value=1),
        output: Option(str, description='–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç', required=False,
                       choices=["1 —Ñ–∞–π–ª (RVC)", "2 —Ñ–∞–π–ª–∞ (RVC & elevenlabs/GTTS)", "None"], default="1 —Ñ–∞–π–ª (RVC)"),
        pitch: Option(int, description="–ò–∑–º–µ–Ω–∏—Ç—å —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å", required=False, default=0, min_value=-24,
                      max_value=24),
        palgo: Option(str, description='–ê–ª–≥–æ—Ä–∏—Ç–º. Rmvpe - –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç, mangio-crepe - –±–æ–ª–µ–µ –º—è–≥–∫–∏–π –≤–æ–∫–∞–ª',
                      required=False,
                      choices=['rmvpe', 'mangio-crepe'], default="rmvpe"),

):
    user = DiscordUser(ctx)
    if not voice_name:
        voice_name = user.character.name
    elif not user.character.name == voice_name:
        await ctx.send("–û–±–Ω–æ–≤–ª–µ–Ω–∞ –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –Ω–∞:" + voice_name)
        await user.set_user_config(SQL_Keys.AIname, voice_name)

    voices = await get_voice_list()
    if str(voice_name) not in voices:
        return await ctx.response.send_message("–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å –¥–ª—è –æ–∑–≤—É—á–∫–∏ (–∏–ª–∏ /add_voice): " + ';'.join(voices))

    if voice_model_eleven == "All":
        voice_models = ALL_VOICES.keys()
    else:
        if voice_model_eleven is None:
            voice_model_eleven = user.character.voice_model_eleven
            if voice_model_eleven is None:
                return await ctx.response.send_message(
                    f"–ì–æ–ª–æ—Å–æ–≤–∞—è –º–æ–¥–µ–ª—å –ø–µ—Ä—Å–æ–Ω–∞–∂–∞: {voice_model_eleven}, —á—Ç–æ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º–æ")
        if voice_model_eleven not in ALL_VOICES.keys():
            await ctx.response.send_message("–°–ø–∏—Å–æ–∫ –≥–æ–ª–æ—Å–æ–≤ elevenlabs: \n" + ';'.join(ALL_VOICES.keys()))
            return
        voice_models = [voice_model_eleven]
    character = user.character

    try:

        await ctx.response.send_message('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...' + voice_name)
        # cuda_number = await cuda_manager.use_cuda()
        await character.load_voice(0, speed=speed, stability=stability, similarity_boost=similarity_boost,
                                   style=style, pitch=pitch, algo=palgo)
        for voice_model in voice_models:
            audio_path_1 = f"{user.id}-{voice_model}-tts-row.mp3"
            audio_path_2 = f"{user.id}-{voice_model}-tts.mp3"
            timer = Time_Count()
            character.voice.voice_model_eleven = voice_model
            # logger.logging("text to speech temp-3", text, color=Color.GRAY)
            mat_found, text = await moderate_mat_in_sentence(text)
            # logger.logging("text to speech temp-2", text, color=Color.GRAY)
            if mat_found:
                await ctx.respond("–¢–∞–∫–æ–µ —Ç–æ—á–Ω–æ –Ω–µ–ª—å–∑—è –ø—Ä–æ–∏–∑–Ω–æ—Å–∏—Ç—å!")
                return
            # –∑–∞–ø—É—Å–∫–∞–µ–º TTS
            await character.text_to_speech(text, audio_path=audio_path_1, output_name=audio_path_2)
            # –ø–µ—Ä–µ—Å—Ç–∞—ë–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—É

            await ctx.respond("–ü–æ—Ç—Ä–∞—á–µ–Ω–æ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É:" + timer.count_time())
            if output:
                if output.startswith("1"):
                    await send_file(ctx, audio_path_2)
                elif output.startswith("2"):
                    await send_file(ctx, audio_path_1)
                    await send_file(ctx, audio_path_2)

            os.remove(audio_path_1)
            os.remove(audio_path_2)
        # await cuda_manager.stop_use_cuda(cuda_number)
    except Exception as e:
        traceback_str = traceback.format_exc()
        logger.logging(str(traceback_str), color=Color.RED)
        await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ (—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ {text}): {e}")
        # –ø–µ—Ä–µ—Å—Ç–∞—ë–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—É
        # await cuda_manager.stop_use_cuda(cuda_number)


@bot.slash_command(name="bark", description='–¢–µ—Å—Ç–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ—á–∏ —Å –ø–æ–º–æ—â—å—é bark')
async def __bark(
        ctx,
        text: Option(str, description='–¢–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏', required=True),
        speaker: Option(int, description='–ì–æ–ª–æ—Å–æ–≤–∞—è –º–æ–¥–µ–ª—å bark', required=False, default=1, min_value=1,
                        max_value=8),
        gen_temp: Option(float, description='–ì–æ–ª–æ—Å–æ–≤–∞—è –º–æ–¥–µ–ª—å bark', required=False, default=0.6)
):
    global bark_model

    mat_found, text = await moderate_mat_in_sentence(text)
    if mat_found:
        await ctx.respond("–¢–∞–∫–æ–µ —Ç–æ—á–Ω–æ –Ω–µ–ª—å–∑—è –ø—Ä–æ–∏–∑–Ω–æ—Å–∏—Ç—å!")
        return

    timer = Time_Count()
    if bark_model is None:
        await ctx.respond('–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...')
        bark_model = BarkTTS()
        await ctx.respond('–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!')
    await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')
    await cuda_manager.use_cuda(index=0)
    try:
        audio_path = f"{ctx.author.id}-{speaker}-bark.mp3"
        await bark_model.text_to_speech_bark(text=text, speaker=speaker, gen_temp=gen_temp, audio_path=audio_path)
        await send_file(ctx, audio_path)
    except Exception as e:
        await ctx.send(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–º–∞–Ω–¥–µ bark: {e}')
    await ctx.respond(timer.count_time())
    await cuda_manager.stop_use_cuda(0)


async def send_output(ctx, audio_path, output, timer):
    await ctx.send("===–§–∞–π–ª—ã " + os.path.basename(audio_path)[:-4] + "===")
    output = output.replace(" ", "")
    # –∫–æ–Ω–µ—á–Ω—ã–π —Ñ–∞–π–ª
    if output == "file":
        await send_file(ctx, audio_path)
    # –≤—Å–µ —Ñ–∞–π–ª—ã
    elif output == "all_files":
        for filename in os.listdir(os.path.dirname(audio_path)):
            file_path = os.path.join(os.path.dirname(audio_path), filename)
            await send_file(ctx, file_path)
    # zip —Ñ–∞–π–ª –ø–æ —Å—Å—ã–ª–∫–µ
    elif output == "link":
        zip_name = os.path.dirname(audio_path) + f"/all_files.zip"
        with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for filename in os.listdir(os.path.dirname(audio_path)):
                file_path = os.path.join(os.path.dirname(audio_path), filename)
                if ".zip" in file_path:
                    continue
                zipf.write(file_path, os.path.basename(file_path))
        link = await get_link_to_file(zip_name, ctx)
        await ctx.send(f"–°—Å—ã–ª–∫–∞ –Ω–∞ —Å–∫–∞—á–∫—É:{link}")
    logger.logging("–ò–≥—Ä–∞–µ—Ç " + os.path.basename(audio_path)[:-4], color=Color.GREEN)
    audio_player = AudioPlayerDiscord(ctx)
    await audio_player.play(audio_path, is_send_file=False)

    if not output == "None":
        await ctx.send(timer.count_time())

    else:
        await ctx.send("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞")


async def run_ai_cover_gen_several_cuda(song_input, rvc_dirname, pitch, index_rate, filter_radius, rms_mix_rate,
                                        protect, pitch_detection_algo,
                                        crepe_hop_length, main_vol, backup_vol,
                                        inst_vol, reverb_size, reverb_wetness, reverb_dryness,
                                        reverb_damping,
                                        output_format, output, ctx):
    cuda_number = await cuda_manager.use_cuda()
    timer = Time_Count()
    audio_path = await run_ai_cover_gen(song_input=song_input, rvc_dirname=rvc_dirname, pitch=pitch,
                                        index_rate=index_rate,
                                        filter_radius=filter_radius, rms_mix_rate=rms_mix_rate, protect=protect,
                                        pitch_detection_algo=pitch_detection_algo,
                                        crepe_hop_length=crepe_hop_length, main_vol=main_vol, backup_vol=backup_vol,
                                        inst_vol=inst_vol, reverb_size=reverb_size, reverb_wetness=reverb_wetness,
                                        reverb_dryness=reverb_dryness,
                                        reverb_damping=reverb_damping,
                                        output_format=output_format, cuda_number=cuda_number)
    await send_output(ctx=ctx, audio_path=audio_path, output=output, timer=timer)
    await cuda_manager.stop_use_cuda(cuda_number)


@bot.slash_command(name="ai_cover", description='–ó–∞—Å—Ç–∞–≤–∏—Ç—å –±–æ—Ç–∞ –æ–∑–≤—É—á–∏—Ç—å –≤–∏–¥–µ–æ/—Å–ø–µ—Ç—å –ø–µ—Å–Ω—é')
async def __cover(
        ctx,
        url: Option(str, description='–°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∏–¥–µ–æ', required=False, default=None),
        audio_path: Option(discord.SlashCommandOptionType.attachment, description='–ê—É–¥–∏–æ—Ñ–∞–π–ª',
                           required=False, default=None),
        voice_name: Option(str, description='–ì–æ–ª–æ—Å –¥–ª—è –≤–∏–¥–µ–æ', required=False, default=None),
        pitch: Option(int, description='–ö–∞–∫—É—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å (–æ—Ç -24 –¥–æ 24) (–∏–ª–∏ —É–∫–∞–∑–∞—Ç—å gender)',
                      required=False,
                      default=None, min_value=-24, max_value=24),
        indexrate: Option(float, description='–ò–Ω–¥–µ–∫—Å –≥–æ–ª–æ—Å–∞ (–æ—Ç 0 –¥–æ 1)', required=False, default=0.5, min_value=0,
                          max_value=1),
        rms_mix_rate: Option(float, description='–ì—Ä–æ–º–∫–æ—Å—Ç—å —à—É–º–∞ (–æ—Ç 0 –¥–æ 1)', required=False, default=0.4, min_value=0,
                             max_value=1),
        filter_radius: Option(int,
                              description='–ù–∞—Å–∫–æ–ª—å–∫–æ –¥–∞–ª–µ–∫–æ –æ—Ç –∫–∞–∂–¥–æ–π —Ç–æ—á–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö –±—É–¥—É—Ç —É—á–∏—Ç—ã–≤–∞—Ç—å—Å—è –∑–Ω–∞—á–µ–Ω–∏—è... (–æ—Ç 1 –¥–æ 7)',
                              required=False, default=3, min_value=0,
                              max_value=7),
        main_vocal: Option(int, description='–ì—Ä–æ–º–∫–æ—Å—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –≤–æ–∫–∞–ª–∞ (–æ—Ç -50 –¥–æ 0)', required=False, default=0,
                           min_value=-50, max_value=0),
        back_vocal: Option(int, description='–ì—Ä–æ–º–∫–æ—Å—Ç—å –±—ç–∫–≤–æ–∫–∞–ª–∞ (–æ—Ç -50 –¥–æ 0)', required=False, default=0,
                           min_value=-50, max_value=0),
        music: Option(int, description='–ì—Ä–æ–º–∫–æ—Å—Ç—å –º—É–∑—ã–∫–∏ (–æ—Ç -50 –¥–æ 0)', required=False, default=0, min_value=-50,
                      max_value=0),
        roomsize: Option(float, description='–†–∞–∑–º–µ—Ä –ø–æ–º–µ—â–µ–Ω–∏—è (–æ—Ç 0 –¥–æ 1)', required=False, default=0.2, min_value=0,
                         max_value=1),
        wetness: Option(float, description='–í–ª–∞–∂–Ω–æ—Å—Ç—å (–æ—Ç 0 –¥–æ 1)', required=False, default=0.2, min_value=0,
                        max_value=1),
        dryness: Option(float, description='–°—É—Ö–æ—Å—Ç—å (–æ—Ç 0 –¥–æ 1)', required=False, default=0.8, min_value=0,
                        max_value=1),
        palgo: Option(str, description='–ê–ª–≥–æ—Ä–∏—Ç–º. Rmvpe - –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç, mangio-crepe - –±–æ–ª–µ–µ –º—è–≥–∫–∏–π –≤–æ–∫–∞–ª',
                      required=False,
                      choices=['rmvpe', 'mangio-crepe'], default="rmvpe"),
        hop: Option(int, description='–ö–∞–∫ —á–∞—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–æ–Ω–∞ –≤ mango-crepe', required=False, default=128,
                    min_value=64,
                    max_value=1280),
        output: Option(str, description='–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç',
                       choices=["—Å—Å—ã–ª–∫–∞ –Ω–∞ –≤—Å–µ —Ñ–∞–π–ª—ã", "—Ç–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç (1 —Ñ–∞–π–ª)", "–≤—Å–µ —Ñ–∞–π–ª—ã", "–Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å"],
                       required=False, default="—Ç–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç (1 —Ñ–∞–π–ª)"),
        only_voice_change: Option(bool,
                                  description='–ù–µ –∏–∑–≤–ª–µ–∫–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–ª –∏ –±—ç–∫–≤–æ–∫–∞–ª, –∏–∑–º–µ–Ω–∏—Ç—å –≥–æ–ª–æ—Å. –ù–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Å—Å—ã–ª–∫–∏',
                                  required=False, default=False)
):
    async def get_links_from_playlist(playlist_url):
        try:
            playlist = Playlist(playlist_url)
            playlist._video_regex = re.compile(r"\"url\":\"(/watch\?v=[\w-]*)")
            video_links = playlist.video_urls
            video_links = str(video_links).replace("'", "").replace("[", "").replace("]", "").replace(" ", "").replace(
                ",",
                ";")
            return video_links
        except Exception as e:
            traceback_str = traceback.format_exc()
            logger.logging(str(traceback_str), color=Color.RED)
            logger.logging(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –ø–ª–µ–π–ª–∏—Å—Ç–∞", color=Color.RED)
            return []

    param_string = None
    # ["link", "file", "all_files", "None"], ["—Å—Å—ã–ª–∫–∞ –Ω–∞ –≤—Å–µ —Ñ–∞–π–ª—ã", "—Ç–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç (1 —Ñ–∞–π–ª)", "–≤—Å–µ —Ñ–∞–π–ª—ã", "–Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å"]
    output = output.replace("—Å—Å—ã–ª–∫–∞ –Ω–∞ –≤—Å–µ —Ñ–∞–π–ª—ã", "link").replace("—Ç–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç (1 —Ñ–∞–π–ª)", "file").replace(
        "–≤—Å–µ —Ñ–∞–π–ª—ã", "all_files").replace("–Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å", "None")
    try:
        await ctx.defer()
        await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')
        user = DiscordUser(ctx)

        if not voice_name:
            voice_name = user.character.name
        elif not user.character.name == voice_name:
            await ctx.send("–û–±–Ω–æ–≤–ª–µ–Ω–∞ –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –Ω–∞:" + voice_name)
            await user.set_user_config(SQL_Keys.AIname, voice_name)

        voices = await get_voice_list()
        if voice_name not in voices:
            await ctx.respond("–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å –¥–ª—è –æ–∑–≤—É—á–∫–∏ (–∏–ª–∏ /add_voice):" + ', '.join(voices))
            return

        if pitch is None:
            pitch = user.character.pitch

        logger.logging("suc params", color=Color.CYAN)

        urls = []
        if audio_path:
            filename = f"{ctx.author.id}-{random.randint(1, 1000000)}.mp3"
            await audio_path.save(filename)
            urls.append(filename)
            if only_voice_change:
                cuda = await cuda_manager.use_cuda()
                voice_changer = Voice_Changer(cuda_number=cuda, voice_name=voice_name, index_rate=indexrate,
                                              pitch=pitch, filter_radius=filter_radius, rms_mix_rate=rms_mix_rate,
                                              protect=0.3, algo=palgo)
                await voice_changer.voice_change(input_path=filename, output_path=filename)
                await send_file(ctx, file_path=filename)
                await cuda_manager.stop_use_cuda(cuda)
                return
        if url:
            if ";" in url:
                urls += url.split(";")
            elif "playlist" in url:
                urls += (await get_links_from_playlist(url)).split(";")
            else:
                urls.append(url)

        for i, url in enumerate(urls):
            asyncio.ensure_future(
                run_ai_cover_gen_several_cuda(song_input=url, rvc_dirname=voice_name, pitch=pitch, index_rate=indexrate,
                                              filter_radius=filter_radius, rms_mix_rate=rms_mix_rate, protect=0.3,
                                              pitch_detection_algo=palgo,
                                              crepe_hop_length=hop, main_vol=main_vocal, backup_vol=back_vocal,
                                              inst_vol=music, reverb_size=roomsize, reverb_wetness=wetness,
                                              reverb_dryness=dryness,
                                              reverb_damping=0.7,
                                              output_format='mp3', output=output, ctx=ctx))
        if not urls:
            await ctx.respond('–ù–µ —É–∫–∞–∑–∞–Ω–∞ —Å—Å—ã–ª–∫–∞ –∏–ª–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª')
            return

    except Exception as e:
        traceback_str = traceback.format_exc()
        logger.logging(str(traceback_str), color=Color.RED)
        await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –≥–æ–ª–æ—Å–∞(ID:d5) (—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ {param_string}): {e}")


@bot.slash_command(name="create_dialog", description='–ò–º–∏—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∏–∞–ª–æ–≥ –ª—é–¥–µ–π')
async def __dialog(
        ctx,
        names: Option(str, description="–£—á–∞—Å—Ç–Ω–∏–∫–∏ –¥–∏–∞–ª–æ–≥–∞ —á–µ—Ä–µ–∑ ';' (—É –∫–∞–∂–¥–æ–≥–æ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω –≥–æ–ª–æ—Å!)",
                      required=True),
        theme: Option(str, description="–ù–∞—á–∞–ª—å–Ω–∞—è —Ç–µ–º–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞", required=False, default="—Å–ª—É—á–∞–π–Ω–∞—è —Ç–µ–º–∞"),
        prompt: Option(str, description="–û–±—â–∏–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –≤—Å–µ—Ö –¥–∏–∞–ª–æ–≥–æ–≤", required=False, default="")
):
    try:
        await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')
        names = names.split(";")
        voices = await get_voice_list()
        for name in names:
            if name not in voices:
                await ctx.respond("–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å –¥–ª—è –æ–∑–≤—É—á–∫–∏ (–∏–ª–∏ /add_voice):" + ', '.join(voices))
                return

        # –Ω–µ –≤ –≤–æ–π—Å —á–∞—Ç–µ
        voice = ctx.author.voice
        if not voice:
            return await ctx.respond(voiceChannelErrorText)

        # –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏
        author_id = ctx.author.id
        if author_id in recognizers:
            recognizer = recognizers[author_id]
            if recognizer:
                await recognizer.stop_recording()

        Dialog_AI(ctx, names, theme, prompt)
    except discord.ApplicationCommandInvokeError:
        await ctx.respond(f"–Ø –∏ —Ç–∞–∫ —Ç–µ–±—è –Ω–µ —Å–ª—É—à–∞–ª ._.")
    except Exception as e:
        traceback_str = traceback.format_exc()
        print(str(traceback_str))
        await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–∏–∞–ª–æ–≥–µ: {e}")


class Dialog_AI:
    def __init__(self, ctx, characters, theme, global_prompt):

        if ctx.guild_id in dialogs:
            asyncio.run(ctx.send("–£–∂–µ –∏–¥—ë—Ç –¥–∏–∞–ª–æ–≥"))
            return

        self.alive = True
        self.ctx = ctx
        dialogs[self.ctx.guild.id] = self

        self.characters = []
        self.names = []
        self.infos = []

        for i, name in enumerate(characters):
            character = Character(name=name)
            asyncio.run(character.load_voice(i % 2, max_simbols=500))
            self.characters.append(character)
            self.names.append(character.name)
            self.infos.append(character.info.replace("–í–æ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–µ–±–µ:", f"–í–æ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ {character.name}:"))

        self.theme = theme
        self.global_prompt = global_prompt
        self.audio_player = AudioPlayerDiscord(ctx)
        asyncio.run(self.audio_player.join_channel())

        self.recognizer = Recognizer(ctx=ctx, with_gpt=False)

        self.play_number = 0
        self.files_number = 0
        self.gpt = ChatGPT(warnings=True, save_history=False)
        self.user_id = ctx.author.id * 10

        self.dialog_create = {}
        self.dialog_play = {}

        self.text_file = f"gpt_history/history-{self.ctx.guild.id}.txt"

        if not os.path.exists(self.text_file):
            with open(self.text_file, "w", encoding="utf-8"):
                pass
        with open(self.text_file, "a", encoding="utf-8") as writer:
            writer.write("\n\n" + ', '.join(self.names))

        asyncio.ensure_future(self.gpt_dialog())
        asyncio.ensure_future(self.play_dialog())
        functions = [self.create_audio_dialog(character) for character in self.characters]
        for function in functions:
            asyncio.ensure_future(function)

    async def stop_dialog(self):
        if self.ctx.guild.id in dialogs:
            del dialogs[self.ctx.guild.id]
            self.alive = False

    async def play_dialog(self):
        while self.alive:
            if self.play_number in self.dialog_play:
                name, audio_path = self.dialog_play[self.play_number]
                audio_path = os.path.abspath(audio_path)
                del self.dialog_play[self.play_number]

                self.play_number += 1

                await self.ctx.send("–≥–æ–≤–æ—Ä–∏—Ç " + name)

                last_removed_key = self.characters[0].voice.elevenlabs_removed_key
                if last_removed_key:
                    await self.ctx.send("Last key:" + last_removed_key)
                await self.audio_player.play(audio_path)
                await self.ctx.send("end")
            else:
                # logger.logging("warn: –ù–µ—Ç –∞—É–¥–∏–æ –¥–ª—è –¥–∏–∞–ª–æ–≥–∞!", color=Color.RED)
                await asyncio.sleep(0.75)

    async def create_audio_dialog(self, character):
        while self.alive:
            try:
                for files_number, (name, text) in self.dialog_create.items():
                    if files_number - self.play_number > 2:
                        continue

                    if name == character.name:
                        # logger.logging(f"Found file: ({files_number}, {self.play_number}). Voice:{character.name}")

                        while not len(self.dialog_play) == 0 and not self.audio_player.isPlaying:
                            # logger.logging("wait for play smth", color=Color.GRAY)
                            await asyncio.sleep(0.25)
                        del self.dialog_create[files_number]
                        audio_path_1 = f"{files_number}{character.name}-row.mp3"
                        audio_path_2 = f"{files_number}{character.name}.mp3"
                        await character.text_to_speech(text=text, audio_path=audio_path_1, output_name=audio_path_2)
                        self.dialog_play[files_number] = (character.name, audio_path_2)
                        os.remove(audio_path_1)
                        break
                await asyncio.sleep(0.5)
            except Exception as e:
                logger.logging(str(e), color=Color.RED)

    async def save_dialog(self, result):
        # logger.logging(result, color=Color.GRAY)
        lines = result.split("\n")
        with open(self.text_file, "a", encoding="utf-8") as writer:
            found_max_line = 0
            for i, line in enumerate(lines):
                for name in self.names:
                    # –ß–µ–ª–æ–≤–µ–∫: –ø—Ä–∏–≤–µ—Ç
                    # –ß–µ–ª–æ–≤–µ–∫ (man): –ø—Ä–∏–≤–µ—Ç
                    # –ß—ç–ª–æ–≤–µ–∫: –ø—Ä–∏–≤–µ—Ç
                    if (line.startswith(name) or line.startswith(name.replace("—ç", "–µ"))) and ":" in line:
                        line = line[line.find(":") + 1:]
                        self.dialog_create[self.files_number] = (name, line)
                        self.files_number += 1
                        writer.write(f"{name}:{line}\n")
                        found_max_line = i
                        break
        return ''.join(lines[found_max_line + 1:])

    async def run_gpt(self, prompt):
        result = await self.gpt.run_all_gpt(prompt=prompt, user_id=self.user_id)
        if "(" in result and ")" in result:
            result = re.sub(r'\(.*?\)', '', result)
        if "*" in result:
            result = re.sub(r'\*.*?\*', '', result)
        return result.replace("[", "").replace("]", "").replace(
            "–ü—Ä–∏–≤–µ—Ç, —Ä–µ–±—è—Ç–∞! ", "").replace("–ü—Ä–∏–≤–µ—Ç, —Ä–µ–±—è—Ç–∞", "").replace("–í—Å–µ–º –ø—Ä–∏–≤–µ—Ç, ", "").replace("–≠–π", "")

    async def gpt_dialog(self):
        infos = '.\n'.join(self.infos)
        prompt = (
            f"# –ó–∞–¥–∞—á–∞\n–°–æ–∑–¥–∞—Ç—å –¥–∏–∞–ª–æ–≥ –º–µ–∂–¥—É {', '.join(self.names)}.\n"
            f"# –¢–µ–º–∞ –¥–∏–∞–ª–æ–≥–∞\n{self.theme}.\n"
            f"# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n{infos}.\n"
            f"# {self.global_prompt}.\n\n"
            f"# –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è\n"
            f"1. –ü–µ—Ä—Å–æ–Ω–∞–∂–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω—ã–º–∏ –∏ –¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å —Å–æ–≥–ª–∞—Å–Ω–æ —Å–≤–æ–µ–º—É —Ö–∞—Ä–∞–∫—Ç–µ—Ä—É.\n"
            f"2. –í –∫–æ–Ω—Ü–µ –¥–∏–∞–ª–æ–≥–∞ —É–∫–∞–∂–∏—Ç–µ –∫—Ä–∞—Ç–∫–æ, —á—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ –∏ —á—Ç–æ –æ–∂–∏–¥–∞–µ—Ç—Å—è –≤ —Å–ª–µ–¥—É—é—â–µ–º –¥–∏–∞–ª–æ–≥–µ.\n"
            f"3. –î–∏–∞–ª–æ–≥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n[–ì–æ–≤–æ—Ä—è—â–∏–π]: [–ü—Ä–æ–∏–∑–Ω–µ—Å–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç]."
        )
        result = await self.run_gpt(prompt)

        dialog_next = await self.save_dialog(result)

        # logger.logging("DIALOG NEXT:", dialog_next, color=Color.GRAY)

        theme_last = self.theme
        theme_was_in_row = 0
        while self.alive:
            try:

                spoken_text = self.recognizer.recognized
                if spoken_text:
                    spoken_text = "\n0. –û—Ç–≤–µ—á–∞–π –∑—Ä–∏—Ç–µ–ª—è–º! –ó—Ä–∏—Ç–µ–ª–∏ –∑–∞ –ø—Ä–æ—à–ª—ã–π –¥–∏–∞–ª–æ–≥ –Ω–∞–ø–∏—Å–∞–ª–∏:\"" + spoken_text + "\"\n"
                    self.recognizer.recognized = ""

                # –¢–µ–º–∞ –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –≤ –∑–∞–ø—Ä–æ—Å, –µ—Å–ª–∏ –æ–Ω–∞ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å
                new_theme = self.theme
                if not theme_last == new_theme:
                    theme_was_in_row = 0
                    theme_last = new_theme
                    theme_temp = f"–¢–µ–º–∞ –¥–∏–∞–ª–æ–≥–∞: \"{new_theme}\""
                    with open(f"caversAI/history-{self.ctx.guild.id}", "a", encoding="utf-8") as writer:
                        writer.write(f"\n==–ù–æ–≤–∞—è —Ç–µ–º–∞==: {new_theme}\n\n")
                elif theme_was_in_row > 1:
                    self.theme = await self.run_gpt(
                        f"–ü—Ä–∏–¥—É–º–∞–π –Ω–æ–≤—É—é —Ç–µ–º—É –¥–ª—è —ç—Ç–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞:\n{result}\n\n–í –æ—Ç–≤–µ—Ç–µ –≤—ã–≤–µ–¥–∏ 2-3 —Å–ª–æ–≤–∞ –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Å–ª–µ–¥—É—é—â–µ–π —Ç–µ–º—ã –¥–ª—è –¥–∏–∞–ª–æ–≥–∞")
                    theme_last = self.theme
                    theme_temp = self.theme
                    theme_was_in_row = 0
                else:
                    theme_was_in_row += 1
                    theme_temp = f"–ò–∑–Ω–∞—á–∞–ª—å–Ω–∞—è —Ç–µ–º–∞ –¥–∏–∞–ª–æ–≥–∞: \"{new_theme}\""
                prompt = (
                    f"# –ó–∞–¥–∞—á–∞\n–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ –¥–∏–∞–ª–æ–≥ –º–µ–∂–¥—É {', '.join(self.names)}.\n"
                    f"# {theme_temp}.\n"
                    f"# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n{'.'.join(self.infos)}.\n"
                    f"# {self.global_prompt}.\n\n"
                    f"# –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è\n"
                    f"{spoken_text}"
                    f"1. –ü–µ—Ä—Å–æ–Ω–∞–∂–∏ –¥–æ–ª–∂–Ω—ã –¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å —Å–æ–≥–ª–∞—Å–Ω–æ —Å–≤–æ–µ–º—É —Ö–∞—Ä–∞–∫—Ç–µ—Ä—É.\n"
                    f"2. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –≤ –Ω–∞—á–∞–ª–µ –¥–∏–∞–ª–æ–≥–∞.\n"
                    f"3. –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π—Ç–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–π –¥–∏–∞–ª–æ–≥. –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞: \"{dialog_next}\".\n"
                    f"4. –í –∫–æ–Ω—Ü–µ –¥–∏–∞–ª–æ–≥–∞ –∫—Ä–∞—Ç–∫–æ —É–∫–∞–∂–∏—Ç–µ, —á—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ –≤ —ç—Ç–æ–º –¥–∏–∞–ª–æ–≥–µ –∏ —á—Ç–æ –¥–æ–ª–∂–Ω–æ –ø—Ä–æ–∏–∑–æ–π—Ç–∏ –¥–∞–ª—å—à–µ.\n"
                    f"5. –ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ –¥–∏–∞–ª–æ–≥ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n[–ì–æ–≤–æ—Ä—è—â–∏–π]: [–ü—Ä–æ–∏–∑–Ω–µ—Å–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç]."
                )

                result = await self.run_gpt(prompt)

                dialog_next = await self.save_dialog(result)

                # –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π —Ä–∞–∑—Ä—ã–≤
                while self.files_number - self.play_number > 2:
                    # logger.logging(f"wait, difference > 4 ({self.files_number},{self.play_number})", color=Color.YELLOW)
                    await asyncio.sleep(5)
                    if not self.alive:
                        return

                # –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
                while len(self.dialog_create) > 2:
                    # logger.logging("wait, too many text > 2", color=Color.YELLOW)
                    await asyncio.sleep(5)
                    if not self.alive:
                        return

            except Exception as e:
                traceback_str = traceback.format_exc()
                logger.logging(str(traceback_str), color=Color.RED)
                await self.ctx.send(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –≥–æ–ª–æ—Å–∞(ID:d4): {e}")


@bot.slash_command(name="add_voice", description='–î–æ–±–∞–≤–∏—Ç—å RVC –≥–æ–ª–æ—Å')
async def __add_voice(
        ctx,
        url: Option(str, description='–°—Å—ã–ª–∫–∞ –Ω–∞ .zip —Ñ–∞–π–ª —Å –º–æ–¥–µ–ª—å—é RVC', required=True),
        name: Option(str, description=f'–ò–º—è –º–æ–¥–µ–ª–∏', required=True),
        gender: Option(str, description=f'–ü–æ–ª (–¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏)', required=True,
                       choices=['–º—É–∂—á–∏–Ω–∞', '–∂–µ–Ω—â–∏–Ω–∞']),
        pitch: Option(int, description="–ö–∞–∫—É—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å (–æ—Ç -24 –¥–æ 24) (–∏–ª–∏ —É–∫–∞–∑–∞—Ç—å gender)",
                      required=False, default=0, min_value=-24, max_value=24),
        info: Option(str, description=f'–ö–∞–∫–∏–µ-—Ç–æ —Å–≤–µ–¥–µ–Ω–∏—è –æ –¥–∞–Ω–Ω–æ–º —á–µ–ª–æ–≤–µ–∫–µ', required=False,
                     default="–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"),
        speed: Option(float, description=f'–£—Å–∫–æ—Ä–µ–Ω–∏–µ/–∑–∞–º–µ–¥–ª–µ–Ω–∏–µ –≥–æ–ª–æ—Å–∞', required=False,
                      default=1, min_value=1, max_value=3),
        voice_model_eleven: Option(str, description=f'–ö–∞–∫–∞—è –º–æ–¥–µ–ª—å elevenlabs –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞', required=False,
                                   default="Adam"),
        change_voice: Option(bool, description=f'(–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ) –ò–∑–º–µ–Ω–∏—Ç—å –≥–æ–ª–æ—Å –Ω–∞ —ç—Ç–æ—Ç', required=False,
                             default=False),
        txt_file: Option(discord.SlashCommandOptionType.attachment,
                         description='–§–∞–π–ª txt –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π —Å—Ä–∞–∑—É',
                         required=False, default=None)
):
    if voice_model_eleven not in ALL_VOICES.keys():
        await ctx.respond("–°–ø–∏—Å–æ–∫ –≥–æ–ª–æ—Å–æ–≤: \n" + '; '.join(ALL_VOICES.keys()))
        return
    await ctx.defer()
    await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')

    if txt_file:
        urls, names, genders, infos, speeds, voice_model_elevens, stabilities, similarity_boosts, styles = await agrs_with_txt(
            txt_file)
        logger.logging("url:", urls)
        logger.logging("name:", names)
        logger.logging("gender:", genders)
        logger.logging("info:", infos)
        logger.logging("speed:", speeds)
        logger.logging("voice_model_eleven:", voice_model_elevens)
        logger.logging("stabilities:", stabilities)
        logger.logging("similarity_boosts:", similarity_boosts)
        logger.logging("styles:", styles)
        for i in range(len(urls)):
            if names[i] is None:
                await ctx.send(f"–ù–µ —É–∫–∞–∑–∞–Ω–æ –∏–º—è –≤ {i + 1} –º–æ–¥–µ–ª–µ")
                continue
            if urls[i] is None:
                await ctx.send(f"–ù–µ —É–∫–∞–∑–∞–Ω–∞ —Å—Å—ã–ª–∫–∞ –≤ {i + 1} –º–æ–¥–µ–ª–µ ({name})")
                continue
            if genders[i] is None:
                await ctx.send(f"–ù–µ —É–∫–∞–∑–∞–Ω –ø–æ–ª –≤ {i + 1} –º–æ–¥–µ–ª–µ ({name})")
                continue
            await download_voice(ctx, urls[i], names[i], genders[i], infos[i], speeds[i], voice_model_elevens[i], False,
                                 stability=stabilities[i], similarity_boost=similarity_boosts[i], style=styles[i])
        await ctx.send("–í—Å–µ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã!")
        return
    if pitch is None:
        pitch = gender
    await download_voice(ctx, url, name, pitch, info, speed, voice_model_eleven, change_voice)


async def agrs_with_txt(txt_file):
    try:
        filename = "temp_args.txt"
        await txt_file.save(filename)
        with open(filename, "r", encoding="utf-8") as file:
            lines = file.readlines()
            lines[-1] = lines[-1] + " "
        url = []
        name = []
        gender = []
        info = []
        speed = []
        voice_model_eleven = []
        stability, similarity_boost, style = [], [], []
        for line in lines:
            if line.strip():
                # –∑–∞–±–µ–π—Ç–µ, –ø—Ä–æ—Å—Ç–æ –Ω—É–∂–µ–Ω –ø—Ä–æ–±–µ–ª –∏ –≤—Å—ë
                line += " "
                line = line.replace(": ", ":")
                # /add_voice url:url_to_model name:some_name gender:–º—É–∂—á–∏–Ω–∞ info:some_info speed:some_speed voice_model_eleven:some_model
                pattern = r'(\w+):(.+?)\s(?=\w+:|$)'

                matches = re.findall(pattern, line)
                arguments = dict(matches)

                url.append(arguments.get('url', None))
                name.append(arguments.get('name', None))
                gender.append(arguments.get('gender', None))
                info.append(arguments.get('info', "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"))
                speed.append(arguments.get('speed', "1"))
                voice_model_eleven.append(arguments.get('voice_model_eleven', "James"))
                stability.append(arguments.get('stability', "0.4"))
                similarity_boost.append(arguments.get('similarity_boost', "0.25"))
                style.append(arguments.get('style', "0.4"))
        return url, name, gender, info, speed, voice_model_eleven, stability, similarity_boost, style
    except Exception:
        traceback_str = traceback.format_exc()
        logger.logging(str(traceback_str), color=Color.RED)
        return None, None, None, None, None, None, None, None, None


async def download_voice(ctx, url, name, gender, info, speed, voice_model_eleven, change_voice, stability="0.4",
                         similarity_boost="0.25", style="0.4"):
    if name == "None" or ";" in name or "/" in name or "\\" in name:
        await ctx.respond('–ò–º—è –Ω–µ –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å \";\" \"/\" \"\\\" –∏–ª–∏ –±—ã—Ç—å None')

    name = name.replace(" ", "_")
    if gender == "–∂–µ–Ω—â–∏–Ω–∞":
        gender = "female"
    elif gender == "–º—É–∂—á–∏–Ω–∞":
        gender = "male"
    try:
        parameters = {
            "info": info,
            "gender": gender.replace(" ", ""),
            "speed": str(speed).replace(" ", ""),
            "voice_model_eleven": voice_model_eleven,
            "stability": stability.replace(" ", ""),
            "similarity_boost": similarity_boost.replace(" ", ""),
            "style": style.replace(" ", ""),
        }
        success, result = await download_online_model(url=url, dir_name=name, parameters=parameters)

        if change_voice and success:
            user = DiscordUser(ctx)
            await user.set_user_config(SQL_Keys.AIname, name)
        await ctx.send(result)

        # –£–¥–∞–ª—è–µ–º –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ –æ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if name in characters_all:
            del characters_all[name]

    except subprocess.CalledProcessError as e:
        traceback_str = traceback.format_exc()
        logger.logging(str(traceback_str), color=Color.RED)
        await ctx.respond("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ –≥–æ–ª–æ—Å–∞.")


async def command_line(ctx, command):
    logger.logging("command line:", command)
    try:
        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)
        stdout, stderr = process.communicate()
        for line in stdout.decode().split('\n'):
            if line.strip():
                await ctx.author.send(line)
        for line in stderr.decode().split('\n'):
            if line.strip():
                await ctx.author.send(line)
    except subprocess.CalledProcessError as e:
        traceback_str = traceback.format_exc()
        logger.logging(str(traceback_str), color=Color.RED)
        await ctx.author.send(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã: {e}")
    except Exception as e:
        traceback_str = traceback.format_exc()
        logger.logging(str(traceback_str), color=Color.RED)
        await ctx.author.send(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")


@bot.command(aliases=['cmd'], help="–∫–æ–º–∞–Ω–¥–Ω–∞—è —Å—Ç—Ä–æ–∫–∞")
async def commands(ctx, *args):
    owner_ids = (await set_get_config_all("Default", SQL_Keys.owner_id)).split(";")
    if str(ctx.author.id) not in owner_ids:
        await ctx.author.send("–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â—ë–Ω")
        return

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ ID
    command = " ".join(args)
    asyncio.ensure_future(command_line(ctx=ctx, command=command))

@bot.command(aliases=['send'], help="–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–∞–π–ª")
async def send_smth(ctx, *args):
    owner_ids = (await set_get_config_all("Default", SQL_Keys.owner_id)).split(";")
    if str(ctx.author.id) not in owner_ids:
        await ctx.author.send("–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â—ë–Ω")
        return
    file_path = ''.join(args)
    await send_file(ctx=ctx, file_path=file_path)

@bot.command(aliases=['restart'], help="–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞")
async def command_restart(ctx):
    owner_ids = (await set_get_config_all("Default", SQL_Keys.owner_id)).split(";")
    if str(ctx.author.id) not in owner_ids:
        await ctx.author.send("–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â—ë–Ω")
        return
    await ctx.send("–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞")
    await set_get_config_all("Default", SQL_Keys.reload, ctx.author.id)
    exit(0)


@bot.command(aliases=['exit'], help="–í—ã–∫–ª—é—á–∏—Ç—å—Å—è")
async def command_exit(ctx, *args):
    owner_ids = (await set_get_config_all("Default", SQL_Keys.owner_id)).split(";")
    if str(ctx.author.id) not in owner_ids:
        await ctx.author.send("–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â—ë–Ω")
        return
    time = ''.join(args).replace(" ", "")
    if time:
        await ctx.send(f"–í—ã–∫–ª—é—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ {time} —Å–µ–∫—É–Ω–¥")
        await asyncio.sleep(int(time))
    else:
        await ctx.send(f"–í—ã–∫–ª—é—á–µ–Ω–∏–µ")
    await set_get_config_all("Default", SQL_Keys.reload, "False")
    exit(0)
    # asyncio.ensure_future(command_line(ctx=ctx, command="pkill -f python"))


@bot.command(aliases=['themer'], help="—Ç–µ–º–∞ –¥–ª—è –¥–∏–∞–ª–æ–≥–∞")
async def themer_set(ctx, *args):
    text = " ".join(args)
    guild_id = ctx.guild.id
    if guild_id in dialogs:
        dialog = dialogs[guild_id]
        if dialog:
            dialog.theme = text
            await ctx.send("–ò–∑–º–µ–Ω–µ–Ω–∞ —Ç–µ–º–∞:" + text)


@bot.slash_command(name="record", description='–≤–æ—Å–ø—Ä–∏–Ω–∏–º–∞—Ç—å –∫–æ–º–∞–Ω–¥—ã –∏–∑ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞')
async def record(ctx):
    global recognizers, audio_players, dialogs
    author_id = ctx.author.id

    if author_id in recognizers:
        recognizer = recognizers[author_id]
        if recognizer:
            await recognizer.stop_recording()

    voice = ctx.author.voice
    if not voice:
        return await ctx.respond(voiceChannelErrorText)
    try:
        Recognizer(ctx)
    except:
        recognizers = {}
        audio_players = {}
        dialogs = {}
        Recognizer(ctx)


@bot.slash_command(name="stop_recording", description='–ø–µ—Ä–µ—Å—Ç–∞—Ç—å –≤–æ—Å–ø—Ä–∏–Ω–∏–º–∞—Ç—å –∫–æ–º–∞–Ω–¥—ã –∏–∑ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞')
async def stop_recording(ctx):
    author_id = ctx.author.id

    if author_id in recognizers:
        recognizer = recognizers[author_id]
        if recognizer:
            await recognizer.stop_recording()
            await ctx.respond("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏.")
        else:
            await ctx.respond("–Ø –∏ —Ç–∞–∫ —Ç–µ–±—è –Ω–µ —Å–ª—ã—à–∞–ª ._.")
    else:
        await ctx.respond("–Ø –∏ —Ç–∞–∫ —Ç–µ–±—è –Ω–µ —Å–ª—ã—à–∞–ª ._.")


class Recognizer:
    def __init__(self, ctx, with_gpt=True):
        if ctx.author.id in recognizers:
            asyncio.run(ctx.send("–£–∂–µ —Å–ª—É—à–∞—é –≤–∞—Å"))
            return

        self.alive = True
        self.ctx = ctx
        self.stream_sink = StreamSink(ctx=ctx)
        self.google_recognizer = sr.Recognizer()
        self.not_speaking = 0
        self.delay_record = float(
            asyncio.run(set_get_config_all("Default", SQL_Keys.delay_record)) if not None else 5) * 10
        self.user = DiscordUser(ctx)

        self.with_gpt = with_gpt
        self.recognized = ""

        self.audio_player = AudioPlayerDiscord(ctx)
        self.vc = None
        asyncio.run(ctx.respond("–í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –≤–∞—Å —Å–ª—É—à–∞—é"))
        asyncio.run(self.initialize())
        asyncio.ensure_future(self.recognize())

    async def initialize(self):
        if not self.audio_player.voice_client:
            await self.audio_player.join_channel()
        self.vc = self.audio_player.voice_client

        if self.vc is None:
            await self.ctx.respond("–û—à–∏–±–∫–∞")

        recognizers[self.ctx.author.id] = self
        self.stream_sink.set_user(self.ctx.author.id)
        self.vc.start_recording(
            self.stream_sink,
            self.once_done,
            self.ctx.channel
        )

    async def once_done(self, _1, _2):
        logger.logging("Once done", type(_1), _1, type(_2), _2, Color.GRAY)

    async def stop_recording(self):
        if self.ctx.author.id in recognizers:
            del recognizers[self.ctx.author.id]
            del audio_players[self.ctx.guild.id]
            logger.logging("RECOGNIZERS LEFT:", recognizers)
            self.alive = False
            if self.vc:
                self.vc.stop_recording()
                await self.vc.disconnect(force=True)
            else:
                logger.logging("Cant stop recording: None")
        else:
            logger.logging("Cant stop recording: No user")

    async def recognize(self):
        await self.user.character.load_voice(1)
        google_recognizer = self.google_recognizer
        logger.logging("Record", color=Color.GRAY)
        while self.alive:
            speaking = self.stream_sink.buffer.speaking
            audio_file = self.stream_sink.buffer.previous_audio_filename
            if not speaking:
                # logger.logging("Not speaking", color=Color.GRAY)
                self.not_speaking += 1

                await asyncio.sleep(0.1)
                if audio_file is None:
                    continue
                # –µ—Å–ª–∏ –¥–æ–ª–≥–æ –Ω–µ –±—ã–ª–æ —Ñ–∞–π–ª–æ–≤ (—á–µ–ª–æ–≤–µ–∫ –ø–µ—Ä–µ—Å—Ç–∞–ª –≥–æ–≤–æ—Ä–∏—Ç—å)
                if self.not_speaking > self.delay_record:
                    text = None
                    self.not_speaking = 0
                    # —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∏–µ —Ä–µ—á–∏
                    try:
                        with sr.AudioFile(audio_file) as source:
                            audio_data = google_recognizer.record(source)
                            text = google_recognizer.recognize_google(audio_data, language="ru-RU")
                    except sr.UnknownValueError:
                        pass
                    except Exception:
                        traceback_str = traceback.format_exc()
                        logger.logging(str(traceback_str), color=Color.RED)

                    # —É–¥–∞–ª–µ–Ω–∏–µ out_all.wav
                    self.stream_sink.buffer.previous_audio_filename = None
                    Path(audio_file).unlink(missing_ok=True)
                    # —Å–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
                    AudioSegment.silent(duration=0).export(audio_file, format="wav")

                    if not text is None:
                        mat_found, text_out = await moderate_mat_in_sentence(text)
                        logger.logging("STT:", text_out, color=Color.GREEN)
                        if self.with_gpt:
                            chatGPT = ChatGPT()
                            answer = await chatGPT.run_all_gpt(f"{self.user.name}:{text_out}",
                                                               user_id=self.user.id,
                                                               gpt_role=self.user.character.gpt_info)
                            await self.ctx.send(answer)
                            if not self.user.character.name == "None":
                                audio_path_1 = f"{self.user.id}-{self.user.character.name}-record-row.mp3"
                                audio_path_2 = f"{self.user.id}-{self.user.character.name}-record.mp3"
                                await self.user.character.text_to_speech(answer, audio_path=audio_path_1,
                                                                         output_name=audio_path_2)
                                await self.audio_player.play(audio_path_2)

                                os.remove(audio_path_1)
                                os.remove(audio_path_2)

                        else:
                            self.recognized += text_out + " "
            else:
                # logger.logging("Speaking", color=Color.GRAY)
                self.stream_sink.buffer.speaking = False
                self.not_speaking = 0
                await asyncio.sleep(self.stream_sink.buffer.block_len)

        logger.logging("Stop_Recording", color=Color.GREEN)


async def send_file(ctx, file_path, delete_file=False):
    try:
        await ctx.send(file=discord.File(file_path))
        if delete_file:
            await asyncio.sleep(1.5)
            os.remove(file_path)
    except FileNotFoundError:
        await ctx.send('–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.')
    except discord.HTTPException as e:
        traceback_str = traceback.format_exc()
        logger.logging(str(traceback_str), color=Color.RED)
        await ctx.send(f'–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–∞–π–ª–∞: {e}.')


@asynccontextmanager
async def audio_play_lock():
    lock = asyncio.Lock()
    async with lock:
        yield lock


class AudioPlayerDiscord:
    def __init__(self, ctx):
        self.guild = ctx.guild
        self.ctx = ctx
        if self.guild:
            create_new = False
            if ctx.guild.id in audio_players:
                try:
                    existing_player = audio_players[ctx.guild.id]
                    self.__dict__.update(existing_player.__dict__)
                    self.voice_channel = ctx.author.voice.channel if ctx.author.voice else None
                except:
                    create_new = True
            else:
                create_new = True

            if create_new:
                logger.logging("–ù–æ–≤—ã–π audio_player", color=Color.PURPLE)
                audio_players[ctx.guild.id] = self
                self.ctx = ctx
                self.guild = ctx.guild.id
                self.voice_channel = ctx.author.voice.channel if ctx.author.voice else None
                self.voice_client = None
                self.queue = []
                self.play_event = asyncio.Event()
                self.isPlaying = False
                self.paused = False

    async def join_channel(self):
        if self.guild:
            ctx = self.ctx
            try:
                if self.voice_client is None:
                    if ctx.author.voice:
                        self.voice_client = await ctx.author.voice.channel.connect()
                        return self.voice_client
                await ctx.send(voiceChannelErrorText)
            except discord.ClientException as e:
                logger.logging("–£–∂–µ –≤ –≥–æ–ª–æ—Å–æ–≤–æ–º –∫–∞–Ω–∞–ª–µ", e, color=Color.GRAY)
                self.voice_client = await ctx.voice_client.move_to(self.voice_channel)
                return self.voice_client

    async def stop(self):
        if self.guild:
            if self.paused:
                self.paused = False
                return "–í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ"
            if self.isPlaying:
                self.paused = True
                self.voice_client.stop()
                return "–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ"
            else:
                return "–ù–µ—Ç –∞—É–¥–∏–æ –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏"
        else:
            return "–í—ã –Ω–µ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ"

    async def play(self, audio_file, delete_file=False, is_send_file=True):
        if not self.guild:
            if is_send_file:
                await send_file(self.ctx, audio_file)
            return

        async with audio_play_lock():
            self.isPlaying = True
            if not self.voice_client or not self.voice_client.is_connected():
                await self.join_channel()
            try:
                audio_source = discord.FFmpegPCMAudio(audio_file)
                audio_duration = AudioSegment.from_file(audio_file).duration_seconds
                self.voice_client.play(audio_source)
                await asyncio.sleep(audio_duration)

                # –ü–∞—É–∑–∞
                while self.paused:
                    logger.logging("–ù–∞ –ø–∞—É–∑–µ", color=Color.GRAY)
                    await asyncio.sleep(0.25)

                if delete_file:
                    os.remove(audio_file)
                self.isPlaying = False
                logger.logging("Finished play", color=Color.GRAY)
            except discord.ClientException:
                logger.logging("already playing smth, not wait", color=Color.RED)

    async def skip(self):
        if self.isPlaying:
            self.voice_client.stop()
            return "–ü—Ä–æ–ø—É—â–µ–Ω–æ"
        else:
            return "–ù–µ—Ç –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞"

    async def disconnect(self):
        if self.voice_client and self.voice_client.is_connected():
            await self.voice_client.disconnect(force=True)
            self.isPlaying = False
            self.queue = []


if __name__ == "__main__":
    import warnings

    warnings.filterwarnings("ignore")
    try:

        # === args ===

        arguments = sys.argv

        if len(arguments) > 1:
            discord_token = arguments[1]
            # load models? (img, gpt, all)
            load_gpt = False
            load_images1 = False
            load_images2 = False
            if len(arguments) > 2:
                args = arguments[2]
                if "img1" in args:
                    load_images1 = True
                if "img2" in args:
                    load_images1 = True
                    load_images2 = True
        else:
            # raise error & exit
            logger.logging("–£–∫–∞–∂–∏—Ç–µ discord_TOKEN", color=Color.RED)
            exit(-1)

        # == load images ==
        if load_images1:
            import discord_bot_images

            logger.logging("load image model on GPU-0", color=Color.CYAN)
            image_generators.append(Image_Generator(0))
        if load_images2:
            logger.logging("load image model on GPU-1", color=Color.CYAN)
            image_generators.append(Image_Generator(1))

        # ==== load bot ====
        logger.logging("====load bot====", color=Color.CYAN)
        loop = asyncio.get_event_loop()
        loop.run_until_complete(bot.start(discord_token))
    except Exception as e:
        traceback_str = traceback.format_exc()
        logger.logging(str(traceback_str), color=Color.RED)
        logger.logging(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞", color=Color.RED)
