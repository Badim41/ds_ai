import multiprocessing
import os
import random
import struct
import subprocess
import configparser
import asyncio
import wave

from pydub import AudioSegment

from discord import Option
from modifed_sinks import StreamSink
import speech_recognition as sr
from pathlib import Path
import sys
import discord
from discord.ext import commands

# –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
voiceChannelErrorText = '‚ùó –í—ã –¥–æ–ª–∂–Ω—ã –Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤ –≥–æ–ª–æ—Å–æ–≤–æ–º –∫–∞–Ω–∞–ª–µ ‚ùó'
config = configparser.ConfigParser()

connections = {}

stream_sink = StreamSink()

intents = discord.Intents.all()
bot = commands.Bot(command_prefix='\\', intents=intents)


async def set_get_config_all(section, key, value):
    config.read('config.ini')
    if value is None:
        config.read('config.ini')
        return config.get(section, key)
    config.set(section, key, str(value))
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    with open('config.ini', 'w') as configfile:
        config.write(configfile)
    return ' '.join([section, key, str(value)])


async def set_get_config(key="record", value=None):
    config.read('config.ini')
    if value is None:
        config.read('config.ini')
        return config.get("Sound", key)
    config.set('Sound', key, str(value))
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    with open('config.ini', 'w') as configfile:
        config.write(configfile)


async def set_get_config_default(key, value=None):
    config.read('config.ini')
    if value is None:
        config.read('config.ini')
        return config.get("Default", key)
    config.set('Default', key, str(value))
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    with open('config.ini', 'w') as configfile:
        config.write(configfile)


@bot.event
async def on_ready():
    print('Status: online')
    await bot.change_presence(activity=discord.Activity(
        type=discord.ActivityType.listening, name='AI-covers'))


# @bot.event
# async def on_message(message):
#     if message.author.bot:
#         return
#     if len(message.attachments) > 0:
#         for attachment in message.attachments:
#             await attachment.save(attachment.filename)
#             print(f'–ü–æ–ª—É—á–µ–Ω —Ñ–∞–π–ª: {attachment.filename}')


@bot.slash_command(name="change_image", description='–∏–∑–º–µ–Ω–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é')
async def __image(ctx,
                  image: Option(discord.SlashCommandOptionType.attachment, description='–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ',
                                required=True),
                  # prompt=prompt, negative_prompt=negative_prompt, x=512, y=512, steps=50,
                  #                      seed=random.randint(1, 10000), strenght=0.5
                  prompt: Option(str, description='–∑–∞–ø—Ä–æ—Å', required=True),
                  negative_prompt: Option(str, description='–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å', default="NSFW", required=False),
                  steps: Option(int, description='—á–∏—Å–ª–æ —à–∞–≥–æ–≤', required=False,
                                default=30,
                                min_value=1,
                                max_value=500),
                  seed: Option(int, description='—Å–∏–¥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è', required=False,
                               default=random.randint(1, 1000000),
                               min_value=1,
                               max_value=1000000),
                  strength: Option(float, description='–Ω–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω—ã –±—É–¥—É—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è', required=False,
                                   default=0.5, min_value=0,
                                   max_value=1),
                  strength_prompt: Option(float,
                                          description='–õ–£–ß–®–ï –ù–ï –¢–†–û–ì–ê–¢–¨! –ù–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç',
                                          required=False,
                                          default=0.85, min_value=0,
                                          max_value=1),
                  strength_negative_prompt: Option(float,
                                                   description='–õ–£–ß–®–ï –ù–ï –¢–†–û–ì–ê–¢–¨! –ù–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç',
                                                   required=False,
                                                   default=1, min_value=0,
                                                   max_value=1)
                  ):
    await set_get_config_all("Image", "result", "None")
    await ctx.defer()
    if await set_get_config_all("Image", "model_loaded", None) == "False":
        return await ctx.respond("–º–æ–¥–µ–ª—å –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–æ–∫ –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å, –ø–æ–¥–æ–∂–¥–∏—Ç–µ 10-20 –º–∏–Ω—É—Ç")
    filename = str(random.randint(1, 1000000)) + ".png"
    await image.save(filename)
    # get image size and round to 64
    x, y = await get_image_dimensions(filename)
    if not x % 64 == 0:
        x = ((x // 64) + 1) * 64
    if not y % 64 == 0:
        y = ((y // 64) + 1) * 64
    # loading params
    await set_get_config_all("Image", "strength_negative_prompt", strength_negative_prompt)
    await set_get_config_all("Image", "strength_prompt", strength_prompt)
    await set_get_config_all("Image", "strength", strength)
    await set_get_config_all("Image", "seed", seed)
    await set_get_config_all("Image", "steps", steps)
    await set_get_config_all("Image", "negative_prompt", negative_prompt)
    await set_get_config_all("Image", "prompt", prompt)
    await set_get_config_all("Image", "x", x)
    await set_get_config_all("Image", "y", y)
    await set_get_config_all("Image", "input", filename)
    print("params suc")
    # wait for answer
    image_path = await set_get_config_all("Image", "result", None)
    while image_path == "None":
        image_path = await set_get_config_all("Image", "result", None)
        await asyncio.sleep(0.25)
    await ctx.respond("–í–æ—Ç –∫–∞–∫ —è –∏–∑–º–µ–Ω–∏–ª –≤–∞—à–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µüñå")
    await send_file(ctx, image_path)


@bot.slash_command(name="config", description='–∏–∑–º–µ–Ω–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥ (–ª—É—á—à–µ –Ω–µ —Ç—Ä–æ–≥–∞—Ç—å, –µ—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å!)')
async def __config(
        ctx,
        section: Option(str, description='—Å–µ–∫—Ü–∏—è', required=True),
        key: Option(str, description='–∫–ª—é—á', required=True),
        value: Option(str, description='–∑–Ω–∞—á–µ–Ω–∏–µ', required=False, default=None)
):
    await ctx.defer()
    await ctx.respond(await set_get_config_all(section, key, value))


@bot.slash_command(name="join", description='–ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å—Å—è –∫ –≥–æ–ª–æ—Å–æ–≤–æ–º—É –∫–∞–Ω–∞–ª—É')
async def join(ctx):
    await ctx.defer()
    voice = ctx.author.voice
    if not voice:
        await ctx.respond(voiceChannelErrorText)
        return

    voice_channel = voice.channel

    if ctx.voice_client is not None:
        return await ctx.voice_client.move_to(voice_channel)

    await voice_channel.connect()
    await ctx.respond("–ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è—é—Å—å")


@bot.slash_command(name="record", description='–≤–æ—Å–ø—Ä–∏–Ω–∏–º–∞—Ç—å –∫–æ–º–∞–Ω–¥—ã –∏–∑ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞')
async def record(ctx):  # if you're using commands.Bot, this will also work.
    voice = ctx.author.voice
    voice_channel = voice.channel
    # –¥–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á –∫ connetions
    if ctx.guild.id not in connections:
        connections[ctx.guild.id] = []

    if not voice:
        return await ctx.respond(voiceChannelErrorText)

    if ctx.voice_client is None:
        # –µ—Å–ª–∏ –±–æ—Ç–∞ –ù–ï–¢ –≤ –≤–æ–π—Å-—á–∞—Ç–µ
        vc = await voice_channel.connect()
    else:
        # –µ—Å–ª–∏ –±–æ—Ç –£–ñ–ï –≤ –≤–æ–π—Å-—á–∞—Ç–µ
        vc = ctx.voice_client
    # –µ—Å–ª–∏ —É–∂–µ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç
    if vc in connections[ctx.guild.id]:
        return await ctx.respond("–£–∂–µ –∑–∞–ø–∏—Å—ã–≤–∞—é –≤–∞—à –≥–æ–ª–æ—Åüé§")
    stream_sink.set_user(ctx.author.id)
    connections[ctx.guild.id].append(vc)

    # –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å
    vc.start_recording(
        stream_sink,  # the sink type to use.
        once_done,  # what to do once done.
        ctx.channel  # the channel to disconnect from.
    )
    await set_get_config(value=True)
    await ctx.respond("Started listening.")
    await recognize(ctx)


@bot.slash_command(name="stop_recording", description='–ø–µ—Ä–µ—Å—Ç–∞—Ç—å –≤–æ—Å–ø—Ä–∏–Ω–∏–º–∞—Ç—å –∫–æ–º–∞–Ω–¥—ã –∏–∑ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞')
async def stop_recording(ctx):
    if ctx.guild.id in connections:
        vc = connections[ctx.guild.id][0]  # –ü–æ–ª—É—á–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç —Å–ø–∏—Å–∫–∞
        vc.stop_recording()
        del connections[ctx.guild.id]
    else:
        await ctx.respond("–Ø –∏ —Ç–∞–∫ —Ç–µ–±—è –Ω–µ —Å–ª—É—à–∞–ª ._.")


@bot.slash_command(name="disconnect", description='–≤—ã–π—Ç–∏ –∏–∑ –≤–æ–π—Å-—á–∞—Ç–∞')
async def disconnect(ctx):
    await ctx.defer()
    voice = ctx.voice_client
    if voice:
        await voice.disconnect(force=True)
        await ctx.respond("–≤—ã—Ö–æ–∂—É")
    else:
        await ctx.respond("–Ø –Ω–µ –≤ –≤–æ–π—Å–µ")
    if ctx.guild.id in connections:
        del connections[ctx.guild.id]  # remove the guild from the cache.


# @bot.command(help="—Å–∫–∞–∑–∞—Ç—å —Ä–æ–±–æ—Ç—É —Ç–µ–∫—Å—Ç")
# async def say(ctx, *args):
#     message = " ".join(args)
#     from function import replace_mat_in_sentence
#     if not default_settings.get("robot_name_need"):
#         message = default_settings.get("currentAIname") + ", " + message
#         print(message)
#     else:
#         print(message)
#     message = await replace_mat_in_sentence(message)
#     # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ –∞–≤—Ç–æ—Ä –∫–æ–º–∞–Ω–¥—ã –≤ –≤–æ–π—Å-—á–∞—Ç–µ
#     # if ctx.author.voice:
#     if True:
#         # –ü–æ–ª—É—á–∞–µ–º –≤–æ–π—Å-–∫–∞–Ω–∞–ª –∞–≤—Ç–æ—Ä–∞ –∫–æ–º–∞–Ω–¥—ã
#         # voice_channel = ctx.author.voice.channel
#         # # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ –±–æ—Ç —É–∂–µ –≤ –∫–∞–∫–æ–º-–ª–∏–±–æ –≤–æ–π—Å-—á–∞—Ç–µ
#         # if ctx.voice_client is None:
#         #     # –ï—Å–ª–∏ –±–æ—Ç –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –≤–æ–π—Å-—á–∞—Ç–µ, –ø–æ–¥–∫–ª—é—á–∞–µ–º –µ–≥–æ
#         #     await voice_channel.connect()
#         # else:
#         #     # –ï—Å–ª–∏ –±–æ—Ç —É–∂–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –≤–æ–π—Å-—á–∞—Ç–µ, –ø–µ—Ä–µ–º–µ—â–∞–µ–º –µ–≥–æ –≤ –Ω–æ–≤—ã–π –≤–æ–π—Å-–∫–∞–Ω–∞–ª
#         #     await ctx.voice_client.move_to(voice_channel)
#         await run_main_with_settings(ctx, message, True)
#     else:
#         await ctx.send("–í—ã –¥–æ–ª–∂–Ω—ã –Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤ –≤–æ–π—Å-—á–∞—Ç–µ, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç—É –∫–æ–º–∞–Ω–¥—É.")


@bot.slash_command(name="pause", description='–ø–∞—É–∑–∞/–≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ')
async def pause(ctx):
    await ctx.defer()
    await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')
    voice_client = ctx.voice_client
    if voice_client.is_playing():
        voice_client.pause()
        await ctx.respond("–ü–∞—É–∑–∞ ‚è∏")
    elif voice_client.is_paused():
        voice_client.resume()
        await ctx.respond("–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ ‚ñ∂Ô∏è")
    else:
        await ctx.respond("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∏–ª–∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è.")


@bot.slash_command(name="skip", description='–ø—Ä–æ–ø—É—Å–∫ –∞—É–¥–∏–æ')
async def skip(ctx):
    await ctx.defer()
    await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')
    voice_client = ctx.voice_client
    if voice_client.is_playing():
        voice_client.stop()
        await ctx.respond("–¢–µ–∫—É—â–∏–π —Ç—Ä–µ–∫ –ø—Ä–æ–ø—É—â–µ–Ω ‚è≠Ô∏è")
        await set_get_config("stop_milliseconds", 0)
    else:
        await ctx.respond("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞.")


@bot.slash_command(name="lenght", description='–î–ª–∏–Ω–∞ –∑–∞–ø—Ä–æ—Å–∞')
async def __lenght(
        ctx,
        number: Option(int, description='–î–ª–∏–Ω–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è GPT (–ß–∏—Å–ª–æ –æ—Ç 1 –¥–æ 1000)', required=True, min_value=1,
                       max_value=1000)
):
    await ctx.defer()
    await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')
    # for argument in (number,"""boolean, member, text, choice"""):
    print(f'{number} ({type(number).__name__})\n')
    await run_main_with_settings(ctx, f"—Ä–æ–±–æ—Ç –¥–ª–∏–Ω–∞ –∑–∞–ø—Ä–æ—Å–∞ {number}", True)
    await ctx.respond(f"–î–ª–∏–Ω–∞ –∑–∞–ø—Ä–æ—Å–∞: {number}")


@bot.slash_command(name="say", description='–°–∫–∞–∑–∞—Ç—å —Ä–æ–±–æ—Ç—É —á—Ç–æ-—Ç–æ')
async def __say(
        ctx,
        text: Option(str, description='–°–∞–º —Ç–µ–∫—Å—Ç/–∫–æ–º–∞–Ω–¥–∞. –°–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥: \\help-say', required=True)
):
    await ctx.defer()
    await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')
    from function import replace_mat_in_sentence
    if await set_get_config_default("robot_name_need") == "False":
        text = await set_get_config_default("currentainame") + ", " + text
    text = await replace_mat_in_sentence(text)
    print(f'{text} ({type(text).__name__})\n')
    await run_main_with_settings(ctx, text, True)


@bot.slash_command(name="tts", description='_–ó–∞—Å—Ç–∞–≤–∏—Ç—å_ –±–æ—Ç–∞ –≥–æ–≤–æ—Ä–∏—Ç—å –≤—Å—ë, —á—Ç–æ –∑–∞—Ö–æ—á–µ—à—å')
async def __tts(
        ctx,
        text: Option(str, description='–¢–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏', required=True),
        ai_voice: Option(str, description='–ì–æ–ª–æ—Å –¥–ª—è –æ–∑–≤—É—á–∫–∏', required=False, default="None")
):
    await ctx.defer()
    await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')
    config.read('config.ini')
    voices = config.get("Sound", "voices").replace("\"", "").replace(",", "").split(";")
    if ai_voice not in voices:
        return await ctx.respond("–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å –∏–∑ —Å–ø–∏—Å–∫–∞: " + ','.join(voices))
    from function import replace_mat_in_sentence, mat_found
    text = await replace_mat_in_sentence(text)
    if mat_found:
        await ctx.respond("–¢–∞–∫–æ–µ –Ω–µ–ª—å–∑—è –ø—Ä–æ–∏–∑–Ω–æ—Å–∏—Ç—å!")
        return
    print(f'{text} ({type(text).__name__})\n')
    # –º–µ–Ω—è–µ–º –≥–æ–ª–æ—Å
    ai_voice_temp = await set_get_config_default("currentainame")
    if ai_voice == "None":
        ai_voice = await set_get_config_default("currentainame")
        print(await set_get_config_default("currentainame"))
    await set_get_config_default("currentainame", ai_voice)
    # –∑–∞–ø—É—Å–∫–∞–µ–º TTS
    await run_main_with_settings(ctx, f"—Ä–æ–±–æ—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª 24 {text}",
                                 False)  # await text_to_speech(text, False, ctx, ai_dictionary=ai_voice)
    # –≤–æ–∑—Ä–∞—â–∞–µ–º –≥–æ–ª–æ—Å
    await set_get_config_default("currentainame", ai_voice_temp)


@bot.slash_command(name="ai_cover", description='_–ó–∞—Å—Ç–∞–≤–∏—Ç—å_ –±–æ—Ç–∞ –æ–∑–≤—É—á–∏—Ç—å –≤–∏–¥–µ–æ/—Å–ø–µ—Ç—å –ø–µ—Å–Ω—é')
async def __cover(
        ctx,
        url: Option(str, description='–°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∏–¥–µ–æ', required=False),
        audio_path: Option(discord.SlashCommandOptionType.attachment, description='–ê—É–¥–∏–æ—Ñ–∞–π–ª',
                      required=False),
        voice: Option(str, description='–ì–æ–ª–æ—Å –¥–ª—è –≤–∏–¥–µ–æ', required=False, default=None),
        pitch: Option(str, description='–ö—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç/–ø–æ—ë—Ç –≤ –≤–∏–¥–µ–æ?', required=False,
                      choices=['–º—É–∂—á–∏–Ω–∞', '–∂–µ–Ω—â–∏–Ω–∞'], default=None),
        time: Option(int, description='–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)', required=False,
                     default=-1, min_value=0),
        indexrate: Option(float, description='–ò–Ω–¥–µ–∫—Å —á–∞—Å—Ç–æ—Ç—ã (–æ—Ç 0 –¥–æ 1)', required=False, default=0.5, min_value=0,
                          max_value=1),
        loudness: Option(float, description='–ì—Ä–æ–º–∫–æ—Å—Ç—å —à—É–º–∞ (–æ—Ç 0 –¥–æ 1)', required=False, default=0.2, min_value=0,
                         max_value=1),
        main_vocal: Option(int, description='–ì—Ä–æ–º–∫–æ—Å—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –≤–æ–∫–∞–ª–∞ (–æ—Ç -20 –¥–æ 0)', required=False, default=0,
                           min_value=-20, max_value=0),
        back_vocal: Option(int, description='–ì—Ä–æ–º–∫–æ—Å—Ç—å –±—ç–∫–≤–æ–∫–∞–ª–∞ (–æ—Ç -20 –¥–æ 0)', required=False, default=0,
                           min_value=-20, max_value=0),
        music: Option(int, description='–ì—Ä–æ–º–∫–æ—Å—Ç—å –º—É–∑—ã–∫–∏ (–æ—Ç -20 –¥–æ 0)', required=False, default=0, min_value=-20,
                      max_value=0),
        roomsize: Option(float, description='–†–∞–∑–º–µ—Ä –ø–æ–º–µ—â–µ–Ω–∏—è (–æ—Ç 0 –¥–æ 1)', required=False, default=0.2, min_value=0,
                         max_value=1),
        wetness: Option(float, description='–í–ª–∞–∂–Ω–æ—Å—Ç—å (–æ—Ç 0 –¥–æ 1)', required=False, default=0.1, min_value=0,
                        max_value=1),
        dryness: Option(float, description='–°—É—Ö–æ—Å—Ç—å (–æ—Ç 0 –¥–æ 1)', required=False, default=0.85, min_value=0,
                        max_value=1),
        start: Option(int, description='–ù–∞—á–∞—Ç—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å —Å (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)', required=False, default=0, min_value=0),
        output: Option(bool, description='–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –∞—Ä—Ö–∏–≤–µ', required=False, default=False)
):
    await ctx.defer()
    await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')
    params = []
    if audio_path:
        filename = str(random.randint(1, 1000000)) + ".mp3"
        await audio_path.save(filename)
        params.append(f"-url {filename}")
    elif url:
        params.append(f"-url {url}")
    else:
        return ctx.respond('–ù–µ —É–∫–∞–∑–∞–Ω–∞ —Å—Å—ã–ª–∫–∞ –∏–ª–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª')
    if voice is None:
        voice = await set_get_config_default("currentAIname")
    if voice:
        params.append(f"-voice {voice}")
    # –µ—Å–ª–∏ –º—É–∂—á–∏–Ω–∞-–º—É–∂—á–∏–Ω–∞, –∂–µ–Ω—â–∏–Ω–∞-–∂–µ–Ω—â–∏–Ω–∞, pitch –Ω–µ –º–µ–Ω—è–µ–º
    pitch_int = 0
    # –µ—Å–ª–∏ –∂–µ–Ω—â–∏–Ω–∞, –Ω–æ AI –º—É–∂—á–∏–Ω–∞ = 1,
    if pitch == '–∂–µ–Ω—â–∏–Ω–∞':
        if not await set_get_config_default("currentaipitch") == 1:
            pitch_int = 1
    # –µ—Å–ª–∏ –º—É–∂—á–∏–Ω–∞, –Ω–æ AI –∂–µ–Ω—â–∏–Ω–∞ = -1,
    elif pitch == '–º—É–∂—á–∏–Ω–∞':
        if not await set_get_config_default("currentaipitch") == 0:
            pitch_int = -1
    params.append(f"-pitch {pitch_int}")
    if time != -1:
        params.append(f"-time {time}")
    if indexrate != 0.5:
        params.append(f"-indexrate {indexrate}")
    if loudness != 0.2:
        params.append(f"-loudness {loudness}")
    if main_vocal != 0:
        params.append(f"-vocal {main_vocal}")
    if back_vocal != 0:
        params.append(f"-bvocal {back_vocal}")
    if music != 0:
        params.append(f"-music {music}")
    if roomsize != 0.2:
        params.append(f"-roomsize {roomsize}")
    if wetness != 0.1:
        params.append(f"-wetness {wetness}")
    if dryness != 0.85:
        params.append(f"-dryness {dryness}")
    if start != 0:
        params.append(f"-start {start}")
    param_string = ' '.join(params)

    await run_main_with_settings(ctx, "—Ä–æ–±–æ—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª 13 " + param_string, False)
    # output..


@bot.slash_command(name="add_voice", description='–î–æ–±–∞–≤–∏—Ç—å RVC –≥–æ–ª–æ—Å')
async def __add_voice(
        ctx,
        url: Option(str, description='–°—Å—ã–ª–∫–∞ –Ω–∞ .zip —Ñ–∞–π–ª —Å –º–æ–¥–µ–ª—å—é RVC', required=True),
        name: Option(str, description=f'–ò–º—è –º–æ–¥–µ–ª–∏', required=True),
        gender: Option(str, description=f'–ü–æ–ª (–¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏)', required=True,
                       choices=['–º—É–∂—á–∏–Ω–∞', '–∂–µ–Ω—â–∏–Ω–∞']),
        info: Option(str, description=f'(–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ) –ö–∞–∫–∏–µ-—Ç–æ —Å–≤–µ–¥–µ–Ω–∏—è –æ –¥–∞–Ω–Ω–æ–º —á–µ–ª–æ–≤–µ–∫–µ', required=False,
                     default="–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"),
        change_voice: Option(bool, description=f'(–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ) –ò–∑–º–µ–Ω–∏—Ç—å –≥–æ–ª–æ—Å –Ω–∞ —ç—Ç–æ—Ç', required=False,
                             default=False)
):
    await ctx.defer()
    await ctx.respond('–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...')
    # !python download_model_with_link_AICoverGen.py {url} {dir_name} {gender} {info}
    command = None
    if gender == "–∂–µ–Ω—â–∏–Ω–∞":
        gender = "female"
    elif gender == "–º—É–∂—á–∏–Ω–∞":
        gender = "male"
    else:
        gender = "male"
    try:
        command = [
            "python",
            "download_model_with_link_AICoverGen.py",
            url,
            name,
            gender,
            info
        ]
        subprocess.run(command, check=True)
        config.read('config.ini')
        voices = config.get("Sound", "voices").split(";")
        voices.append(name)
        config.set('Sound', "voices", ';'.join(voices))
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        with open('config.ini', 'w') as configfile:
            config.write(configfile)
        if change_voice:
            await run_main_with_settings(ctx, f"—Ä–æ–±–æ—Ç –∏–∑–º–µ–Ω–∏ –≥–æ–ª–æ—Å –Ω–∞ {name}", True)
    except subprocess.CalledProcessError as e:
        await ctx.respond(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ –≥–æ–ª–æ—Å–∞ {command}: {e}")


@bot.command(aliases=['cmd'], help="–∫–æ–º–∞–Ω–¥–Ω–∞—è —Å—Ç—Ä–æ–∫–∞")
async def command_line(ctx, *args):
    text = " ".join(args)
    try:
        process = subprocess.Popen(text, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)
        stdout, stderr = process.communicate()
        for line in stdout.decode().split('\n'):
            if line.strip():
                await ctx.send(line)
        for line in stderr.decode().split('\n'):
            if line.strip():
                await ctx.send(line)
    except subprocess.CalledProcessError as e:
        await ctx.send(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã: {e}")
    except Exception as e:
        await ctx.send(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")


@bot.command(aliases=['–ø—Ä–æ—Å–ª—É—à–∞–π_–∫–µ–∫–ª–æ–ª–∞'], help="–•–ê–í–•–í–ê–•–í–ê–•–í–ê–•–í–ê–•")
async def i_hear_you(ctx):  # if you're using commands.Bot, this will also work.
    await ctx.send("–ü–æ–ª—É—á–∞—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
    await asyncio.sleep(1)
    await ctx.send("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å <@920404602317324388> –Ω–∞–π–¥–µ–Ω!")
    await asyncio.sleep(1)
    await ctx.send("–ü–æ–ª—É—á–µ–Ω –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞!")


async def run_main_with_settings(ctx, spokenText, writeAnswer):
    from function import start_bot
    await start_bot(ctx, spokenText, writeAnswer)


async def write_in_discord(ctx, text):
    # await run_main_with_settings(ctx, text, True)
    await ctx.send(text)


async def send_file(ctx, file_path):
    try:
        await ctx.send(file=discord.File(file_path))
    except FileNotFoundError:
        await ctx.send('–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.')
    except discord.HTTPException:
        await ctx.send('–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–∞–π–ª–∞.')


async def playSoundFileDiscord(ctx, audio_file_path, duration, start_seconds):
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ –±–æ—Ç –≤ –≥–æ–ª–æ—Å–æ–≤–æ–º –∫–∞–Ω–∞–ª–µ
    if not ctx.voice_client:
        await ctx.send("–ë–æ—Ç –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –≥–æ–ª–æ—Å–æ–≤–æ–º –∫–∞–Ω–∞–ª–µ. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É `join`, —á—Ç–æ–±—ã –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å –µ–≥–æ.")
        return

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–≥—Ä–∞–µ—Ç –ª–∏ —á—Ç–æ-—Ç–æ —É–∂–µ
    if ctx.voice_client.is_playing():
        await asyncio.sleep(0.1)

    # –ø—Ä–æ–∏–≥—Ä—ã–≤–∞–µ–º
    source = discord.FFmpegPCMAudio(audio_file_path, options=f"-ss {start_seconds} -t {duration}")
    ctx.voice_client.play(source)

    # –û–∂–∏–¥–∞–µ–º –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø—Ä–æ–∏–≥—Ä—ã–≤–∞–Ω–∏—è
    while ctx.voice_client.is_playing():
        await asyncio.sleep(1)
        # stop_milliseconds += 1000
        await set_get_config("stop_milliseconds", int(await set_get_config("stop_milliseconds")) + 1000)


async def once_done(sink: discord.sinks, channel: discord.TextChannel, *args):
    await set_get_config(value=False)
    # await sink.vc.disconnect()  # disconnect from the voice channel.
    print("Stopped listening.")


file_not_found_in_raw = 0


async def recognize(ctx):
    global file_not_found_in_raw
    wav_filename = "out_all.wav"
    recognizer = sr.Recognizer()
    while True:
        # —Ä–∞—Å–ø–æ–∑–Ω–∞—ë–º, –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–∏–∑–æ–π–¥—ë—Ç once_done
        if await set_get_config() == "False":
            print("Stopped listening2.")
            return
        file_found = None
        # –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        for filename in os.listdir(os.getcwd()):
            if filename.startswith("output") and filename.endswith(".wav"):
                file_found = filename
                break
        if file_found is None:
            await asyncio.sleep(0.1)
            file_not_found_in_raw += 1
            # –µ—Å–ª–∏ –¥–æ–ª–≥–æ –Ω–µ –±—ã–ª–æ —Ñ–∞–π–ª–æ–≤ (—á–µ–ª–æ–≤–µ–∫ –ø–µ—Ä–µ—Å—Ç–∞–ª –≥–æ–≤–æ—Ä–∏—Ç—å)
            if file_not_found_in_raw > float(await set_get_config("delay_record")) * 10:
                text = None
                # –æ—á–∏—â–∞–µ–º –ø–æ—Ç–æ–∫
                stream_sink.cleanup()
                file_not_found_in_raw = 0
                # —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∏–µ —Ä–µ—á–∏
                try:
                    with sr.AudioFile(wav_filename) as source:
                        audio_data = recognizer.record(source)
                        text = recognizer.recognize_google(audio_data, language="ru-RU")
                except sr.UnknownValueError:
                    pass
                except sr.RequestError as e:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏: {e}")
                # —É–¥–∞–ª–µ–Ω–∏–µ out_all.wav
                try:
                    Path(wav_filename).unlink()
                except FileNotFoundError:
                    pass

                # —Å–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
                empty_audio = AudioSegment.silent(duration=0)
                try:
                    empty_audio.export(wav_filename, format="wav")
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø—É—Å—Ç–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞: {e}")
                # –≤—ã–∑–æ–≤ function
                if not text is None:
                    from function import replace_mat_in_sentence, replace_numbers_in_sentence
                    text = await replace_numbers_in_sentence(text)
                    text = await replace_mat_in_sentence(text)
                    print(text)
                    await run_main_with_settings(ctx, "—Ä–æ–±–æ—Ç, " + text, True)

            continue
        result = AudioSegment.from_file(wav_filename, format="wav") + AudioSegment.from_file(file_found, format="wav")
        try:
            result.export(wav_filename, format="wav")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ –∞—É–¥–∏–æ: {e}")
        print("recognize_saved")
        # —É–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        try:
            Path(file_found).unlink()
        except FileNotFoundError:
            pass
    print("Stop_Recording")


async def get_image_dimensions(file_path):
    with open(file_path, 'rb') as file:
        data = file.read(24)

    if data.startswith(b'\x89PNG\r\n\x1a\n'):
        return struct.unpack('>ii', data[16:24])
    elif data[:6] in (b'GIF87a', b'GIF89a') and data[10:12] == b'\x00\x00':
        return struct.unpack('<HH', data[6:10])
    elif data.startswith(b'\xff\xd8\xff\xe0') and data[6:10] == b'JFIF':
        return struct.unpack('>H', data[7:9])[0], struct.unpack('>H', data[9:11])[0]
    elif data.startswith(b'\xff\xd8\xff\xe1') and data[6:10] == b'Exif':
        return struct.unpack('<HH', data[10:14])[0], struct.unpack('<HH', data[14:18])[0]
    else:
        raise ValueError("–§–æ—Ä–º–∞—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")


if __name__ == "__main__":
    print("update 1")
    arguments = sys.argv

    if len(arguments) > 1:
        discord_token = arguments[1]
    else:
        print("–£–∫–∞–∂–∏—Ç–µ discord_TOKEN")
        exit(-1)
    # load models
    from GPT_runner import run
    from image_create import generate_picture

    print("load gpt model")
    pool1 = multiprocessing.Pool(processes=1)
    pool1.apply_async(run)
    pool1.close()
    print("load image model")
    pool2 = multiprocessing.Pool(processes=1)
    pool2.apply_async(generate_picture)
    pool2.close()
    print("load bot")
    bot.run(discord_token)
